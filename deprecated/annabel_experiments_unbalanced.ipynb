{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTgrxJWKRlzZ"
      },
      "source": [
        "# imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y7_UCg8N5Qeu"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import os\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Dict, Any, List\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    T5ForConditionalGeneration,\n",
        "    T5TokenizerFast,\n",
        "    GPT2LMHeadModel,\n",
        "    GPT2TokenizerFast,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mICAot6NRn46"
      },
      "source": [
        "# functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0et_iRKT5UDt"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class ExperimentConfig:\n",
        "    model_name: str = \"t5-large\"\n",
        "    gpt2_name: str = \"gpt2\"\n",
        "    max_source_length: int = 256\n",
        "    max_target_length: int = 4\n",
        "    batch_size: int = 16\n",
        "    lr: float = 1e-3\n",
        "    num_epochs: int = 5\n",
        "    prompt_length: int = 10\n",
        "    lambda_grid: List[float] = None\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.lambda_grid is None:\n",
        "            self.lambda_grid = [0.0, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1.0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yF-b68es5X9s"
      },
      "outputs": [],
      "source": [
        "def preprocess_boolq(example, tokenizer: T5TokenizerFast, max_source_length: int, max_target_length: int):\n",
        "    \"\"\"\n",
        "    Turn BoolQ into T5 inputs:\n",
        "      \"question: {question} passage: {passage}\"\n",
        "    Targets are \"yes\" or \"no\".\n",
        "    \"\"\"\n",
        "    question = example[\"question\"]\n",
        "    passage = example[\"passage\"]\n",
        "    answer = \"yes\" if example[\"answer\"] else \"no\"\n",
        "\n",
        "    source = f\"question: {question} passage: {passage}\"\n",
        "    target = answer\n",
        "\n",
        "    model_inputs = tokenizer(\n",
        "        source,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=max_source_length,\n",
        "    )\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            target,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=max_target_length,\n",
        "        )\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "\n",
        "def load_boolq(tokenizer: T5TokenizerFast, cfg: ExperimentConfig):\n",
        "    ds = load_dataset(\"boolq\")\n",
        "\n",
        "    preprocess_fn = lambda ex: preprocess_boolq(\n",
        "        ex,\n",
        "        tokenizer=tokenizer,\n",
        "        max_source_length=cfg.max_source_length,\n",
        "        max_target_length=cfg.max_target_length,\n",
        "    )\n",
        "\n",
        "    ds = ds.map(preprocess_fn, batched=False)\n",
        "    ds.set_format(\n",
        "        type=\"torch\",\n",
        "        columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
        "    )\n",
        "\n",
        "    train_dl = DataLoader(ds[\"train\"], batch_size=cfg.batch_size, shuffle=True)\n",
        "    val_dl = DataLoader(ds[\"validation\"], batch_size=cfg.batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "    return train_dl, val_dl\n",
        "\n",
        "\n",
        "def load_boolq_balanced(tokenizer: T5TokenizerFast, cfg: ExperimentConfig, seed: int = 42):\n",
        "    \"\"\"\n",
        "    Load BoolQ, balance the train split on the raw dataset (True/False),\n",
        "    then preprocess into T5-style inputs and wrap in DataLoaders.\n",
        "    \"\"\"\n",
        "    raw = load_dataset(\"boolq\")\n",
        "    train_raw = raw[\"train\"]\n",
        "    val_raw   = raw[\"validation\"]\n",
        "\n",
        "    # --- Balance train: downsample majority label ---\n",
        "    true_indices  = [i for i, ex in enumerate(train_raw) if ex[\"answer\"]]\n",
        "    false_indices = [i for i, ex in enumerate(train_raw) if not ex[\"answer\"]]\n",
        "\n",
        "    min_count = min(len(true_indices), len(false_indices))\n",
        "    true_indices  = true_indices[:min_count]\n",
        "    false_indices = false_indices[:min_count]\n",
        "\n",
        "    balanced_indices = true_indices + false_indices\n",
        "    # Optional but usually helpful: shuffle indices for randomness\n",
        "    rng = torch.Generator().manual_seed(seed)\n",
        "    perm = torch.randperm(len(balanced_indices), generator=rng).tolist()\n",
        "    balanced_indices = [balanced_indices[i] for i in perm]\n",
        "\n",
        "    train_balanced = train_raw.select(balanced_indices)\n",
        "\n",
        "    print(\n",
        "        f\"Balanced BoolQ train: {len(train_balanced)} examples \"\n",
        "        f\"({min_count} True, {min_count} False)\"\n",
        "    )\n",
        "\n",
        "    # --- Preprocess to T5 format ---\n",
        "    def preprocess_fn(ex):\n",
        "        return preprocess_boolq(\n",
        "            ex,\n",
        "            tokenizer=tokenizer,\n",
        "            max_source_length=cfg.max_source_length,\n",
        "            max_target_length=cfg.max_target_length,\n",
        "        )\n",
        "\n",
        "    train_proc = train_balanced.map(preprocess_fn, batched=False)\n",
        "    val_proc   = val_raw.map(preprocess_fn, batched=False)\n",
        "\n",
        "    # Keep only the model fields and cast to torch\n",
        "    cols = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
        "    train_proc.set_format(type=\"torch\", columns=cols)\n",
        "    val_proc.set_format(type=\"torch\", columns=cols)\n",
        "\n",
        "    train_dl = DataLoader(train_proc, batch_size=cfg.batch_size, shuffle=True)\n",
        "    val_dl   = DataLoader(val_proc,   batch_size=cfg.batch_size, shuffle=False)\n",
        "\n",
        "    return train_dl, val_dl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hAkwGMi9J4C",
        "outputId": "3ecbadfd-cf90-4379-8b23-7eaf5270c6e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_true: 5874\n",
            "num_false: 3553\n",
            "P(True) = 0.6231038506417736\n",
            "P(False) = 0.37689614935822635\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "ds = load_dataset(\"boolq\")\n",
        "labels = [ex[\"answer\"] for ex in ds[\"train\"]]   # True/False labels\n",
        "ctr = Counter(labels)\n",
        "\n",
        "num_true  = ctr[True]\n",
        "num_false = ctr[False]\n",
        "total     = num_true + num_false\n",
        "\n",
        "print(\"num_true:\", num_true)\n",
        "print(\"num_false:\", num_false)\n",
        "print(\"P(True) =\", num_true / total)\n",
        "print(\"P(False) =\", num_false / total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MF5gFm545goZ"
      },
      "outputs": [],
      "source": [
        "class T5ContinuousSoftPrompt(nn.Module):\n",
        "    \"\"\"\n",
        "    Continuous soft prompts: learn a (prompt_length, d_model) tensor\n",
        "    and prepend it as prefix embeddings to the encoder input.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base: T5ForConditionalGeneration, prompt_length: int):\n",
        "        super().__init__()\n",
        "        self.t5 = base\n",
        "        self.prompt_length = prompt_length\n",
        "\n",
        "        d_model = base.encoder.embed_tokens.weight.shape[1]\n",
        "        self.soft_prompt = nn.Parameter(\n",
        "            torch.zeros(prompt_length, d_model)\n",
        "        )\n",
        "        nn.init.normal_(self.soft_prompt, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.Tensor,\n",
        "        attention_mask: torch.Tensor,\n",
        "        labels: torch.Tensor,\n",
        "    ):\n",
        "        batch_size = input_ids.size(0)\n",
        "        device = input_ids.device\n",
        "\n",
        "        # Original token embeddings\n",
        "        inputs_embeds = self.t5.encoder.embed_tokens(input_ids)\n",
        "\n",
        "        # Broadcast prompt to batch\n",
        "        prompt_embeds = self.soft_prompt.unsqueeze(0).expand(batch_size, -1, -1)\n",
        "\n",
        "        # Prepend to input sequence\n",
        "        inputs_embeds = torch.cat([prompt_embeds, inputs_embeds], dim=1)\n",
        "\n",
        "        # Extend attention mask\n",
        "        prompt_mask = torch.ones(batch_size, self.prompt_length, device=device, dtype=attention_mask.dtype)\n",
        "        attention_mask = torch.cat([prompt_mask, attention_mask], dim=1)\n",
        "\n",
        "        outputs = self.t5(\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels,\n",
        "        )\n",
        "        return outputs  # has .loss and .logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OHbVDFyp5iem"
      },
      "outputs": [],
      "source": [
        "class T5PEZPrompt(nn.Module):\n",
        "    \"\"\"\n",
        "    PEZ-style one-hot prompt over the T5 vocabulary.\n",
        "\n",
        "    - self.prompt is (L, V) with rows ~ one-hot\n",
        "    - FORWARD: treat self.prompt as continuous, embed via matrix multiply\n",
        "               prompt_embeds = prompt @ embed_tokens.weight\n",
        "      This keeps the computation differentiable w.r.t. self.prompt.\n",
        "    - DISCRETIZATION: use argmax *outside* the forward (for decoding / GPT-2).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base: T5ForConditionalGeneration, prompt_length: int):\n",
        "        super().__init__()\n",
        "        self.t5 = base\n",
        "        self.vocab_size = base.encoder.embed_tokens.weight.shape[0]\n",
        "        self.prompt_length = prompt_length\n",
        "\n",
        "        # Initialize as random one-hot rows\n",
        "        init_ids = torch.randint(0, self.vocab_size, (prompt_length,))\n",
        "        prompt = torch.nn.functional.one_hot(init_ids, num_classes=self.vocab_size).float()\n",
        "        self.prompt = nn.Parameter(prompt)  # (L, V), requires_grad=True by default\n",
        "\n",
        "    # ---- helper used ONLY for decoding / perplexity, NOT in forward ----\n",
        "    def get_prompt_token_ids(self) -> torch.Tensor:\n",
        "        return self.prompt.argmax(dim=-1)  # (L,)\n",
        "\n",
        "    def decode_prompt(self, tokenizer: T5TokenizerFast) -> str:\n",
        "        token_ids = self.get_prompt_token_ids().tolist()\n",
        "        return tokenizer.decode(token_ids, skip_special_tokens=True)\n",
        "\n",
        "    # ---- differentiable forward ----\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.Tensor,\n",
        "        attention_mask: torch.Tensor,\n",
        "        labels: torch.Tensor,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Embed prompt by multiplying the (L, V) prompt matrix with the\n",
        "        (V, d_model) embedding matrix. This is linear in self.prompt,\n",
        "        so gradients flow into self.prompt.\n",
        "        \"\"\"\n",
        "        batch_size = input_ids.size(0)\n",
        "        device = input_ids.device\n",
        "\n",
        "        # 1) Embed the prompt: (L, V) @ (V, d) -> (L, d)\n",
        "        embed_matrix = self.t5.encoder.embed_tokens.weight  # (V, d_model)\n",
        "        prompt_embeds = self.prompt @ embed_matrix          # (L, d_model)\n",
        "        prompt_embeds = prompt_embeds.unsqueeze(0).expand(batch_size, -1, -1)\n",
        "\n",
        "        # 2) Embed the original input tokens\n",
        "        inputs_embeds = self.t5.encoder.embed_tokens(input_ids)\n",
        "\n",
        "        # 3) Prepend prompt embeddings\n",
        "        inputs_embeds = torch.cat([prompt_embeds, inputs_embeds], dim=1)\n",
        "\n",
        "        # 4) Extend attention mask\n",
        "        prompt_mask = torch.ones(\n",
        "            batch_size,\n",
        "            self.prompt_length,\n",
        "            device=device,\n",
        "            dtype=attention_mask.dtype,\n",
        "        )\n",
        "        attention_mask = torch.cat([prompt_mask, attention_mask], dim=1)\n",
        "\n",
        "        # 5) Standard T5 forward\n",
        "        outputs = self.t5(\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels,\n",
        "        )\n",
        "        return outputs  # has .loss and .logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "i2sO9MX55oHZ"
      },
      "outputs": [],
      "source": [
        "def compute_prompt_ppl_loss_from_text(\n",
        "    gpt2_model: GPT2LMHeadModel,\n",
        "    gpt2_tokenizer: GPT2TokenizerFast,\n",
        "    prompt_text: str,\n",
        "    device: str,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Take the decoded prompt text, feed to GPT-2, compute LM loss.\n",
        "    Returns 0.0 if the text tokenizes to an empty sequence.\n",
        "    \"\"\"\n",
        "    # Guard 1: decoded text is empty or whitespace\n",
        "    if not prompt_text or not prompt_text.strip():\n",
        "        return torch.tensor(0.0, device=device)\n",
        "\n",
        "    enc = gpt2_tokenizer(\n",
        "        prompt_text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "    )\n",
        "    input_ids = enc[\"input_ids\"].to(device)\n",
        "\n",
        "    # Guard 2: tokenizer produced no tokens\n",
        "    if input_ids.numel() == 0:\n",
        "        return torch.tensor(0.0, device=device)\n",
        "\n",
        "    labels = input_ids.clone()\n",
        "    with torch.no_grad():\n",
        "        outputs = gpt2_model(input_ids=input_ids, labels=labels)\n",
        "    return outputs.loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rRjqZKA75scC"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate_accuracy_t5(model: nn.Module, dataloader: DataLoader,\n",
        "                         tokenizer: T5TokenizerFast, device: str) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    BoolQ accuracy for T5-style models:\n",
        "    - We look at the first decoder position's logits (position 0 in labels)\n",
        "    - Compare scores for 'yes' vs 'no'\n",
        "    \n",
        "    Returns a dictionary with:\n",
        "    - 'overall': overall accuracy\n",
        "    - 'true_acc': accuracy on questions where answer is True (yes)\n",
        "    - 'false_acc': accuracy on questions where answer is False (no)\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Correct way to get the IDs for \"yes\" / \"no\" for T5\n",
        "    yes_id = tokenizer(\"yes\", add_special_tokens=False).input_ids[0]\n",
        "    no_id  = tokenizer(\"no\",  add_special_tokens=False).input_ids[0]\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    # Separate tracking for True and False answers\n",
        "    correct_true = 0\n",
        "    total_true = 0\n",
        "    correct_false = 0\n",
        "    total_false = 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        input_ids      = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels         = batch[\"labels\"].to(device)\n",
        "\n",
        "        # Forward pass: all your wrappers accept labels=...\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels,\n",
        "        )\n",
        "        # logits: (B, T_out, V)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # First decoder step (the token that should be \"yes\" or \"no\")\n",
        "        first_step_logits = logits[:, 0, :]  # (B, V)\n",
        "\n",
        "        # Scores only for \"yes\" and \"no\"\n",
        "        yes_scores = first_step_logits[:, yes_id]\n",
        "        no_scores  = first_step_logits[:, no_id]\n",
        "\n",
        "        # Predict yes if yes_score >= no_score else no\n",
        "        pred_is_yes = (yes_scores >= no_scores)\n",
        "\n",
        "        # Ground truth: first label token\n",
        "        target_ids  = labels[:, 0]\n",
        "        target_is_yes = (target_ids == yes_id)\n",
        "        target_is_no  = (target_ids == no_id)\n",
        "\n",
        "        # Correct if our yes/no prediction matches target\n",
        "        correct_batch = (pred_is_yes & target_is_yes) | (~pred_is_yes & target_is_no)\n",
        "        correct += correct_batch.sum().item()\n",
        "        total   += target_ids.size(0)\n",
        "        \n",
        "        # Track accuracy separately for True and False answers\n",
        "        # True answers (yes)\n",
        "        true_mask = target_is_yes\n",
        "        if true_mask.any():\n",
        "            correct_true_batch = (pred_is_yes & target_is_yes)[true_mask]\n",
        "            correct_true += correct_true_batch.sum().item()\n",
        "            total_true += true_mask.sum().item()\n",
        "        \n",
        "        # False answers (no)\n",
        "        false_mask = target_is_no\n",
        "        if false_mask.any():\n",
        "            correct_false_batch = (~pred_is_yes & target_is_no)[false_mask]\n",
        "            correct_false += correct_false_batch.sum().item()\n",
        "            total_false += false_mask.sum().item()\n",
        "\n",
        "    overall_acc = correct / total if total > 0 else 0.0\n",
        "    true_acc = correct_true / total_true if total_true > 0 else 0.0\n",
        "    false_acc = correct_false / total_false if total_false > 0 else 0.0\n",
        "    \n",
        "    return {\n",
        "        \"overall\": overall_acc,\n",
        "        \"true_acc\": true_acc,\n",
        "        \"false_acc\": false_acc\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-G92MA2C5tLQ"
      },
      "outputs": [],
      "source": [
        "def train_continuous_soft_prompt(\n",
        "    cfg: ExperimentConfig,\n",
        "    tokenizer: T5TokenizerFast,\n",
        "    train_dl: DataLoader,\n",
        "    val_dl: DataLoader,\n",
        "    adversarial: bool,\n",
        ") -> Dict[str, Any]:\n",
        "    device = cfg.device\n",
        "    base = T5ForConditionalGeneration.from_pretrained(cfg.model_name).to(device)\n",
        "    base.eval()\n",
        "    for p in base.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    model = T5ContinuousSoftPrompt(base, prompt_length=cfg.prompt_length).to(device)\n",
        "\n",
        "    # Use lower learning rate for adversarial training to prevent explosion\n",
        "    effective_lr = cfg.lr * 0.1 if adversarial else cfg.lr\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=effective_lr, weight_decay=0.01)\n",
        "\n",
        "    # --- label ids for flipping (yes/no) ---\n",
        "    if adversarial:\n",
        "        yes_id = tokenizer(\"yes\", add_special_tokens=False).input_ids[0]\n",
        "        no_id  = tokenizer(\"no\",  add_special_tokens=False).input_ids[0]\n",
        "    # --------------------------------------#\n",
        "\n",
        "    history = {\n",
        "        \"train_joint\": [],\n",
        "        \"train_task\": [],\n",
        "        \"val_loss\": [],\n",
        "        \"val_acc\": [],\n",
        "        \"val_acc_true\": [],\n",
        "        \"val_acc_false\": [],\n",
        "        \"prompt_norm\": [],\n",
        "    }\n",
        "\n",
        "    for epoch in range(cfg.num_epochs):\n",
        "        model.train()\n",
        "        running_joint = 0.0\n",
        "        running_task  = 0.0\n",
        "        n_batches = 0\n",
        "\n",
        "        for batch in train_dl:\n",
        "            input_ids      = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels         = batch[\"labels\"].to(device)\n",
        "\n",
        "            # ---- flip labels during adversarial TRAINING ----\n",
        "            if adversarial:\n",
        "                labels_flipped = labels.clone()\n",
        "                mask_yes = labels == yes_id\n",
        "                mask_no  = labels == no_id\n",
        "                labels_flipped[mask_yes] = no_id\n",
        "                labels_flipped[mask_no]  = yes_id\n",
        "                labels_for_loss = labels_flipped\n",
        "            else:\n",
        "                labels_for_loss = labels\n",
        "            # -------------------------------------------------#\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels_for_loss,\n",
        "            )\n",
        "            task_loss = outputs.loss\n",
        "            joint_loss = task_loss  # no sign flip\n",
        "\n",
        "            joint_loss.backward()\n",
        "            # gradient clipping (tighter for adversarial)\n",
        "            max_norm = 0.5 if adversarial else 1.0\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
        "            optimizer.step()\n",
        "\n",
        "            running_joint += joint_loss.item()\n",
        "            running_task  += task_loss.item()\n",
        "            n_batches += 1\n",
        "\n",
        "        avg_train_joint = running_joint / max(1, n_batches)\n",
        "        avg_train_task  = running_task  / max(1, n_batches)\n",
        "\n",
        "        # ----------------- validation: TRUE labels -----------------\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_batches = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_dl:\n",
        "                input_ids      = batch[\"input_ids\"].to(device)\n",
        "                attention_mask = batch[\"attention_mask\"].to(device)\n",
        "                labels         = batch[\"labels\"].to(device)\n",
        "\n",
        "                outputs = model(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    labels=labels,  # real yes/no labels\n",
        "                )\n",
        "                val_loss += outputs.loss.item()\n",
        "                val_batches += 1\n",
        "\n",
        "        avg_val_loss = val_loss / max(1, val_batches)\n",
        "        val_acc_dict = evaluate_accuracy_t5(model, val_dl, tokenizer, device)\n",
        "        val_acc = val_acc_dict[\"overall\"]\n",
        "        val_acc_true = val_acc_dict[\"true_acc\"]\n",
        "        val_acc_false = val_acc_dict[\"false_acc\"]\n",
        "\n",
        "        prompt_norm = model.soft_prompt.norm().item()\n",
        "\n",
        "        history[\"train_joint\"].append(avg_train_joint)\n",
        "        history[\"train_task\"].append(avg_train_task)\n",
        "        history[\"val_loss\"].append(avg_val_loss)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "        history[\"val_acc_true\"].append(val_acc_true)\n",
        "        history[\"val_acc_false\"].append(val_acc_false)\n",
        "        history[\"prompt_norm\"].append(prompt_norm)\n",
        "\n",
        "        print(\n",
        "            f\"[Continuous {'ADV' if adversarial else 'NON-ADV'}] \"\n",
        "            f\"Epoch {epoch+1}/{cfg.num_epochs} | \"\n",
        "            f\"joint={avg_train_joint:.4f} task={avg_train_task:.4f} \"\n",
        "            f\"val_loss={avg_val_loss:.4f} val_acc={val_acc:.4f} \"\n",
        "            f\"(true={val_acc_true:.4f} false={val_acc_false:.4f}) \"\n",
        "            f\"‖prompt‖={prompt_norm:.2f}\"\n",
        "        )\n",
        "\n",
        "    return {\"model\": model, \"history\": history}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ykfVADCa5wCZ"
      },
      "outputs": [],
      "source": [
        "def train_pez(\n",
        "    cfg,\n",
        "    tokenizer: T5TokenizerFast,\n",
        "    gpt2_model: GPT2LMHeadModel,\n",
        "    gpt2_tokenizer: GPT2TokenizerFast,\n",
        "    train_dl: DataLoader,\n",
        "    val_dl: DataLoader,\n",
        "    lambda_ppl: float,\n",
        "    adversarial: bool,\n",
        "    log_every: int = 50,\n",
        "):\n",
        "    device = cfg.device\n",
        "    base = T5ForConditionalGeneration.from_pretrained(cfg.model_name).to(device)\n",
        "    base.eval()\n",
        "    for p in base.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    model = T5PEZPrompt(base, prompt_length=cfg.prompt_length).to(device)\n",
        "\n",
        "    # --- label ids for flipping (yes/no) ---\n",
        "    if adversarial:\n",
        "        yes_id = tokenizer(\"yes\", add_special_tokens=False).input_ids[0]\n",
        "        no_id  = tokenizer(\"no\",  add_special_tokens=False).input_ids[0]\n",
        "    # --------------------------------------#\n",
        "\n",
        "    history = {\n",
        "        \"lambda_ppl\": lambda_ppl,\n",
        "        \"train_joint\": [],\n",
        "        \"train_task\": [],\n",
        "        \"train_ppl_loss\": [],\n",
        "        \"train_ppl_ppx\": [],\n",
        "        \"val_loss\": [],\n",
        "        \"val_acc\": [],\n",
        "        \"val_acc_true\": [],\n",
        "        \"val_acc_false\": [],\n",
        "        \"prompt_ppl_ppx\": [],\n",
        "    }\n",
        "\n",
        "    for epoch in range(cfg.num_epochs):\n",
        "        model.train()\n",
        "        running_joint = 0.0\n",
        "        running_task = 0.0\n",
        "        running_ppl  = 0.0\n",
        "        running_ppl_ppx = 0.0\n",
        "        n_batches = 0\n",
        "\n",
        "        empty_ppl_calls = 0\n",
        "        nonempty_ppl_calls = 0\n",
        "\n",
        "        for batch in train_dl:\n",
        "            input_ids      = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels         = batch[\"labels\"].to(device)\n",
        "\n",
        "            # ---- flip labels during adversarial TRAINING ----\n",
        "            if adversarial:\n",
        "                labels_flipped = labels.clone()\n",
        "                mask_yes = labels == yes_id\n",
        "                mask_no  = labels == no_id\n",
        "                labels_flipped[mask_yes] = no_id\n",
        "                labels_flipped[mask_no]  = yes_id\n",
        "                labels_for_loss = labels_flipped\n",
        "            else:\n",
        "                labels_for_loss = labels\n",
        "            # -------------------------------------------------#\n",
        "\n",
        "            model.prompt.grad = None\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels_for_loss,\n",
        "            )\n",
        "            task_loss = outputs.loss\n",
        "\n",
        "            # ---- perplexity term ----\n",
        "            if lambda_ppl > 0.0:\n",
        "                prompt_ids = model.get_prompt_token_ids()\n",
        "                prompt_text = tokenizer.decode(\n",
        "                    prompt_ids.tolist(),\n",
        "                    skip_special_tokens=True,\n",
        "                    clean_up_tokenization_spaces=True,\n",
        "                ).strip()\n",
        "\n",
        "                if not prompt_text:\n",
        "                    ppl_loss = torch.tensor(0.0, device=device)\n",
        "                    empty_ppl_calls += 1\n",
        "                else:\n",
        "                    nonempty_ppl_calls += 1\n",
        "                    ppl_loss = compute_prompt_ppl_loss_from_text(\n",
        "                        gpt2_model, gpt2_tokenizer, prompt_text, device=device\n",
        "                    )\n",
        "                    if torch.isnan(ppl_loss) or torch.isinf(ppl_loss):\n",
        "                        ppl_loss = torch.tensor(0.0, device=device)\n",
        "            else:\n",
        "                ppl_loss = torch.tensor(0.0, device=device)\n",
        "\n",
        "            joint_loss = task_loss + lambda_ppl * ppl_loss\n",
        "            joint_loss.backward()\n",
        "\n",
        "            # ---- PEZ projection step (one-hot update) ----\n",
        "            with torch.no_grad():\n",
        "                grads = model.prompt.grad\n",
        "                indices = grads.argmin(dim=-1)\n",
        "                new_prompt = torch.nn.functional.one_hot(\n",
        "                    indices, num_classes=model.vocab_size\n",
        "                ).float()\n",
        "                model.prompt.copy_(new_prompt)\n",
        "                model.prompt.grad.zero_()\n",
        "            # ---------------------------------------------\n",
        "\n",
        "            running_joint += joint_loss.item()\n",
        "            running_task  += task_loss.item()\n",
        "            running_ppl   += ppl_loss.item()\n",
        "            if lambda_ppl > 0.0:\n",
        "                running_ppl_ppx += math.exp(ppl_loss.item())\n",
        "            n_batches += 1\n",
        "\n",
        "            if (n_batches % log_every) == 0:\n",
        "                avg_joint_so_far = running_joint / n_batches\n",
        "                avg_task_so_far  = running_task  / n_batches\n",
        "                avg_ppl_so_far   = running_ppl   / n_batches\n",
        "                avg_ppl_ppx_so_far = (\n",
        "                    running_ppl_ppx / n_batches if lambda_ppl > 0.0 else 0.0\n",
        "                )\n",
        "                print(\n",
        "                    f\"[PEZ λ={lambda_ppl} {'ADV' if adversarial else 'NON-ADV'}] \"\n",
        "                    f\"Epoch {epoch+1}/{cfg.num_epochs}, \"\n",
        "                    f\"batch {n_batches} | \"\n",
        "                    f\"joint={avg_joint_so_far:.4f} \"\n",
        "                    f\"task={avg_task_so_far:.4f} \"\n",
        "                    f\"ppl_loss={avg_ppl_so_far:.4f} \"\n",
        "                    f\"ppl={avg_ppl_ppx_so_far:.2f}\"\n",
        "                )\n",
        "\n",
        "        # ---- end-of-epoch aggregation ----\n",
        "        avg_joint = running_joint / max(1, n_batches)\n",
        "        avg_task  = running_task  / max(1, n_batches)\n",
        "        avg_ppl   = running_ppl   / max(1, n_batches)\n",
        "        avg_ppl_ppx = running_ppl_ppx / max(1, n_batches) if lambda_ppl > 0.0 else 0.0\n",
        "\n",
        "        history[\"train_joint\"].append(avg_joint)\n",
        "        history[\"train_task\"].append(avg_task)\n",
        "        history[\"train_ppl_loss\"].append(avg_ppl)\n",
        "        history[\"train_ppl_ppx\"].append(avg_ppl_ppx)\n",
        "\n",
        "        # ---- validation: TRUE labels ----\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_batches = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_dl:\n",
        "                input_ids      = batch[\"input_ids\"].to(device)\n",
        "                attention_mask = batch[\"attention_mask\"].to(device)\n",
        "                labels         = batch[\"labels\"].to(device)\n",
        "\n",
        "                outputs = model(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    labels=labels,   # real yes/no labels here\n",
        "                )\n",
        "                val_loss += outputs.loss.item()\n",
        "                val_batches += 1\n",
        "        avg_val_loss = val_loss / max(1, val_batches)\n",
        "        val_acc_dict = evaluate_accuracy_t5(model, val_dl, tokenizer, device)\n",
        "        val_acc = val_acc_dict[\"overall\"]\n",
        "        val_acc_true = val_acc_dict[\"true_acc\"]\n",
        "        val_acc_false = val_acc_dict[\"false_acc\"]\n",
        "\n",
        "        history[\"val_loss\"].append(avg_val_loss)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "        history[\"val_acc_true\"].append(val_acc_true)\n",
        "        history[\"val_acc_false\"].append(val_acc_false)\n",
        "\n",
        "        # ---- prompt perplexity once per epoch ----\n",
        "        if lambda_ppl > 0.0:\n",
        "            prompt_text_epoch = model.decode_prompt(tokenizer).strip()\n",
        "            if prompt_text_epoch:\n",
        "                ppl_loss_epoch = compute_prompt_ppl_loss_from_text(\n",
        "                    gpt2_model, gpt2_tokenizer, prompt_text_epoch, device=device\n",
        "                )\n",
        "                prompt_ppx = math.exp(ppl_loss_epoch.item())\n",
        "            else:\n",
        "                prompt_ppx = float(\"nan\")\n",
        "        else:\n",
        "            prompt_ppx = 0.0\n",
        "        history[\"prompt_ppl_ppx\"].append(prompt_ppx)\n",
        "\n",
        "        decoded_prompt = model.decode_prompt(tokenizer)\n",
        "        print(\n",
        "            f\"[PEZ λ={lambda_ppl} {'ADV' if adversarial else 'NON-ADV'}] \"\n",
        "            f\"Epoch {epoch+1}/{cfg.num_epochs} | \"\n",
        "            f\"joint={avg_joint:.4f} task={avg_task:.4f} \"\n",
        "            f\"ppl_loss={avg_ppl:.4f} ppl={avg_ppl_ppx:.2f} \"\n",
        "            f\"val_loss={avg_val_loss:.4f} val_acc={val_acc:.4f} \"\n",
        "            f\"(true={val_acc_true:.4f} false={val_acc_false:.4f}) \"\n",
        "            f\"prompt_ppl={prompt_ppx:.2f}\\n\"\n",
        "            f\"Prompt: {decoded_prompt}\"\n",
        "        )\n",
        "\n",
        "    return {\"model\": model, \"history\": history}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# running stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CBs66Bn588X",
        "outputId": "d9d2b657-989a-4a9e-cccd-a3977d08b76b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "cfg = ExperimentConfig()\n",
        "\n",
        "device = cfg.device\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155,
          "referenced_widgets": [
            "a17df50c4f204519873f9106027417b7",
            "3b564b95f24b47018a0c061b713fd2f2",
            "537277c120ca4dd495f0e3b948d81ed7",
            "7e3ca244fb6d4a248b3798617f150856",
            "b0a00dfc20db40a3a75a8afde035f4d2",
            "ff2fd178419e48f0a922f7fb354ccaaa",
            "783196c6ba9d4aa4b805d5625f5c9b98",
            "e3cccc52a75343b28f52bc928d3619df",
            "b83c602ff4df496f852b03d7c903988d",
            "5f84e12c24e24469a4d7b0d96cef0f21",
            "b29fe5a23ed44819a1c5d07abd6a6ce7",
            "0c0c7beb4c0e48f19d55760a141462ef",
            "c61ad218e38a4f91bee3d2aba749b418",
            "b10cb7508ac449199e8616cecccfc52c",
            "2efead2471ca4a3bb20607bb896e5eb2",
            "c177a5639a1f4f1e8bb11d7f4cb423b0",
            "086934b5adb1494c82f3cfd2afad0f34",
            "863e5e6b0574490687e34f80d592fe97",
            "a0cda38cd3f34a958bc37682c22e41ac",
            "6f559210513640af97f3766efe23a3a9",
            "a93c739224fe48ae870d8a00619edc9a",
            "ddb0f6c766214bc08d2a4cc6ac162723"
          ]
        },
        "id": "VlXZEBhl59rG",
        "outputId": "ac0c8340-f894-4ff2-a6ce-609192695d8c"
      },
      "outputs": [],
      "source": [
        "# Tokenizers and data\n",
        "tokenizer = T5TokenizerFast.from_pretrained(cfg.model_name)\n",
        "train_dl, val_dl = load_boolq(tokenizer, cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRABVGTW7vZI",
        "outputId": "e8e6f9d8-94bc-4af9-91a0-a2c9ee76ef9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([150,   1,   0,   0])\n",
            "yes_id 4273\n",
            "no_id 150\n",
            "decoded label: no</s><pad><pad>\n"
          ]
        }
      ],
      "source": [
        "batch = next(iter(val_dl))\n",
        "print(batch[\"labels\"][0][:5])  # first 5 label tokens\n",
        "print(\"yes_id\", tokenizer(\"yes\", add_special_tokens=False).input_ids[0])\n",
        "print(\"no_id\",  tokenizer(\"no\",  add_special_tokens=False).input_ids[0])\n",
        "print(\"decoded label:\", tokenizer.decode(batch[\"labels\"][0]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## baseline accuracy of t5 large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "BASELINE: T5 Large (No Soft Prompt)\n",
            "================================================================================\n",
            "\n",
            "Loading t5-large for baseline evaluation...\n",
            "Evaluating baseline model on validation set...\n",
            "\n",
            "================================================================================\n",
            "Baseline Results:\n",
            "================================================================================\n",
            "Overall Accuracy: 0.6838\n",
            "True (yes) Accuracy:  0.5706\n",
            "False (no) Accuracy:  0.8698\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# put baseline here\n",
        "# Baseline accuracy of T5 Large on validation set (no soft prompt tuning)\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"BASELINE: T5 Large (No Soft Prompt)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Load T5 Large model (baseline without any prompt tuning)\n",
        "baseline_model_name = \"t5-large\"  # Use t5-large for baseline\n",
        "print(f\"\\nLoading {baseline_model_name} for baseline evaluation...\")\n",
        "baseline_model = T5ForConditionalGeneration.from_pretrained(baseline_model_name).to(device)\n",
        "baseline_model.eval()\n",
        "for p in baseline_model.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "# Evaluate on validation set\n",
        "print(\"Evaluating baseline model on validation set...\")\n",
        "baseline_acc_dict = evaluate_accuracy_t5(baseline_model, val_dl, tokenizer, device)\n",
        "\n",
        "baseline_overall = baseline_acc_dict[\"overall\"]\n",
        "baseline_true = baseline_acc_dict[\"true_acc\"]\n",
        "baseline_false = baseline_acc_dict[\"false_acc\"]\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Baseline Results:\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Overall Accuracy: {baseline_overall:.4f}\")\n",
        "print(f\"True (yes) Accuracy:  {baseline_true:.4f}\")\n",
        "print(f\"False (no) Accuracy:  {baseline_false:.4f}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Store baseline for comparison\n",
        "baseline_results = {\n",
        "    \"model_name\": baseline_model_name,\n",
        "    \"overall_acc\": baseline_overall,\n",
        "    \"true_acc\": baseline_true,\n",
        "    \"false_acc\": baseline_false\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPY-tVcTTF2r"
      },
      "source": [
        "## baselines (no interpretability) with 10 length prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxrpJIeQ6AO4",
        "outputId": "3281a199-215e-4007-f4e9-4a5b05a19f93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Continuous Soft Prompt: Non-Adversarial ===\n",
            "[Continuous NON-ADV] Epoch 1/5 | joint=7.7847 task=7.7847 val_loss=0.5864 val_acc=0.6654 (true=0.9843 false=0.1415) ‖prompt‖=3.24\n",
            "[Continuous NON-ADV] Epoch 2/5 | joint=2.9133 task=2.9133 val_loss=0.3128 val_acc=0.6254 (true=0.9990 false=0.0113) ‖prompt‖=3.98\n",
            "[Continuous NON-ADV] Epoch 3/5 | joint=1.9641 task=1.9641 val_loss=0.2195 val_acc=0.6388 (true=0.9936 false=0.0558) ‖prompt‖=4.62\n",
            "[Continuous NON-ADV] Epoch 4/5 | joint=1.7019 task=1.7019 val_loss=0.2248 val_acc=0.6330 (true=0.9990 false=0.0315) ‖prompt‖=5.16\n",
            "[Continuous NON-ADV] Epoch 5/5 | joint=1.4898 task=1.4898 val_loss=0.2858 val_acc=0.6284 (true=0.9990 false=0.0194) ‖prompt‖=5.65\n",
            "\n",
            "=== Continuous Soft Prompt: Adversarial ===\n",
            "[Continuous ADV] Epoch 1/5 | joint=14.5359 task=14.5359 val_loss=12.8305 val_acc=0.6006 (true=0.4009 false=0.9289) ‖prompt‖=2.02\n",
            "[Continuous ADV] Epoch 2/5 | joint=11.0675 task=11.0675 val_loss=8.8545 val_acc=0.4254 (true=0.0831 false=0.9879) ‖prompt‖=2.02\n",
            "[Continuous ADV] Epoch 3/5 | joint=9.2014 task=9.2014 val_loss=7.1741 val_acc=0.4107 (true=0.0576 false=0.9911) ‖prompt‖=2.04\n",
            "[Continuous ADV] Epoch 4/5 | joint=7.6029 task=7.6029 val_loss=4.9483 val_acc=0.4520 (true=0.1471 false=0.9531) ‖prompt‖=2.05\n",
            "[Continuous ADV] Epoch 5/5 | joint=6.1263 task=6.1263 val_loss=1.9967 val_acc=0.4869 (true=0.2238 false=0.9192) ‖prompt‖=2.06\n"
          ]
        }
      ],
      "source": [
        "# Continuous soft prompt baselines\n",
        "print(\"\\n=== Continuous Soft Prompt: Non-Adversarial ===\")\n",
        "cont_non_adv = train_continuous_soft_prompt(\n",
        "    cfg, tokenizer, train_dl, val_dl, adversarial=False\n",
        ")\n",
        "\n",
        "print(\"\\n=== Continuous Soft Prompt: Adversarial ===\")\n",
        "cont_adv = train_continuous_soft_prompt(\n",
        "    cfg, tokenizer, train_dl, val_dl, adversarial=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## gridsearch LR non adv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "GRID SEARCH: Learning Rates for Continuous Soft Prompt (Non-Adversarial)\n",
            "================================================================================\n",
            "\n",
            "--- Testing LR = 1e-05 ---\n",
            "[Continuous NON-ADV] Epoch 1/10 | joint=16.8341 task=16.8341 val_loss=20.1736 val_acc=0.7670 (true=0.7118 false=0.8577) ‖prompt‖=2.04\n",
            "[Continuous NON-ADV] Epoch 2/10 | joint=16.5245 task=16.5245 val_loss=19.6023 val_acc=0.7587 (true=0.6936 false=0.8658) ‖prompt‖=2.04\n",
            "[Continuous NON-ADV] Epoch 3/10 | joint=16.2218 task=16.2218 val_loss=19.1111 val_acc=0.7544 (true=0.6857 false=0.8674) ‖prompt‖=2.04\n",
            "[Continuous NON-ADV] Epoch 4/10 | joint=15.8928 task=15.8928 val_loss=18.6931 val_acc=0.7465 (true=0.6773 false=0.8601) ‖prompt‖=2.04\n",
            "[Continuous NON-ADV] Epoch 5/10 | joint=15.4876 task=15.4876 val_loss=18.2031 val_acc=0.7453 (true=0.6754 false=0.8601) ‖prompt‖=2.04\n",
            "[Continuous NON-ADV] Epoch 6/10 | joint=15.1413 task=15.1413 val_loss=17.5713 val_acc=0.7419 (true=0.6699 false=0.8601) ‖prompt‖=2.04\n",
            "[Continuous NON-ADV] Epoch 7/10 | joint=14.6371 task=14.6371 val_loss=16.7586 val_acc=0.7266 (true=0.6493 false=0.8537) ‖prompt‖=2.04\n",
            "[Continuous NON-ADV] Epoch 8/10 | joint=14.1970 task=14.1970 val_loss=16.0898 val_acc=0.7153 (true=0.6281 false=0.8585) ‖prompt‖=2.04\n",
            "[Continuous NON-ADV] Epoch 9/10 | joint=13.8440 task=13.8440 val_loss=15.3050 val_acc=0.6979 (true=0.5937 false=0.8690) ‖prompt‖=2.04\n",
            "[Continuous NON-ADV] Epoch 10/10 | joint=13.4646 task=13.4646 val_loss=14.4473 val_acc=0.6615 (true=0.5278 false=0.8812) ‖prompt‖=2.04\n",
            "LR=1e-05 (10 epochs): best_val_acc=0.7670, final_val_acc=0.6615\n",
            "\n",
            "--- Testing LR = 5e-05 ---\n",
            "[Continuous NON-ADV] Epoch 1/10 | joint=16.4354 task=16.4354 val_loss=18.4715 val_acc=0.7584 (true=0.6940 false=0.8642) ‖prompt‖=2.04\n",
            "[Continuous NON-ADV] Epoch 2/10 | joint=14.6697 task=14.6697 val_loss=16.0325 val_acc=0.6642 (true=0.5229 false=0.8965) ‖prompt‖=2.04\n",
            "[Continuous NON-ADV] Epoch 3/10 | joint=13.3744 task=13.3744 val_loss=14.4659 val_acc=0.5893 (true=0.3842 false=0.9264) ‖prompt‖=2.04\n",
            "[Continuous NON-ADV] Epoch 4/10 | joint=12.5632 task=12.5632 val_loss=12.8420 val_acc=0.5018 (true=0.2194 false=0.9660) ‖prompt‖=2.04\n",
            "[Continuous NON-ADV] Epoch 5/10 | joint=11.9307 task=11.9307 val_loss=11.2804 val_acc=0.4110 (true=0.0580 false=0.9911) ‖prompt‖=2.04\n",
            "[Continuous NON-ADV] Epoch 6/10 | joint=11.3269 task=11.3269 val_loss=10.1776 val_acc=0.4168 (true=0.0669 false=0.9919) ‖prompt‖=2.04\n",
            "[Continuous NON-ADV] Epoch 7/10 | joint=10.7034 task=10.7034 val_loss=9.4367 val_acc=0.3917 (true=0.0241 false=0.9960) ‖prompt‖=2.04\n",
            "[Continuous NON-ADV] Epoch 8/10 | joint=10.0718 task=10.0718 val_loss=8.7204 val_acc=0.3957 (true=0.0300 false=0.9968) ‖prompt‖=2.04\n",
            "[Continuous NON-ADV] Epoch 9/10 | joint=9.5189 task=9.5189 val_loss=8.1704 val_acc=0.4043 (true=0.0472 false=0.9911) ‖prompt‖=2.04\n",
            "[Continuous NON-ADV] Epoch 10/10 | joint=8.9412 task=8.9412 val_loss=6.8519 val_acc=0.3948 (true=0.0305 false=0.9935) ‖prompt‖=2.04\n",
            "LR=5e-05 (10 epochs): best_val_acc=0.7584, final_val_acc=0.3948\n",
            "\n",
            "--- Testing LR = 0.0001 ---\n",
            "[Continuous NON-ADV] Epoch 1/10 | joint=15.7549 task=15.7549 val_loss=14.1941 val_acc=0.6636 (true=0.5111 false=0.9143) ‖prompt‖=2.05\n",
            "[Continuous NON-ADV] Epoch 2/10 | joint=12.2427 task=12.2427 val_loss=9.8433 val_acc=0.4321 (true=0.0944 false=0.9871) ‖prompt‖=2.05\n",
            "[Continuous NON-ADV] Epoch 3/10 | joint=10.0146 task=10.0146 val_loss=8.2325 val_acc=0.4823 (true=0.1854 false=0.9701) ‖prompt‖=2.06\n",
            "[Continuous NON-ADV] Epoch 4/10 | joint=8.6163 task=8.6163 val_loss=6.3280 val_acc=0.5813 (true=0.3881 false=0.8989) ‖prompt‖=2.07\n",
            "[Continuous NON-ADV] Epoch 5/10 | joint=7.5319 task=7.5319 val_loss=4.5661 val_acc=0.6746 (true=0.6188 false=0.7664) ‖prompt‖=2.08\n",
            "[Continuous NON-ADV] Epoch 6/10 | joint=6.5814 task=6.5814 val_loss=2.9406 val_acc=0.6966 (true=0.7334 false=0.6362) ‖prompt‖=2.09\n",
            "[Continuous NON-ADV] Epoch 7/10 | joint=5.6311 task=5.6311 val_loss=1.6684 val_acc=0.7174 (true=0.7585 false=0.6500) ‖prompt‖=2.09\n",
            "[Continuous NON-ADV] Epoch 8/10 | joint=4.8981 task=4.8981 val_loss=1.3655 val_acc=0.6743 (true=0.5991 false=0.7979) ‖prompt‖=2.10\n",
            "[Continuous NON-ADV] Epoch 9/10 | joint=4.3710 task=4.3710 val_loss=0.8648 val_acc=0.7358 (true=0.8062 false=0.6200) ‖prompt‖=2.11\n",
            "[Continuous NON-ADV] Epoch 10/10 | joint=3.9253 task=3.9253 val_loss=0.7104 val_acc=0.7294 (true=0.8101 false=0.5966) ‖prompt‖=2.12\n",
            "LR=0.0001 (10 epochs): best_val_acc=0.7358, final_val_acc=0.7294\n",
            "\n",
            "--- Testing LR = 0.0005 ---\n",
            "[Continuous NON-ADV] Epoch 1/8 | joint=11.2329 task=11.2329 val_loss=7.1836 val_acc=0.4807 (true=0.1894 false=0.9596) ‖prompt‖=2.32\n",
            "[Continuous NON-ADV] Epoch 2/8 | joint=6.7614 task=6.7614 val_loss=0.9286 val_acc=0.7180 (true=0.9429 false=0.3484) ‖prompt‖=2.55\n",
            "[Continuous NON-ADV] Epoch 3/8 | joint=4.9517 task=4.9517 val_loss=0.4349 val_acc=0.6887 (true=0.9725 false=0.2223) ‖prompt‖=2.76\n",
            "[Continuous NON-ADV] Epoch 4/8 | joint=3.7873 task=3.7873 val_loss=0.3227 val_acc=0.7113 (true=0.9351 false=0.3436) ‖prompt‖=2.95\n",
            "[Continuous NON-ADV] Epoch 5/8 | joint=3.1497 task=3.1497 val_loss=0.2663 val_acc=0.6661 (true=0.9031 false=0.2765) ‖prompt‖=3.12\n",
            "[Continuous NON-ADV] Epoch 6/8 | joint=2.8182 task=2.8182 val_loss=0.3072 val_acc=0.6560 (true=0.9867 false=0.1124) ‖prompt‖=3.29\n",
            "[Continuous NON-ADV] Epoch 7/8 | joint=2.6082 task=2.6082 val_loss=0.2480 val_acc=0.6670 (true=0.9631 false=0.1803) ‖prompt‖=3.44\n",
            "[Continuous NON-ADV] Epoch 8/8 | joint=2.4821 task=2.4821 val_loss=0.2638 val_acc=0.6590 (true=0.9739 false=0.1415) ‖prompt‖=3.59\n",
            "LR=0.0005 (8 epochs): best_val_acc=0.7180, final_val_acc=0.6590\n",
            "\n",
            "--- Testing LR = 0.001 ---\n",
            "[Continuous NON-ADV] Epoch 1/5 | joint=7.6245 task=7.6245 val_loss=0.6404 val_acc=0.7101 (true=0.9444 false=0.3250) ‖prompt‖=3.11\n",
            "[Continuous NON-ADV] Epoch 2/5 | joint=2.9328 task=2.9328 val_loss=0.2714 val_acc=0.6630 (true=0.8264 false=0.3945) ‖prompt‖=3.73\n",
            "[Continuous NON-ADV] Epoch 3/5 | joint=2.2780 task=2.2780 val_loss=0.1922 val_acc=0.6621 (true=0.8549 false=0.3452) ‖prompt‖=4.27\n",
            "[Continuous NON-ADV] Epoch 4/5 | joint=1.9653 task=1.9653 val_loss=0.1907 val_acc=0.5691 (true=0.4673 false=0.7365) ‖prompt‖=4.72\n",
            "[Continuous NON-ADV] Epoch 5/5 | joint=1.7777 task=1.7777 val_loss=0.1660 val_acc=0.6752 (true=0.8264 false=0.4268) ‖prompt‖=5.13\n",
            "LR=0.001 (5 epochs): best_val_acc=0.7101, final_val_acc=0.6752\n",
            "\n",
            "================================================================================\n",
            "Learning Rate Grid Search Results:\n",
            "================================================================================\n",
            "LR=1e-05 (10 epochs): best_val_acc=0.7670, final_val_acc=0.6615\n",
            "LR=5e-05 (10 epochs): best_val_acc=0.7584, final_val_acc=0.3948\n",
            "LR=1e-04 (10 epochs): best_val_acc=0.7358, final_val_acc=0.7294\n",
            "LR=5e-04 (8 epochs): best_val_acc=0.7180, final_val_acc=0.6590\n",
            "LR=1e-03 (5 epochs): best_val_acc=0.7101, final_val_acc=0.6752\n",
            "\n",
            "Best LR: 1e-05 (10 epochs) with best_val_acc=0.7670\n"
          ]
        }
      ],
      "source": [
        "# Grid search over learning rates for continuous soft prompt (non-adversarial)\n",
        "# Using lower learning rates and gradient clipping to prevent collapse\n",
        "# Smaller LRs need more epochs to converge\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"GRID SEARCH: Learning Rates for Continuous Soft Prompt (Non-Adversarial)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "lr_grid = [1e-5, 5e-5, 1e-4, 5e-4, 1e-3]  # Lower range to prevent collapse\n",
        "continuous_lr_results = []\n",
        "\n",
        "for lr in lr_grid:\n",
        "    print(f\"\\n--- Testing LR = {lr} ---\")\n",
        "    # Create a temporary config with this learning rate\n",
        "    temp_cfg = ExperimentConfig()\n",
        "    temp_cfg.lr = lr\n",
        "    # Use more epochs for smaller learning rates\n",
        "    if lr <= 1e-4:\n",
        "        temp_cfg.num_epochs = 10  # More epochs for very small LRs\n",
        "    elif lr <= 5e-4:\n",
        "        temp_cfg.num_epochs = 8   # Moderate epochs for small LRs\n",
        "    else:\n",
        "        temp_cfg.num_epochs = 5   # Default for larger LRs\n",
        "    \n",
        "    result = train_continuous_soft_prompt(\n",
        "        temp_cfg, tokenizer, train_dl, val_dl, adversarial=False\n",
        "    )\n",
        "    \n",
        "    best_val_acc = max(result[\"history\"][\"val_acc\"])\n",
        "    final_val_acc = result[\"history\"][\"val_acc\"][-1]\n",
        "    continuous_lr_results.append({\n",
        "        \"lr\": lr,\n",
        "        \"num_epochs\": temp_cfg.num_epochs,\n",
        "        \"best_val_acc\": best_val_acc,\n",
        "        \"final_val_acc\": final_val_acc,\n",
        "        \"history\": result[\"history\"]\n",
        "    })\n",
        "    print(f\"LR={lr} ({temp_cfg.num_epochs} epochs): best_val_acc={best_val_acc:.4f}, final_val_acc={final_val_acc:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Learning Rate Grid Search Results:\")\n",
        "print(\"=\" * 80)\n",
        "for r in continuous_lr_results:\n",
        "    print(f\"LR={r['lr']:.0e} ({r['num_epochs']} epochs): best_val_acc={r['best_val_acc']:.4f}, final_val_acc={r['final_val_acc']:.4f}\")\n",
        "\n",
        "best_lr_result = max(continuous_lr_results, key=lambda x: x[\"best_val_acc\"])\n",
        "print(f\"\\nBest LR: {best_lr_result['lr']:.0e} ({best_lr_result['num_epochs']} epochs) with best_val_acc={best_lr_result['best_val_acc']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## lr gridsearch for adversarial prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "GRID SEARCH: Learning Rates for Continuous Soft Prompt (Non-Adversarial)\n",
            "================================================================================\n",
            "\n",
            "--- Testing LR = 1e-05 ---\n",
            "[Continuous NON-ADV] Epoch 1/10 | joint=9.4593 task=9.4593 val_loss=4.4545 val_acc=0.3783 ‖prompt‖=4.53\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Continuous NON-ADV] Epoch 2/10 | joint=5.2384 task=5.2384 val_loss=1.7574 val_acc=0.3783 ‖prompt‖=4.53\n",
            "[Continuous NON-ADV] Epoch 3/10 | joint=3.7788 task=3.7788 val_loss=0.7803 val_acc=0.3783 ‖prompt‖=4.53\n",
            "[Continuous NON-ADV] Epoch 4/10 | joint=2.8895 task=2.8895 val_loss=0.3976 val_acc=0.4581 ‖prompt‖=4.53\n",
            "[Continuous NON-ADV] Epoch 5/10 | joint=2.2292 task=2.2292 val_loss=0.2583 val_acc=0.4615 ‖prompt‖=4.53\n",
            "[Continuous NON-ADV] Epoch 6/10 | joint=1.7813 task=1.7813 val_loss=0.1996 val_acc=0.5758 ‖prompt‖=4.54\n",
            "[Continuous NON-ADV] Epoch 7/10 | joint=1.4965 task=1.4965 val_loss=0.1804 val_acc=0.6131 ‖prompt‖=4.54\n",
            "[Continuous NON-ADV] Epoch 8/10 | joint=1.2571 task=1.2571 val_loss=0.1774 val_acc=0.6162 ‖prompt‖=4.54\n",
            "[Continuous NON-ADV] Epoch 9/10 | joint=1.0867 task=1.0867 val_loss=0.1767 val_acc=0.6174 ‖prompt‖=4.54\n",
            "[Continuous NON-ADV] Epoch 10/10 | joint=0.9476 task=0.9476 val_loss=0.1860 val_acc=0.6199 ‖prompt‖=4.54\n",
            "LR=1e-05 (10 epochs): best_val_acc=0.6199, final_val_acc=0.6199\n",
            "\n",
            "--- Testing LR = 5e-05 ---\n",
            "[Continuous NON-ADV] Epoch 1/10 | joint=4.8577 task=4.8577 val_loss=0.3725 val_acc=0.3917 ‖prompt‖=4.55\n",
            "[Continuous NON-ADV] Epoch 2/10 | joint=1.5527 task=1.5527 val_loss=0.2542 val_acc=0.3783 ‖prompt‖=4.57\n",
            "[Continuous NON-ADV] Epoch 3/10 | joint=0.9073 task=0.9073 val_loss=0.2014 val_acc=0.3810 ‖prompt‖=4.58\n",
            "[Continuous NON-ADV] Epoch 4/10 | joint=0.5864 task=0.5864 val_loss=0.1723 val_acc=0.5593 ‖prompt‖=4.59\n",
            "[Continuous NON-ADV] Epoch 5/10 | joint=0.4353 task=0.4353 val_loss=0.1701 val_acc=0.5878 ‖prompt‖=4.60\n",
            "[Continuous NON-ADV] Epoch 6/10 | joint=0.3739 task=0.3739 val_loss=0.1684 val_acc=0.6180 ‖prompt‖=4.60\n",
            "[Continuous NON-ADV] Epoch 7/10 | joint=0.3400 task=0.3400 val_loss=0.1841 val_acc=0.4028 ‖prompt‖=4.61\n",
            "[Continuous NON-ADV] Epoch 8/10 | joint=0.3115 task=0.3115 val_loss=0.1683 val_acc=0.6223 ‖prompt‖=4.62\n",
            "[Continuous NON-ADV] Epoch 9/10 | joint=0.2987 task=0.2987 val_loss=0.1691 val_acc=0.5939 ‖prompt‖=4.63\n",
            "[Continuous NON-ADV] Epoch 10/10 | joint=0.2853 task=0.2853 val_loss=0.1720 val_acc=0.5557 ‖prompt‖=4.63\n",
            "LR=5e-05 (10 epochs): best_val_acc=0.6223, final_val_acc=0.5557\n",
            "\n",
            "--- Testing LR = 0.0001 ---\n",
            "[Continuous NON-ADV] Epoch 1/10 | joint=3.3394 task=3.3394 val_loss=0.1917 val_acc=0.4269 ‖prompt‖=4.61\n",
            "[Continuous NON-ADV] Epoch 2/10 | joint=0.7282 task=0.7282 val_loss=0.1799 val_acc=0.4456 ‖prompt‖=4.64\n",
            "[Continuous NON-ADV] Epoch 3/10 | joint=0.4045 task=0.4045 val_loss=0.1781 val_acc=0.6217 ‖prompt‖=4.66\n",
            "[Continuous NON-ADV] Epoch 4/10 | joint=0.3085 task=0.3085 val_loss=0.1683 val_acc=0.6220 ‖prompt‖=4.69\n",
            "[Continuous NON-ADV] Epoch 5/10 | joint=0.2729 task=0.2729 val_loss=0.1669 val_acc=0.6211 ‖prompt‖=4.71\n",
            "[Continuous NON-ADV] Epoch 6/10 | joint=0.2593 task=0.2593 val_loss=0.1754 val_acc=0.6217 ‖prompt‖=4.74\n",
            "[Continuous NON-ADV] Epoch 7/10 | joint=0.2456 task=0.2456 val_loss=0.1734 val_acc=0.6217 ‖prompt‖=4.76\n",
            "[Continuous NON-ADV] Epoch 8/10 | joint=0.2375 task=0.2375 val_loss=0.1663 val_acc=0.6214 ‖prompt‖=4.79\n",
            "[Continuous NON-ADV] Epoch 9/10 | joint=0.2339 task=0.2339 val_loss=0.1667 val_acc=0.6217 ‖prompt‖=4.81\n",
            "[Continuous NON-ADV] Epoch 10/10 | joint=0.2274 task=0.2274 val_loss=0.1680 val_acc=0.6202 ‖prompt‖=4.83\n",
            "LR=0.0001 (10 epochs): best_val_acc=0.6220, final_val_acc=0.6202\n",
            "\n",
            "--- Testing LR = 0.0005 ---\n",
            "[Continuous NON-ADV] Epoch 1/8 | joint=1.1672 task=1.1672 val_loss=0.1693 val_acc=0.6147 ‖prompt‖=5.31\n",
            "[Continuous NON-ADV] Epoch 2/8 | joint=0.2624 task=0.2624 val_loss=0.1679 val_acc=0.6217 ‖prompt‖=5.78\n",
            "[Continuous NON-ADV] Epoch 3/8 | joint=0.2317 task=0.2317 val_loss=0.1924 val_acc=0.3783 ‖prompt‖=6.21\n",
            "[Continuous NON-ADV] Epoch 4/8 | joint=0.2199 task=0.2199 val_loss=0.1674 val_acc=0.6217 ‖prompt‖=6.62\n",
            "[Continuous NON-ADV] Epoch 5/8 | joint=0.2146 task=0.2146 val_loss=0.1666 val_acc=0.6217 ‖prompt‖=6.97\n",
            "[Continuous NON-ADV] Epoch 6/8 | joint=0.2082 task=0.2082 val_loss=0.1821 val_acc=0.3789 ‖prompt‖=7.27\n",
            "[Continuous NON-ADV] Epoch 7/8 | joint=0.2066 task=0.2066 val_loss=0.1671 val_acc=0.6217 ‖prompt‖=7.57\n",
            "[Continuous NON-ADV] Epoch 8/8 | joint=0.2053 task=0.2053 val_loss=0.1683 val_acc=0.6217 ‖prompt‖=7.82\n",
            "LR=0.0005 (8 epochs): best_val_acc=0.6217, final_val_acc=0.6217\n",
            "\n",
            "--- Testing LR = 0.001 ---\n",
            "[Continuous NON-ADV] Epoch 1/5 | joint=0.9695 task=0.9695 val_loss=0.1677 val_acc=0.6217 ‖prompt‖=6.78\n",
            "[Continuous NON-ADV] Epoch 2/5 | joint=0.2501 task=0.2501 val_loss=0.1691 val_acc=0.6217 ‖prompt‖=8.06\n",
            "[Continuous NON-ADV] Epoch 3/5 | joint=0.2265 task=0.2265 val_loss=0.1682 val_acc=0.6217 ‖prompt‖=9.00\n",
            "[Continuous NON-ADV] Epoch 4/5 | joint=0.2168 task=0.2168 val_loss=0.1673 val_acc=0.6217 ‖prompt‖=9.78\n",
            "[Continuous NON-ADV] Epoch 5/5 | joint=0.2109 task=0.2109 val_loss=0.1669 val_acc=0.6217 ‖prompt‖=10.50\n",
            "LR=0.001 (5 epochs): best_val_acc=0.6217, final_val_acc=0.6217\n",
            "\n",
            "================================================================================\n",
            "Learning Rate Grid Search Results:\n",
            "================================================================================\n",
            "LR=1e-05 (10 epochs): best_val_acc=0.6199, final_val_acc=0.6199\n",
            "LR=5e-05 (10 epochs): best_val_acc=0.6223, final_val_acc=0.5557\n",
            "LR=1e-04 (10 epochs): best_val_acc=0.6220, final_val_acc=0.6202\n",
            "LR=5e-04 (8 epochs): best_val_acc=0.6217, final_val_acc=0.6217\n",
            "LR=1e-03 (5 epochs): best_val_acc=0.6217, final_val_acc=0.6217\n",
            "\n",
            "Best LR: 5e-05 (10 epochs) with best_val_acc=0.6223\n"
          ]
        }
      ],
      "source": [
        "# Grid search over learning rates for continuous soft prompt (adversarial)\n",
        "# Using lower learning rates and gradient clipping to prevent collapse\n",
        "# Smaller LRs need more epochs to converge\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"GRID SEARCH: Learning Rates for Continuous Soft Prompt (Adversarial)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "lr_grid = [1e-5, 5e-5, 1e-4, 5e-4, 1e-3]  # Lower range to prevent collapse\n",
        "continuous_lr_results_adv = []\n",
        "\n",
        "for lr in lr_grid:\n",
        "    print(f\"\\n--- Testing LR = {lr} ---\")\n",
        "    # Create a temporary config with this learning rate\n",
        "    temp_cfg = ExperimentConfig()\n",
        "    temp_cfg.lr = lr\n",
        "    # Use more epochs for smaller learning rates\n",
        "    if lr <= 1e-4:\n",
        "        temp_cfg.num_epochs = 10  # More epochs for very small LRs\n",
        "    elif lr <= 5e-4:\n",
        "        temp_cfg.num_epochs = 8   # Moderate epochs for small LRs\n",
        "    else:\n",
        "        temp_cfg.num_epochs = 5   # Default for larger LRs\n",
        "    \n",
        "    result = train_continuous_soft_prompt(\n",
        "        temp_cfg, tokenizer, train_dl, val_dl, adversarial=True\n",
        "    )\n",
        "    \n",
        "    best_val_acc = max(result[\"history\"][\"val_acc\"])\n",
        "    final_val_acc = result[\"history\"][\"val_acc\"][-1]\n",
        "    best_val_acc_true = max(result[\"history\"][\"val_acc_true\"])\n",
        "    best_val_acc_false = max(result[\"history\"][\"val_acc_false\"])\n",
        "    continuous_lr_results_adv.append({\n",
        "        \"lr\": lr,\n",
        "        \"num_epochs\": temp_cfg.num_epochs,\n",
        "        \"best_val_acc\": best_val_acc,\n",
        "        \"final_val_acc\": final_val_acc,\n",
        "        \"best_val_acc_true\": best_val_acc_true,\n",
        "        \"best_val_acc_false\": best_val_acc_false,\n",
        "        \"history\": result[\"history\"]\n",
        "    })\n",
        "    print(\n",
        "        f\"LR={lr} ({temp_cfg.num_epochs} epochs): \"\n",
        "        f\"final_val_acc={final_val_acc:.4f} \"\n",
        "        f\"(true={best_val_acc_true:.4f}, false={best_val_acc_false:.4f})\"\n",
        "    )\n",
        "\n",
        "import json, os\n",
        "\n",
        "save_path = \"/mnt/polished-lake/home/annabelma/other/results/unbalanced/continuous/continuous_lr_results_adv.json\"\n",
        "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "with open(save_path, \"w\") as f:\n",
        "    json.dump(continuous_lr_results_adv, f, indent=2)\n",
        "\n",
        "print(\"Saved to\", save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grid search: Prompt Length for Continuous Soft Prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "GRID SEARCH: Prompt Lengths for Continuous Soft Prompt (Non-Adversarial)\n",
            "================================================================================\n",
            "\n",
            "--- Testing Prompt Length = 1 ---\n",
            "[Continuous NON-ADV] Epoch 1/20 | joint=14.0087 task=14.0087 val_loss=13.0611 val_acc=0.5453 (true=0.2996 false=0.9491) ‖prompt‖=0.62\n",
            "[Continuous NON-ADV] Epoch 2/20 | joint=12.8482 task=12.8482 val_loss=12.6606 val_acc=0.4391 (true=0.1176 false=0.9677) ‖prompt‖=0.62\n",
            "[Continuous NON-ADV] Epoch 3/20 | joint=12.9251 task=12.9251 val_loss=11.8554 val_acc=0.4404 (true=0.1230 false=0.9620) ‖prompt‖=0.63\n",
            "[Continuous NON-ADV] Epoch 4/20 | joint=12.4211 task=12.4211 val_loss=11.7748 val_acc=0.4453 (true=0.1426 false=0.9426) ‖prompt‖=0.63\n",
            "[Continuous NON-ADV] Epoch 5/20 | joint=12.2375 task=12.2375 val_loss=11.7048 val_acc=0.4541 (true=0.1628 false=0.9329) ‖prompt‖=0.64\n",
            "[Continuous NON-ADV] Epoch 6/20 | joint=12.1681 task=12.1681 val_loss=11.6180 val_acc=0.4670 (true=0.1923 false=0.9184) ‖prompt‖=0.64\n",
            "[Continuous NON-ADV] Epoch 7/20 | joint=12.0431 task=12.0431 val_loss=11.5927 val_acc=0.4737 (true=0.2081 false=0.9103) ‖prompt‖=0.65\n",
            "[Continuous NON-ADV] Epoch 8/20 | joint=12.0388 task=12.0388 val_loss=11.5339 val_acc=0.4789 (true=0.2184 false=0.9070) ‖prompt‖=0.65\n",
            "[Continuous NON-ADV] Epoch 9/20 | joint=12.0646 task=12.0646 val_loss=11.4764 val_acc=0.4841 (true=0.2248 false=0.9103) ‖prompt‖=0.65\n",
            "[Continuous NON-ADV] Epoch 10/20 | joint=12.0165 task=12.0165 val_loss=11.4386 val_acc=0.4865 (true=0.2253 false=0.9159) ‖prompt‖=0.65\n",
            "[Continuous NON-ADV] Epoch 11/20 | joint=11.9692 task=11.9692 val_loss=11.4066 val_acc=0.4905 (true=0.2336 false=0.9127) ‖prompt‖=0.66\n",
            "[Continuous NON-ADV] Epoch 12/20 | joint=12.0101 task=12.0101 val_loss=11.3791 val_acc=0.4985 (true=0.2455 false=0.9143) ‖prompt‖=0.66\n",
            "[Continuous NON-ADV] Epoch 13/20 | joint=12.0400 task=12.0400 val_loss=11.3833 val_acc=0.5018 (true=0.2548 false=0.9078) ‖prompt‖=0.66\n",
            "[Continuous NON-ADV] Epoch 14/20 | joint=11.9511 task=11.9511 val_loss=11.3672 val_acc=0.5064 (true=0.2582 false=0.9143) ‖prompt‖=0.67\n",
            "[Continuous NON-ADV] Epoch 15/20 | joint=11.9230 task=11.9230 val_loss=11.3311 val_acc=0.5122 (true=0.2666 false=0.9159) ‖prompt‖=0.67\n",
            "[Continuous NON-ADV] Epoch 16/20 | joint=11.9579 task=11.9579 val_loss=11.3593 val_acc=0.5180 (true=0.2789 false=0.9111) ‖prompt‖=0.67\n",
            "[Continuous NON-ADV] Epoch 17/20 | joint=11.9649 task=11.9649 val_loss=11.3576 val_acc=0.5220 (true=0.2863 false=0.9095) ‖prompt‖=0.68\n",
            "[Continuous NON-ADV] Epoch 18/20 | joint=11.9194 task=11.9194 val_loss=11.3487 val_acc=0.5339 (true=0.3050 false=0.9103) ‖prompt‖=0.68\n",
            "[Continuous NON-ADV] Epoch 19/20 | joint=11.9231 task=11.9231 val_loss=11.2990 val_acc=0.5367 (true=0.3153 false=0.9006) ‖prompt‖=0.68\n",
            "[Continuous NON-ADV] Epoch 20/20 | joint=11.9674 task=11.9674 val_loss=11.3189 val_acc=0.5437 (true=0.3187 false=0.9135) ‖prompt‖=0.69\n",
            "Prompt Length=1: best_val_acc=0.5453, final_val_acc=0.5437 (true=0.3187, false=0.9677) ‖prompt‖=0.69\n",
            "\n",
            "--- Testing Prompt Length = 5 ---\n",
            "[Continuous NON-ADV] Epoch 1/20 | joint=14.1782 task=14.1782 val_loss=12.8634 val_acc=0.4694 (true=0.1594 false=0.9790) ‖prompt‖=1.44\n",
            "[Continuous NON-ADV] Epoch 2/20 | joint=12.5851 task=12.5851 val_loss=11.9888 val_acc=0.4425 (true=0.1151 false=0.9806) ‖prompt‖=1.44\n",
            "[Continuous NON-ADV] Epoch 3/20 | joint=11.6519 task=11.6519 val_loss=9.4951 val_acc=0.4303 (true=0.0939 false=0.9830) ‖prompt‖=1.45\n",
            "[Continuous NON-ADV] Epoch 4/20 | joint=10.3629 task=10.3629 val_loss=8.2442 val_acc=0.5080 (true=0.2538 false=0.9256) ‖prompt‖=1.46\n",
            "[Continuous NON-ADV] Epoch 5/20 | joint=9.6565 task=9.6565 val_loss=7.1032 val_acc=0.7202 (true=0.8298 false=0.5400) ‖prompt‖=1.47\n",
            "[Continuous NON-ADV] Epoch 6/20 | joint=9.1754 task=9.1754 val_loss=6.6421 val_acc=0.7177 (true=0.8992 false=0.4196) ‖prompt‖=1.48\n",
            "[Continuous NON-ADV] Epoch 7/20 | joint=8.8315 task=8.8315 val_loss=6.2382 val_acc=0.6948 (true=0.9597 false=0.2595) ‖prompt‖=1.49\n",
            "[Continuous NON-ADV] Epoch 8/20 | joint=8.6392 task=8.6392 val_loss=6.1687 val_acc=0.6933 (true=0.9518 false=0.2684) ‖prompt‖=1.50\n",
            "[Continuous NON-ADV] Epoch 9/20 | joint=8.4022 task=8.4022 val_loss=5.4217 val_acc=0.7138 (true=0.9065 false=0.3969) ‖prompt‖=1.52\n",
            "[Continuous NON-ADV] Epoch 10/20 | joint=7.9435 task=7.9435 val_loss=4.6596 val_acc=0.7165 (true=0.8618 false=0.4778) ‖prompt‖=1.52\n",
            "[Continuous NON-ADV] Epoch 11/20 | joint=7.6612 task=7.6612 val_loss=4.2563 val_acc=0.7076 (true=0.8082 false=0.5424) ‖prompt‖=1.53\n",
            "[Continuous NON-ADV] Epoch 12/20 | joint=7.4478 task=7.4478 val_loss=4.0052 val_acc=0.7076 (true=0.7506 false=0.6370) ‖prompt‖=1.54\n",
            "[Continuous NON-ADV] Epoch 13/20 | joint=7.3279 task=7.3279 val_loss=3.7673 val_acc=0.6633 (true=0.6222 false=0.7308) ‖prompt‖=1.55\n",
            "[Continuous NON-ADV] Epoch 14/20 | joint=7.1538 task=7.1538 val_loss=3.4340 val_acc=0.7150 (true=0.7944 false=0.5845) ‖prompt‖=1.56\n",
            "[Continuous NON-ADV] Epoch 15/20 | joint=6.9939 task=6.9939 val_loss=3.1933 val_acc=0.7086 (true=0.8106 false=0.5408) ‖prompt‖=1.57\n",
            "[Continuous NON-ADV] Epoch 16/20 | joint=6.8725 task=6.8725 val_loss=2.9704 val_acc=0.7064 (true=0.8318 false=0.5004) ‖prompt‖=1.58\n",
            "[Continuous NON-ADV] Epoch 17/20 | joint=6.7346 task=6.7346 val_loss=2.8132 val_acc=0.7021 (true=0.8844 false=0.4026) ‖prompt‖=1.59\n",
            "[Continuous NON-ADV] Epoch 18/20 | joint=6.6184 task=6.6184 val_loss=2.5388 val_acc=0.6991 (true=0.9390 false=0.3048) ‖prompt‖=1.60\n",
            "[Continuous NON-ADV] Epoch 19/20 | joint=6.5275 task=6.5275 val_loss=2.2499 val_acc=0.6875 (true=0.9646 false=0.2320) ‖prompt‖=1.61\n",
            "[Continuous NON-ADV] Epoch 20/20 | joint=6.4435 task=6.4435 val_loss=2.1260 val_acc=0.6893 (true=0.9454 false=0.2684) ‖prompt‖=1.62\n",
            "Prompt Length=5: best_val_acc=0.7202, final_val_acc=0.6893 (true=0.9646, false=0.9830) ‖prompt‖=1.62\n",
            "\n",
            "--- Testing Prompt Length = 10 ---\n",
            "[Continuous NON-ADV] Epoch 1/20 | joint=14.1930 task=14.1930 val_loss=12.7114 val_acc=0.6156 (true=0.4255 false=0.9281) ‖prompt‖=2.05\n",
            "[Continuous NON-ADV] Epoch 2/20 | joint=11.5690 task=11.5690 val_loss=8.8318 val_acc=0.4343 (true=0.0994 false=0.9846) ‖prompt‖=2.06\n",
            "[Continuous NON-ADV] Epoch 3/20 | joint=8.5767 task=8.5767 val_loss=4.5701 val_acc=0.6835 (true=0.8485 false=0.4123) ‖prompt‖=2.08\n",
            "[Continuous NON-ADV] Epoch 4/20 | joint=6.1209 task=6.1209 val_loss=1.0857 val_acc=0.6459 (true=0.9941 false=0.0736) ‖prompt‖=2.10\n",
            "[Continuous NON-ADV] Epoch 5/20 | joint=4.5457 task=4.5457 val_loss=0.7635 val_acc=0.6361 (true=0.9980 false=0.0412) ‖prompt‖=2.12\n",
            "[Continuous NON-ADV] Epoch 6/20 | joint=3.6730 task=3.6730 val_loss=0.7345 val_acc=0.6309 (true=0.9980 false=0.0275) ‖prompt‖=2.13\n",
            "[Continuous NON-ADV] Epoch 7/20 | joint=3.1858 task=3.1858 val_loss=0.6230 val_acc=0.6312 (true=0.9990 false=0.0267) ‖prompt‖=2.15\n",
            "[Continuous NON-ADV] Epoch 8/20 | joint=2.8136 task=2.8136 val_loss=0.5146 val_acc=0.6327 (true=0.9990 false=0.0307) ‖prompt‖=2.16\n",
            "[Continuous NON-ADV] Epoch 9/20 | joint=2.5440 task=2.5440 val_loss=0.6301 val_acc=0.6291 (true=0.9995 false=0.0202) ‖prompt‖=2.18\n",
            "[Continuous NON-ADV] Epoch 10/20 | joint=2.3338 task=2.3338 val_loss=0.4495 val_acc=0.6336 (true=0.9970 false=0.0364) ‖prompt‖=2.19\n",
            "[Continuous NON-ADV] Epoch 11/20 | joint=2.1589 task=2.1589 val_loss=0.5178 val_acc=0.6346 (true=0.9966 false=0.0396) ‖prompt‖=2.21\n",
            "[Continuous NON-ADV] Epoch 12/20 | joint=2.0287 task=2.0287 val_loss=0.3899 val_acc=0.6346 (true=0.9990 false=0.0356) ‖prompt‖=2.22\n",
            "[Continuous NON-ADV] Epoch 13/20 | joint=1.8831 task=1.8831 val_loss=0.4148 val_acc=0.6416 (true=0.9961 false=0.0590) ‖prompt‖=2.24\n",
            "[Continuous NON-ADV] Epoch 14/20 | joint=1.8079 task=1.8079 val_loss=0.3379 val_acc=0.6443 (true=0.9970 false=0.0647) ‖prompt‖=2.25\n",
            "[Continuous NON-ADV] Epoch 15/20 | joint=1.7020 task=1.7020 val_loss=0.3380 val_acc=0.6440 (true=0.9936 false=0.0695) ‖prompt‖=2.26\n",
            "[Continuous NON-ADV] Epoch 16/20 | joint=1.6618 task=1.6618 val_loss=0.4084 val_acc=0.6315 (true=0.9975 false=0.0299) ‖prompt‖=2.27\n",
            "[Continuous NON-ADV] Epoch 17/20 | joint=1.5501 task=1.5501 val_loss=0.2759 val_acc=0.6373 (true=0.9966 false=0.0469) ‖prompt‖=2.29\n",
            "[Continuous NON-ADV] Epoch 18/20 | joint=1.4507 task=1.4507 val_loss=0.2212 val_acc=0.6361 (true=0.9921 false=0.0509) ‖prompt‖=2.30\n",
            "[Continuous NON-ADV] Epoch 19/20 | joint=1.3905 task=1.3905 val_loss=0.2188 val_acc=0.6333 (true=0.9931 false=0.0420) ‖prompt‖=2.31\n",
            "[Continuous NON-ADV] Epoch 20/20 | joint=1.3137 task=1.3137 val_loss=0.2277 val_acc=0.6272 (true=0.9951 false=0.0226) ‖prompt‖=2.32\n",
            "Prompt Length=10: best_val_acc=0.6835, final_val_acc=0.6272 (true=0.9995, false=0.9846) ‖prompt‖=2.32\n",
            "\n",
            "--- Testing Prompt Length = 20 ---\n",
            "[Continuous NON-ADV] Epoch 1/20 | joint=13.6464 task=13.6464 val_loss=11.0678 val_acc=0.4165 (true=0.0694 false=0.9871) ‖prompt‖=2.91\n",
            "[Continuous NON-ADV] Epoch 2/20 | joint=11.0209 task=11.0209 val_loss=9.3916 val_acc=0.4101 (true=0.0561 false=0.9919) ‖prompt‖=2.93\n",
            "[Continuous NON-ADV] Epoch 3/20 | joint=9.4700 task=9.4700 val_loss=6.1483 val_acc=0.4930 (true=0.2228 false=0.9369) ‖prompt‖=2.94\n",
            "[Continuous NON-ADV] Epoch 4/20 | joint=6.8606 task=6.8606 val_loss=2.0265 val_acc=0.7202 (true=0.8273 false=0.5441) ‖prompt‖=2.96\n",
            "[Continuous NON-ADV] Epoch 5/20 | joint=4.4058 task=4.4058 val_loss=0.3557 val_acc=0.7015 (true=0.9439 false=0.3032) ‖prompt‖=2.98\n",
            "[Continuous NON-ADV] Epoch 6/20 | joint=2.8578 task=2.8578 val_loss=0.2466 val_acc=0.6532 (true=0.9980 false=0.0865) ‖prompt‖=3.00\n",
            "[Continuous NON-ADV] Epoch 7/20 | joint=2.0049 task=2.0049 val_loss=0.2027 val_acc=0.6664 (true=0.9887 false=0.1366) ‖prompt‖=3.02\n",
            "[Continuous NON-ADV] Epoch 8/20 | joint=1.5037 task=1.5037 val_loss=0.2076 val_acc=0.6697 (true=0.9882 false=0.1463) ‖prompt‖=3.04\n",
            "[Continuous NON-ADV] Epoch 9/20 | joint=1.2061 task=1.2061 val_loss=0.2297 val_acc=0.6636 (true=0.9892 false=0.1285) ‖prompt‖=3.06\n",
            "[Continuous NON-ADV] Epoch 10/20 | joint=0.9901 task=0.9901 val_loss=0.2491 val_acc=0.6535 (true=0.9966 false=0.0897) ‖prompt‖=3.08\n",
            "[Continuous NON-ADV] Epoch 11/20 | joint=0.8167 task=0.8167 val_loss=0.2599 val_acc=0.6425 (true=0.9990 false=0.0566) ‖prompt‖=3.10\n",
            "[Continuous NON-ADV] Epoch 12/20 | joint=0.7021 task=0.7021 val_loss=0.2399 val_acc=0.6401 (true=0.9990 false=0.0501) ‖prompt‖=3.12\n",
            "[Continuous NON-ADV] Epoch 13/20 | joint=0.6191 task=0.6191 val_loss=0.2191 val_acc=0.6474 (true=0.9980 false=0.0711) ‖prompt‖=3.13\n",
            "[Continuous NON-ADV] Epoch 14/20 | joint=0.5533 task=0.5533 val_loss=0.2183 val_acc=0.6456 (true=0.9985 false=0.0655) ‖prompt‖=3.15\n",
            "[Continuous NON-ADV] Epoch 15/20 | joint=0.5172 task=0.5172 val_loss=0.2060 val_acc=0.6446 (true=0.9980 false=0.0639) ‖prompt‖=3.17\n",
            "[Continuous NON-ADV] Epoch 16/20 | joint=0.4852 task=0.4852 val_loss=0.2260 val_acc=0.6367 (true=0.9985 false=0.0420) ‖prompt‖=3.18\n",
            "[Continuous NON-ADV] Epoch 17/20 | joint=0.4538 task=0.4538 val_loss=0.1755 val_acc=0.6612 (true=0.9921 false=0.1172) ‖prompt‖=3.20\n",
            "[Continuous NON-ADV] Epoch 18/20 | joint=0.4352 task=0.4352 val_loss=0.2145 val_acc=0.6425 (true=0.9975 false=0.0590) ‖prompt‖=3.22\n",
            "[Continuous NON-ADV] Epoch 19/20 | joint=0.4126 task=0.4126 val_loss=0.2331 val_acc=0.6382 (true=0.9995 false=0.0445) ‖prompt‖=3.23\n",
            "[Continuous NON-ADV] Epoch 20/20 | joint=0.4000 task=0.4000 val_loss=0.1899 val_acc=0.6508 (true=0.9961 false=0.0833) ‖prompt‖=3.25\n",
            "Prompt Length=20: best_val_acc=0.7202, final_val_acc=0.6508 (true=0.9995, false=0.9919) ‖prompt‖=3.25\n",
            "\n",
            "--- Testing Prompt Length = 50 ---\n",
            "[Continuous NON-ADV] Epoch 1/20 | joint=11.6119 task=11.6119 val_loss=8.9597 val_acc=0.4128 (true=0.0831 false=0.9547) ‖prompt‖=4.54\n",
            "[Continuous NON-ADV] Epoch 2/20 | joint=8.3156 task=8.3156 val_loss=3.2738 val_acc=0.4581 (true=0.1722 false=0.9281) ‖prompt‖=4.57\n",
            "[Continuous NON-ADV] Epoch 3/20 | joint=5.0795 task=5.0795 val_loss=1.1905 val_acc=0.6569 (true=0.6301 false=0.7009) ‖prompt‖=4.59\n",
            "[Continuous NON-ADV] Epoch 4/20 | joint=2.8675 task=2.8675 val_loss=0.2756 val_acc=0.6495 (true=0.6340 false=0.6750) ‖prompt‖=4.62\n",
            "[Continuous NON-ADV] Epoch 5/20 | joint=1.4297 task=1.4297 val_loss=0.1616 val_acc=0.6914 (true=0.9562 false=0.2563) ‖prompt‖=4.65\n",
            "[Continuous NON-ADV] Epoch 6/20 | joint=0.8649 task=0.8649 val_loss=0.1847 val_acc=0.6599 (true=0.9936 false=0.1116) ‖prompt‖=4.68\n",
            "[Continuous NON-ADV] Epoch 7/20 | joint=0.6355 task=0.6355 val_loss=0.1790 val_acc=0.6606 (true=0.9921 false=0.1156) ‖prompt‖=4.71\n",
            "[Continuous NON-ADV] Epoch 8/20 | joint=0.5170 task=0.5170 val_loss=0.1495 val_acc=0.6936 (true=0.9739 false=0.2328) ‖prompt‖=4.74\n",
            "[Continuous NON-ADV] Epoch 9/20 | joint=0.4442 task=0.4442 val_loss=0.1548 val_acc=0.6838 (true=0.9808 false=0.1956) ‖prompt‖=4.77\n",
            "[Continuous NON-ADV] Epoch 10/20 | joint=0.4052 task=0.4052 val_loss=0.1514 val_acc=0.6942 (true=0.9803 false=0.2239) ‖prompt‖=4.79\n",
            "[Continuous NON-ADV] Epoch 11/20 | joint=0.3779 task=0.3779 val_loss=0.1387 val_acc=0.7128 (true=0.9533 false=0.3177) ‖prompt‖=4.82\n",
            "[Continuous NON-ADV] Epoch 12/20 | joint=0.3575 task=0.3575 val_loss=0.1569 val_acc=0.6899 (true=0.9877 false=0.2005) ‖prompt‖=4.85\n",
            "[Continuous NON-ADV] Epoch 13/20 | joint=0.3358 task=0.3358 val_loss=0.1365 val_acc=0.7245 (true=0.9572 false=0.3420) ‖prompt‖=4.88\n",
            "[Continuous NON-ADV] Epoch 14/20 | joint=0.3167 task=0.3167 val_loss=0.1343 val_acc=0.7284 (true=0.9513 false=0.3622) ‖prompt‖=4.91\n",
            "[Continuous NON-ADV] Epoch 15/20 | joint=0.3033 task=0.3033 val_loss=0.1305 val_acc=0.7422 (true=0.9346 false=0.4260) ‖prompt‖=4.93\n",
            "[Continuous NON-ADV] Epoch 16/20 | joint=0.2835 task=0.2835 val_loss=0.1374 val_acc=0.7159 (true=0.9666 false=0.3040) ‖prompt‖=4.96\n",
            "[Continuous NON-ADV] Epoch 17/20 | joint=0.2846 task=0.2846 val_loss=0.1364 val_acc=0.7183 (true=0.9661 false=0.3112) ‖prompt‖=4.99\n",
            "[Continuous NON-ADV] Epoch 18/20 | joint=0.2726 task=0.2726 val_loss=0.1453 val_acc=0.7089 (true=0.9754 false=0.2708) ‖prompt‖=5.01\n",
            "[Continuous NON-ADV] Epoch 19/20 | joint=0.2607 task=0.2607 val_loss=0.1316 val_acc=0.7382 (true=0.9454 false=0.3977) ‖prompt‖=5.04\n",
            "[Continuous NON-ADV] Epoch 20/20 | joint=0.2597 task=0.2597 val_loss=0.1358 val_acc=0.7306 (true=0.9572 false=0.3581) ‖prompt‖=5.07\n",
            "Prompt Length=50: best_val_acc=0.7422, final_val_acc=0.7306 (true=0.9936, false=0.9547) ‖prompt‖=5.07\n",
            "\n",
            "--- Testing Prompt Length = 100 ---\n",
            "[Continuous NON-ADV] Epoch 1/20 | joint=10.6974 task=10.6974 val_loss=7.4069 val_acc=0.4477 (true=0.1751 false=0.8957) ‖prompt‖=6.47\n",
            "[Continuous NON-ADV] Epoch 2/20 | joint=6.5995 task=6.5995 val_loss=0.8945 val_acc=0.5095 (true=0.3733 false=0.7332) ‖prompt‖=6.51\n",
            "[Continuous NON-ADV] Epoch 3/20 | joint=2.2449 task=2.2449 val_loss=0.1888 val_acc=0.6248 (true=0.9970 false=0.0129) ‖prompt‖=6.55\n",
            "[Continuous NON-ADV] Epoch 4/20 | joint=0.9274 task=0.9274 val_loss=0.2373 val_acc=0.6220 (true=0.9990 false=0.0024) ‖prompt‖=6.59\n",
            "[Continuous NON-ADV] Epoch 5/20 | joint=0.4854 task=0.4854 val_loss=0.2043 val_acc=0.6266 (true=0.9990 false=0.0146) ‖prompt‖=6.63\n",
            "[Continuous NON-ADV] Epoch 6/20 | joint=0.3573 task=0.3573 val_loss=0.1828 val_acc=0.6242 (true=0.9975 false=0.0105) ‖prompt‖=6.67\n",
            "[Continuous NON-ADV] Epoch 7/20 | joint=0.2961 task=0.2961 val_loss=0.1688 val_acc=0.6373 (true=0.9926 false=0.0534) ‖prompt‖=6.71\n",
            "[Continuous NON-ADV] Epoch 8/20 | joint=0.2677 task=0.2677 val_loss=0.1605 val_acc=0.6450 (true=0.9818 false=0.0914) ‖prompt‖=6.74\n",
            "[Continuous NON-ADV] Epoch 9/20 | joint=0.2495 task=0.2495 val_loss=0.1614 val_acc=0.6437 (true=0.9970 false=0.0631) ‖prompt‖=6.79\n",
            "[Continuous NON-ADV] Epoch 10/20 | joint=0.2321 task=0.2321 val_loss=0.1606 val_acc=0.6413 (true=0.9985 false=0.0542) ‖prompt‖=6.83\n",
            "[Continuous NON-ADV] Epoch 11/20 | joint=0.2257 task=0.2257 val_loss=0.1601 val_acc=0.6404 (true=0.9975 false=0.0534) ‖prompt‖=6.86\n",
            "[Continuous NON-ADV] Epoch 12/20 | joint=0.2218 task=0.2218 val_loss=0.1526 val_acc=0.6920 (true=0.9661 false=0.2417) ‖prompt‖=6.90\n",
            "[Continuous NON-ADV] Epoch 13/20 | joint=0.2108 task=0.2108 val_loss=0.1494 val_acc=0.6997 (true=0.9675 false=0.2595) ‖prompt‖=6.94\n",
            "[Continuous NON-ADV] Epoch 14/20 | joint=0.2104 task=0.2104 val_loss=0.1417 val_acc=0.7339 (true=0.8962 false=0.4673) ‖prompt‖=6.98\n",
            "[Continuous NON-ADV] Epoch 15/20 | joint=0.2063 task=0.2063 val_loss=0.1469 val_acc=0.7385 (true=0.8308 false=0.5869) ‖prompt‖=7.02\n",
            "[Continuous NON-ADV] Epoch 16/20 | joint=0.2030 task=0.2030 val_loss=0.1366 val_acc=0.7358 (true=0.9262 false=0.4228) ‖prompt‖=7.06\n",
            "[Continuous NON-ADV] Epoch 17/20 | joint=0.1955 task=0.1955 val_loss=0.1377 val_acc=0.7602 (true=0.8269 false=0.6508) ‖prompt‖=7.09\n",
            "[Continuous NON-ADV] Epoch 18/20 | joint=0.1946 task=0.1946 val_loss=0.1302 val_acc=0.7425 (true=0.9602 false=0.3848) ‖prompt‖=7.13\n",
            "[Continuous NON-ADV] Epoch 19/20 | joint=0.1941 task=0.1941 val_loss=0.1272 val_acc=0.7719 (true=0.8815 false=0.5918) ‖prompt‖=7.17\n",
            "[Continuous NON-ADV] Epoch 20/20 | joint=0.1884 task=0.1884 val_loss=0.1247 val_acc=0.7734 (true=0.8938 false=0.5756) ‖prompt‖=7.21\n",
            "Prompt Length=100: best_val_acc=0.7734, final_val_acc=0.7734 (true=0.9990, false=0.8957) ‖prompt‖=7.21\n",
            "\n",
            "================================================================================\n",
            "Prompt Length Grid Search Results:\n",
            "================================================================================\n",
            "Length=  1: best_val_acc=0.5453, final_val_acc=0.5437 (true=0.3187, false=0.9677) ‖prompt‖=0.69\n",
            "Length=  5: best_val_acc=0.7202, final_val_acc=0.6893 (true=0.9646, false=0.9830) ‖prompt‖=1.62\n",
            "Length= 10: best_val_acc=0.6835, final_val_acc=0.6272 (true=0.9995, false=0.9846) ‖prompt‖=2.32\n",
            "Length= 20: best_val_acc=0.7202, final_val_acc=0.6508 (true=0.9995, false=0.9919) ‖prompt‖=3.25\n",
            "Length= 50: best_val_acc=0.7422, final_val_acc=0.7306 (true=0.9936, false=0.9547) ‖prompt‖=5.07\n",
            "Length=100: best_val_acc=0.7734, final_val_acc=0.7734 (true=0.9990, false=0.8957) ‖prompt‖=7.21\n",
            "\n",
            "Best Prompt Length: 100\n",
            "  best_val_acc=0.7734, final_val_acc=0.7734\n",
            "  true_acc=0.9990, false_acc=0.8957\n"
          ]
        }
      ],
      "source": [
        "# Grid search over prompt lengths for continuous soft prompt (non-adversarial)\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"GRID SEARCH: Prompt Lengths for Continuous Soft Prompt (Non-Adversarial)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "prompt_length_grid = [1, 5, 10, 20, 50, 100]\n",
        "prompt_length_results = []\n",
        "\n",
        "for prompt_len in prompt_length_grid:\n",
        "    print(f\"\\n--- Testing Prompt Length = {prompt_len} ---\")\n",
        "    # Create a temporary config with this prompt length\n",
        "    temp_cfg = ExperimentConfig()\n",
        "    temp_cfg.prompt_length = prompt_len\n",
        "    # Use a reasonable learning rate (from previous grid search, 5e-5 was good)\n",
        "    temp_cfg.lr = 1e-4\n",
        "    temp_cfg.num_epochs = 20  # Use enough epochs to see convergence\n",
        "    \n",
        "    result = train_continuous_soft_prompt(\n",
        "        temp_cfg, tokenizer, train_dl, val_dl, adversarial=False\n",
        "    )\n",
        "    \n",
        "    best_val_acc = max(result[\"history\"][\"val_acc\"])\n",
        "    final_val_acc = result[\"history\"][\"val_acc\"][-1]\n",
        "    best_val_acc_true = max(result[\"history\"][\"val_acc_true\"])\n",
        "    best_val_acc_false = max(result[\"history\"][\"val_acc_false\"])\n",
        "    final_prompt_norm = result[\"history\"][\"prompt_norm\"][-1]\n",
        "    \n",
        "    prompt_length_results.append({\n",
        "        \"prompt_length\": prompt_len,\n",
        "        \"best_val_acc\": best_val_acc,\n",
        "        \"final_val_acc\": final_val_acc,\n",
        "        \"best_val_acc_true\": best_val_acc_true,\n",
        "        \"best_val_acc_false\": best_val_acc_false,\n",
        "        \"final_prompt_norm\": final_prompt_norm,\n",
        "        \"history\": result[\"history\"]\n",
        "    })\n",
        "    print(\n",
        "        f\"Prompt Length={prompt_len}: \"\n",
        "        f\"best_val_acc={best_val_acc:.4f}, final_val_acc={final_val_acc:.4f} \"\n",
        "        f\"(true={best_val_acc_true:.4f}, false={best_val_acc_false:.4f}) \"\n",
        "        f\"‖prompt‖={final_prompt_norm:.2f}\"\n",
        "    )\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Prompt Length Grid Search Results:\")\n",
        "print(\"=\" * 80)\n",
        "for r in prompt_length_results:\n",
        "    print(\n",
        "        f\"Length={r['prompt_length']:3d}: \"\n",
        "        f\"best_val_acc={r['best_val_acc']:.4f}, final_val_acc={r['final_val_acc']:.4f} \"\n",
        "        f\"(true={r['best_val_acc_true']:.4f}, false={r['best_val_acc_false']:.4f}) \"\n",
        "        f\"‖prompt‖={r['final_prompt_norm']:.2f}\"\n",
        "    )\n",
        "\n",
        "best_prompt_length_result = max(prompt_length_results, key=lambda x: x[\"best_val_acc\"])\n",
        "print(f\"\\nBest Prompt Length: {best_prompt_length_result['prompt_length']}\")\n",
        "print(f\"  best_val_acc={best_prompt_length_result['best_val_acc']:.4f}, final_val_acc={best_prompt_length_result['final_val_acc']:.4f}\")\n",
        "print(f\"  true_acc={best_prompt_length_result['best_val_acc_true']:.4f}, false_acc={best_prompt_length_result['best_val_acc_false']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'prompt_length_results' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(save_path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(save_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 8\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(\u001b[43mprompt_length_results\u001b[49m, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'prompt_length_results' is not defined"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "save_path = \"/mnt/polished-lake/home/annabelma/other/results/unbalanced/continuous/prompt_length_non_adv1e-4.json\"\n",
        "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "with open(save_path, \"w\") as f:\n",
        "    json.dump(prompt_length_results, f, indent=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU1Ebf5JTJBJ"
      },
      "source": [
        "## gpt2 for prompt perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "b6cea69db3f948d4a87de89ba2219766",
            "a7b84fbc86d549d2b2d920b6e3e3f0e5",
            "80cd3377e1114fc0a2867d7ddfc139b1",
            "d58c3b603b5a4da3a3a7d9ebf688da03",
            "20243da2ac294c3aacaf5d772e3949b4",
            "1770a56348fd46faa7dda98fd6e469a1",
            "8d015465f6ef45a3a2523436c980115c",
            "5d25e89862664bdf9da8514b83074871",
            "470fc6596292403eb23f95be83990ca4",
            "b264639e6ab844b2b9e82a12d4d416aa",
            "e59b649c3ab24a4c8eee1a467f43bd87",
            "14da7a720d9149bebc10df04372e1e1a",
            "9d7599aa26904213bd54da21678646a4",
            "34377ca0f40c40c79dc38262f42acc16",
            "71556d7b286c4276a13f1b2d59e38c90",
            "e0855a8f0f544de2bd5bc5d08715ae52",
            "e2873877eb504826955030022536b519",
            "5f9bd90305a34f1ca9144149d4ba4730",
            "c2981cf4f6944050937be182e2d5a689",
            "3e58c98d7d1b4985b70746e03ed024d4",
            "53f3a7e017154ef98643eeaa464f8f48",
            "eb3d0d180d2e4a038b9fcf9980415f92",
            "d8b46c27ef8043f595b98f4325e209ad",
            "215ed698f92440d6a46917aadac3c1c7",
            "1e51377579ba4abfa992c83c1f6cb813",
            "1282c30469414c189d85af443093d9e9",
            "8fdf5679f14f4dce88cc699459e4ed79",
            "e7713e97d01641be959c80f7f026bdbf",
            "fe10d19e5dc54962830988ae3e6a998e",
            "43d518174b1f453088029f68b3b6a8e7",
            "13d38c560176434eb7a59499fc2973d2",
            "21836b672c2043fa921d15e889089787",
            "5b8b5720210447fdb3a94847a1fa2009",
            "8309bfc4dafb44acaf77c95898e29cca",
            "b076905342de477fae2624ff76fd3882",
            "9fc1258416a349c7a9762b600e85b223",
            "9e3b3ee5f9024d56ac18dfeda824dba6",
            "b20e90d9cfb847b7bfc0b42a48b2177e",
            "00b47d8727e74846b0f34f5965c1e594",
            "1d7caa60ce2e4e8cabd76070d280423b",
            "d7f08ad6930247f7afe82da892cf36f1",
            "51a225dc368549bdb1a5afcade5afdc5",
            "4cb307737e234c1680af072581479112",
            "4d752fa70b2740e68d3e4edd94e22fda",
            "fb0254c92eb444729fca77fa6d1ef4cf",
            "f74e787f1ed147c19fb487a581973321",
            "e0d9e9075bcf460b85dd4a67ff2641c9",
            "d9c22dc8fb8a4b5089e10d11d15860c0",
            "4a600e223f82494fb6d68e9bf3e0254a",
            "39557a0229844ffa8de50a9311459fab",
            "d4a756c485ed480abdfe51b4301d1e54",
            "74a02027c1c54ea9831abcf5eb237a5e",
            "11f0dbd8f0094ee286a5d9fea27b6022",
            "7a2b7ab2ab7947d0968f00ae131435ff",
            "967502b1a3514750975abe7dd9fb3eff",
            "4342b8d1363941288490c78ba8f9f0bc",
            "632812daab0d4d4b9b0d175989fff0c8",
            "d1072b96a26d410fa10ebf460b27560e",
            "dad7a2483bc74bd280fb5c330a5a717b",
            "f7b5c045bc3e45898e4aed56024949a9",
            "6cd283a1d6494809ab3b765c265576db",
            "ed7aeb2009b1403582f0f227cff4e501",
            "4fba7520145449a590054610593b8339",
            "c7477dbb47fb435fb346d77f02d608be",
            "3cfdcc6ee0024e4c9d196d1de4c5b015",
            "2fd09996546e4f2baada745c4db3a97f",
            "8d5ca3b68ec44c4d8280112c23209a9e",
            "9ff27408b9644fb0b98c3124531750fa",
            "d5797b4514b6495a9be7fbe2cc8a3813",
            "085b923e86d04f5eb55cb22d6e2c90fe",
            "52a9351b0faa4f2aacb9bf49ece031fb",
            "ddd74b2f17234311a64acd5ad4825181",
            "55d1b5a100854d0589bbd3587273bcfd",
            "f32d7cb08ca24cdf8ada2ef29a808686",
            "83e3eff2246d409eaa4da41eebe9cb2c",
            "863c0a415aee414898b4642b5e8ab66d",
            "50b3ede950b743c2b7fbb95e6af6b034"
          ]
        },
        "id": "nBkVkbCm6DO7",
        "outputId": "ad9dc167-4de3-4be3-8271-58f3ca0c2db4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loading GPT-2 for prompt perplexity...\n"
          ]
        }
      ],
      "source": [
        "# GPT-2 for prompt perplexity\n",
        "print(\"\\nLoading GPT-2 for prompt perplexity...\")\n",
        "gpt2_tokenizer = GPT2TokenizerFast.from_pretrained(cfg.gpt2_name)\n",
        "gpt2_model = GPT2LMHeadModel.from_pretrained(cfg.gpt2_name).to(device)\n",
        "gpt2_model.eval()\n",
        "for p in gpt2_model.parameters():\n",
        "    p.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHivMjh6TNRJ"
      },
      "source": [
        "## pez non adversarial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "GRID SEARCH: Lambda for PEZ (Non-Adversarial, Balanced Loader)\n",
            "================================================================================\n",
            "\n",
            "--- Testing λ=0.0 ---\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 1/5, batch 50 | joint=16.2101 task=16.2101 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 1/5, batch 100 | joint=16.2121 task=16.2121 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 1/5, batch 150 | joint=16.2548 task=16.2548 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 1/5, batch 200 | joint=16.2770 task=16.2770 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 1/5, batch 250 | joint=16.3057 task=16.3057 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 1/5, batch 300 | joint=16.3355 task=16.3355 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 1/5, batch 350 | joint=16.3694 task=16.3694 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 1/5, batch 400 | joint=16.3632 task=16.3632 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 1/5, batch 450 | joint=16.3494 task=16.3494 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 1/5, batch 500 | joint=16.3474 task=16.3474 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 1/5, batch 550 | joint=16.3539 task=16.3539 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 1/5 | joint=16.3642 task=16.3642 ppl_loss=0.0000 ppl=0.00 val_loss=20.6477 val_acc=0.7930 (true=0.7905 false=0.7971) prompt_ppl=0.00\n",
            "Prompt: mobilradaboundALT Luxberry Christie salva situatie gasi\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 2/5, batch 50 | joint=16.1622 task=16.1622 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 2/5, batch 100 | joint=16.4217 task=16.4217 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 2/5, batch 150 | joint=16.4029 task=16.4029 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 2/5, batch 200 | joint=16.4044 task=16.4044 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 2/5, batch 250 | joint=16.4056 task=16.4056 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 2/5, batch 300 | joint=16.4228 task=16.4228 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 2/5, batch 350 | joint=16.4256 task=16.4256 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 2/5, batch 400 | joint=16.3831 task=16.3831 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 2/5, batch 450 | joint=16.3963 task=16.3963 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 2/5, batch 500 | joint=16.4230 task=16.4230 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 2/5, batch 550 | joint=16.4182 task=16.4182 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 2/5 | joint=16.4298 task=16.4298 ppl_loss=0.0000 ppl=0.00 val_loss=21.3726 val_acc=0.7933 (true=0.7969 false=0.7874) prompt_ppl=0.00\n",
            "Prompt: incredere proprietati livrare dărui accompany Rule ieftin pretul poarta pu\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 3/5, batch 50 | joint=16.1713 task=16.1713 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 3/5, batch 100 | joint=16.3100 task=16.3100 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 3/5, batch 150 | joint=16.2437 task=16.2437 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 3/5, batch 200 | joint=16.3249 task=16.3249 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 3/5, batch 250 | joint=16.3742 task=16.3742 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 3/5, batch 300 | joint=16.4042 task=16.4042 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 3/5, batch 350 | joint=16.3802 task=16.3802 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 3/5, batch 400 | joint=16.3693 task=16.3693 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 3/5, batch 450 | joint=16.3669 task=16.3669 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 3/5, batch 500 | joint=16.3576 task=16.3576 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 3/5, batch 550 | joint=16.3823 task=16.3823 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 3/5 | joint=16.3851 task=16.3851 ppl_loss=0.0000 ppl=0.00 val_loss=21.7516 val_acc=0.8006 (true=0.8210 false=0.7672) prompt_ppl=0.00\n",
            "Prompt: Minimum boulderATORSchw răc draußenTRItungs locuinteonne\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 4/5, batch 50 | joint=16.2516 task=16.2516 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 4/5, batch 100 | joint=16.3596 task=16.3596 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 4/5, batch 150 | joint=16.3914 task=16.3914 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 4/5, batch 200 | joint=16.4129 task=16.4129 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 4/5, batch 250 | joint=16.4373 task=16.4373 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 4/5, batch 300 | joint=16.4668 task=16.4668 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 4/5, batch 350 | joint=16.4766 task=16.4766 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 4/5, batch 400 | joint=16.4906 task=16.4906 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 4/5, batch 450 | joint=16.4566 task=16.4566 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 4/5, batch 500 | joint=16.4591 task=16.4591 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 4/5, batch 550 | joint=16.4306 task=16.4306 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 4/5 | joint=16.4230 task=16.4230 ppl_loss=0.0000 ppl=0.00 val_loss=21.8797 val_acc=0.7969 (true=0.8052 false=0.7833) prompt_ppl=0.00\n",
            "Prompt: Françoiseurosrophyeklagte Britanie Clauslingerodia(8) proaspat\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 5/5, batch 50 | joint=16.3640 task=16.3640 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 5/5, batch 100 | joint=16.3710 task=16.3710 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 5/5, batch 150 | joint=16.3418 task=16.3418 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 5/5, batch 200 | joint=16.3768 task=16.3768 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 5/5, batch 250 | joint=16.3485 task=16.3485 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 5/5, batch 300 | joint=16.3480 task=16.3480 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 5/5, batch 350 | joint=16.3733 task=16.3733 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 5/5, batch 400 | joint=16.3591 task=16.3591 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 5/5, batch 450 | joint=16.3795 task=16.3795 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 5/5, batch 500 | joint=16.3805 task=16.3805 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 5/5, batch 550 | joint=16.4011 task=16.4011 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 5/5 | joint=16.3891 task=16.3891 ppl_loss=0.0000 ppl=0.00 val_loss=20.8623 val_acc=0.7896 (true=0.7900 false=0.7890) prompt_ppl=0.00\n",
            "Prompt: yedikivru pamant Kli Barkgate imobil Hampshire poat\n",
            "λ=0.0: best_val_acc=0.8006, final_val_acc=0.7896, prompt_ppl=0.00\n",
            "\n",
            "--- Testing λ=0.01 ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PEZ λ=0.01 NON-ADV] Epoch 1/5, batch 50 | joint=16.3756 task=16.2891 ppl_loss=8.6497 ppl=11371.86\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 1/5, batch 100 | joint=16.3442 task=16.2573 ppl_loss=8.6925 ppl=12312.99\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 1/5, batch 150 | joint=16.4915 task=16.4041 ppl_loss=8.7423 ppl=11815.26\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 1/5, batch 200 | joint=16.4437 task=16.3562 ppl_loss=8.7456 ppl=11267.47\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 1/5, batch 250 | joint=16.4424 task=16.3553 ppl_loss=8.7117 ppl=10917.36\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 1/5, batch 300 | joint=16.4720 task=16.3852 ppl_loss=8.6839 ppl=10358.59\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 1/5, batch 350 | joint=16.4680 task=16.3810 ppl_loss=8.6917 ppl=10136.34\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 1/5, batch 400 | joint=16.4525 task=16.3651 ppl_loss=8.7381 ppl=10823.21\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 1/5, batch 450 | joint=16.4351 task=16.3482 ppl_loss=8.6930 ppl=10226.68\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 1/5, batch 500 | joint=16.4291 task=16.3422 ppl_loss=8.6856 ppl=10498.77\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 1/5, batch 550 | joint=16.4309 task=16.3439 ppl_loss=8.7007 ppl=10779.59\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 1/5 | joint=16.4470 task=16.3599 ppl_loss=8.7125 ppl=11090.69 val_loss=21.3251 val_acc=0.7966 (true=0.8136 false=0.7688) prompt_ppl=29174.29\n",
            "Prompt: âmevpnDetectbach BengalUneori Iron VanChancellorOU\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 2/5, batch 50 | joint=16.3953 task=16.3092 ppl_loss=8.6039 ppl=9870.21\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 2/5, batch 100 | joint=16.4729 task=16.3865 ppl_loss=8.6426 ppl=10380.90\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 2/5, batch 150 | joint=16.4629 task=16.3771 ppl_loss=8.5784 ppl=9008.21\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 2/5, batch 200 | joint=16.5283 task=16.4420 ppl_loss=8.6284 ppl=9197.63\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 2/5, batch 250 | joint=16.5081 task=16.4218 ppl_loss=8.6287 ppl=9207.42\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 2/5, batch 300 | joint=16.5075 task=16.4211 ppl_loss=8.6405 ppl=9304.93\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 2/5, batch 350 | joint=16.4963 task=16.4099 ppl_loss=8.6419 ppl=9276.56\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 2/5, batch 400 | joint=16.5049 task=16.4188 ppl_loss=8.6092 ppl=8894.83\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 2/5, batch 450 | joint=16.4939 task=16.4077 ppl_loss=8.6188 ppl=9015.77\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 2/5, batch 500 | joint=16.5088 task=16.4227 ppl_loss=8.6105 ppl=9370.90\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 2/5, batch 550 | joint=16.4999 task=16.4140 ppl_loss=8.5990 ppl=9114.68\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 2/5 | joint=16.4987 task=16.4127 ppl_loss=8.5975 ppl=9069.24 val_loss=21.3930 val_acc=0.7881 (true=0.7860 false=0.7914) prompt_ppl=5246.66\n",
            "Prompt: nisip cartofiuleiullohnt situatia RenaultELLEafli organizatori Wolfgang\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 3/5, batch 50 | joint=16.3024 task=16.2141 ppl_loss=8.8360 ppl=12800.42\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 3/5, batch 100 | joint=16.4846 task=16.3977 ppl_loss=8.6936 ppl=10353.19\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 3/5, batch 150 | joint=16.4980 task=16.4111 ppl_loss=8.6914 ppl=10128.46\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 3/5, batch 200 | joint=16.4899 task=16.4027 ppl_loss=8.7257 ppl=10399.25\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 3/5, batch 250 | joint=16.4585 task=16.3713 ppl_loss=8.7185 ppl=12378.05\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 3/5, batch 300 | joint=16.4548 task=16.3676 ppl_loss=8.7124 ppl=12117.42\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 3/5, batch 350 | joint=16.4622 task=16.3750 ppl_loss=8.7213 ppl=11811.19\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 3/5, batch 400 | joint=16.4517 task=16.3645 ppl_loss=8.7198 ppl=11448.58\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 3/5, batch 450 | joint=16.4333 task=16.3460 ppl_loss=8.7315 ppl=11350.53\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 3/5, batch 500 | joint=16.4333 task=16.3457 ppl_loss=8.7643 ppl=11433.46\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 3/5, batch 550 | joint=16.4444 task=16.3570 ppl_loss=8.7450 ppl=11099.91\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 3/5 | joint=16.4483 task=16.3611 ppl_loss=8.7224 ppl=10748.84 val_loss=21.2989 val_acc=0.7963 (true=0.7964 false=0.7963) prompt_ppl=8520.55\n",
            "Prompt: merci frumoasa intreb scuz deci lunăaloo fleet Guerre vindec\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 4/5, batch 50 | joint=16.4246 task=16.3391 ppl_loss=8.5558 ppl=7587.85\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 4/5, batch 100 | joint=16.4082 task=16.3208 ppl_loss=8.7420 ppl=11621.09\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 4/5, batch 150 | joint=16.4572 task=16.3695 ppl_loss=8.7720 ppl=12632.36\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 4/5, batch 200 | joint=16.4049 task=16.3177 ppl_loss=8.7159 ppl=11250.94\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 4/5, batch 250 | joint=16.4323 task=16.3461 ppl_loss=8.6272 ppl=10188.09\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 4/5, batch 300 | joint=16.4209 task=16.3346 ppl_loss=8.6244 ppl=10730.03\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 4/5, batch 350 | joint=16.3919 task=16.3056 ppl_loss=8.6368 ppl=10529.23\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 4/5, batch 400 | joint=16.4298 task=16.3436 ppl_loss=8.6275 ppl=11479.16\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 4/5, batch 450 | joint=16.4203 task=16.3339 ppl_loss=8.6380 ppl=11325.99\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 4/5, batch 500 | joint=16.4239 task=16.3376 ppl_loss=8.6332 ppl=11017.83\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 4/5, batch 550 | joint=16.4307 task=16.3444 ppl_loss=8.6307 ppl=10852.06\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 4/5 | joint=16.4457 task=16.3594 ppl_loss=8.6280 ppl=10643.14 val_loss=21.6153 val_acc=0.7960 (true=0.8096 false=0.7736) prompt_ppl=3007.63\n",
            "Prompt: arii fișierLinked sarbatori prelucrallowdrauploads contulbou\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 5/5, batch 50 | joint=16.5018 task=16.4161 ppl_loss=8.5693 ppl=8829.41\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 5/5, batch 100 | joint=16.5092 task=16.4233 ppl_loss=8.5935 ppl=8604.37\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 5/5, batch 150 | joint=16.5436 task=16.4573 ppl_loss=8.6253 ppl=9194.47\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 5/5, batch 200 | joint=16.5417 task=16.4554 ppl_loss=8.6309 ppl=8848.96\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 5/5, batch 250 | joint=16.5234 task=16.4370 ppl_loss=8.6406 ppl=9463.81\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 5/5, batch 300 | joint=16.5799 task=16.4936 ppl_loss=8.6224 ppl=9237.04\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 5/5, batch 350 | joint=16.5647 task=16.4784 ppl_loss=8.6275 ppl=9067.77\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 5/5, batch 400 | joint=16.5426 task=16.4564 ppl_loss=8.6172 ppl=8937.98\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 5/5, batch 450 | joint=16.5182 task=16.4321 ppl_loss=8.6033 ppl=8766.16\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 5/5, batch 500 | joint=16.4990 task=16.4128 ppl_loss=8.6171 ppl=8949.34\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 5/5, batch 550 | joint=16.4938 task=16.4076 ppl_loss=8.6201 ppl=8923.19\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 5/5 | joint=16.4986 task=16.4124 ppl_loss=8.6220 ppl=8908.29 val_loss=21.5620 val_acc=0.7957 (true=0.8116 false=0.7696) prompt_ppl=3565.22\n",
            "Prompt: liesLicensed monsieuracious formularul puținâme solutielucrareaäger\n",
            "λ=0.01: best_val_acc=0.7966, final_val_acc=0.7957, prompt_ppl=3565.22\n",
            "\n",
            "--- Testing λ=0.05 ---\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 1/5, batch 50 | joint=16.8747 task=16.4422 ppl_loss=8.6498 ppl=8364.15\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 1/5, batch 100 | joint=16.8449 task=16.4120 ppl_loss=8.6574 ppl=8682.84\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 1/5, batch 150 | joint=16.8521 task=16.4174 ppl_loss=8.6950 ppl=9008.40\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 1/5, batch 200 | joint=16.8512 task=16.4195 ppl_loss=8.6343 ppl=8450.53\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 1/5, batch 250 | joint=16.8217 task=16.3896 ppl_loss=8.6418 ppl=8821.09\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 1/5, batch 300 | joint=16.8481 task=16.4151 ppl_loss=8.6588 ppl=9371.68\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 1/5, batch 350 | joint=16.8303 task=16.3984 ppl_loss=8.6369 ppl=8961.16\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 1/5, batch 400 | joint=16.8468 task=16.4145 ppl_loss=8.6451 ppl=9783.47\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 1/5, batch 450 | joint=16.8593 task=16.4270 ppl_loss=8.6455 ppl=9851.25\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 1/5, batch 500 | joint=16.8315 task=16.3994 ppl_loss=8.6420 ppl=9779.83\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 1/5, batch 550 | joint=16.8324 task=16.3999 ppl_loss=8.6486 ppl=10020.50\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 1/5 | joint=16.8373 task=16.4051 ppl_loss=8.6440 ppl=9885.45 val_loss=21.5065 val_acc=0.7908 (true=0.7909 false=0.7906) prompt_ppl=6658.39\n",
            "Prompt: cunoasteMuzeul duhovnicDimensiuni aerialutilizatoriiveniturile celule Trouve preturi\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 2/5, batch 50 | joint=16.8344 task=16.3826 ppl_loss=9.0346 ppl=16919.79\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 2/5, batch 100 | joint=16.5949 task=16.1523 ppl_loss=8.8519 ppl=14254.86\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 2/5, batch 150 | joint=16.6867 task=16.2510 ppl_loss=8.7147 ppl=11996.98\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 2/5, batch 200 | joint=16.7445 task=16.3106 ppl_loss=8.6776 ppl=11201.25\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 2/5, batch 250 | joint=16.7629 task=16.3280 ppl_loss=8.6981 ppl=11025.57\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 2/5, batch 300 | joint=16.8117 task=16.3750 ppl_loss=8.7347 ppl=11365.26\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 2/5, batch 350 | joint=16.8191 task=16.3841 ppl_loss=8.6999 ppl=11127.02\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 2/5, batch 400 | joint=16.7978 task=16.3620 ppl_loss=8.7164 ppl=11348.15\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 2/5, batch 450 | joint=16.7991 task=16.3641 ppl_loss=8.7011 ppl=11083.71\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 2/5, batch 500 | joint=16.8057 task=16.3704 ppl_loss=8.7059 ppl=10978.40\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 2/5, batch 550 | joint=16.8003 task=16.3643 ppl_loss=8.7196 ppl=11117.91\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 2/5 | joint=16.7933 task=16.3575 ppl_loss=8.7164 ppl=11136.03 val_loss=21.5991 val_acc=0.7893 (true=0.7934 false=0.7825) prompt_ppl=6960.84\n",
            "Prompt: Conservative formularul Târgu AD gradini aparitiTeatrularni tac\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 3/5, batch 50 | joint=16.9271 task=16.4934 ppl_loss=8.6729 ppl=8916.51\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 3/5, batch 100 | joint=16.8602 task=16.4335 ppl_loss=8.5349 ppl=7477.74\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 3/5, batch 150 | joint=16.8434 task=16.4083 ppl_loss=8.7004 ppl=8991.97\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 3/5, batch 200 | joint=16.8542 task=16.4202 ppl_loss=8.6786 ppl=8962.31\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 3/5, batch 250 | joint=16.8186 task=16.3845 ppl_loss=8.6819 ppl=8842.22\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 3/5, batch 300 | joint=16.8258 task=16.3924 ppl_loss=8.6675 ppl=8814.04\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 3/5, batch 350 | joint=16.8535 task=16.4208 ppl_loss=8.6533 ppl=8783.23\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 3/5, batch 400 | joint=16.8343 task=16.4026 ppl_loss=8.6341 ppl=8647.36\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 3/5, batch 450 | joint=16.8079 task=16.3755 ppl_loss=8.6483 ppl=9114.01\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 3/5, batch 500 | joint=16.8014 task=16.3700 ppl_loss=8.6273 ppl=8891.97\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 3/5, batch 550 | joint=16.7970 task=16.3657 ppl_loss=8.6276 ppl=8844.18\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 3/5 | joint=16.8012 task=16.3700 ppl_loss=8.6232 ppl=8780.84 val_loss=21.9666 val_acc=0.7997 (true=0.8219 false=0.7631) prompt_ppl=1783.82\n",
            "Prompt: igung accesorii noastranumităPlattform Füße urmari footwear QR Throw\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 4/5, batch 50 | joint=17.0400 task=16.6062 ppl_loss=8.6768 ppl=9874.26\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 4/5, batch 100 | joint=17.0004 task=16.5601 ppl_loss=8.8065 ppl=14805.21\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 4/5, batch 150 | joint=16.9772 task=16.5430 ppl_loss=8.6841 ppl=12362.53\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 4/5, batch 200 | joint=16.9200 task=16.4867 ppl_loss=8.6664 ppl=11666.33\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 4/5, batch 250 | joint=16.8985 task=16.4654 ppl_loss=8.6603 ppl=10844.22\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 4/5, batch 300 | joint=16.8779 task=16.4450 ppl_loss=8.6584 ppl=10484.92\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 4/5, batch 350 | joint=16.8495 task=16.4198 ppl_loss=8.5941 ppl=9943.30\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 4/5, batch 400 | joint=16.8595 task=16.4293 ppl_loss=8.6031 ppl=10910.32\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 4/5, batch 450 | joint=16.8272 task=16.3971 ppl_loss=8.6012 ppl=10650.62\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 4/5, batch 500 | joint=16.8441 task=16.4147 ppl_loss=8.5869 ppl=10253.45\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 4/5, batch 550 | joint=16.8227 task=16.3936 ppl_loss=8.5808 ppl=10249.63\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 4/5 | joint=16.8292 task=16.3992 ppl_loss=8.5998 ppl=10231.27 val_loss=21.2682 val_acc=0.7988 (true=0.8101 false=0.7801) prompt_ppl=1955.00\n",
            "Prompt: PrairieectomylutaphilWürttembergmoto Pumponnéeltegram\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 5/5, batch 50 | joint=16.9069 task=16.4726 ppl_loss=8.6849 ppl=9336.86\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 5/5, batch 100 | joint=16.9370 task=16.5064 ppl_loss=8.6121 ppl=8813.02\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 5/5, batch 150 | joint=16.9107 task=16.4808 ppl_loss=8.5979 ppl=8700.62\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 5/5, batch 200 | joint=16.8511 task=16.4187 ppl_loss=8.6472 ppl=9091.44\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 5/5, batch 250 | joint=16.8290 task=16.3978 ppl_loss=8.6243 ppl=8985.42\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 5/5, batch 300 | joint=16.8250 task=16.3935 ppl_loss=8.6300 ppl=9011.80\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 5/5, batch 350 | joint=16.8290 task=16.3979 ppl_loss=8.6226 ppl=8997.23\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 5/5, batch 400 | joint=16.8364 task=16.4049 ppl_loss=8.6290 ppl=8995.97\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 5/5, batch 450 | joint=16.8201 task=16.3888 ppl_loss=8.6255 ppl=8973.00\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 5/5, batch 500 | joint=16.8254 task=16.3939 ppl_loss=8.6316 ppl=8964.03\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 5/5, batch 550 | joint=16.8185 task=16.3857 ppl_loss=8.6556 ppl=9300.57\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 5/5 | joint=16.8009 task=16.3674 ppl_loss=8.6702 ppl=9796.70 val_loss=21.0614 val_acc=0.7872 (true=0.7831 false=0.7939) prompt_ppl=6428.86\n",
            "Prompt: carré cabluWOOD duhovnicizoggiezimal autorizat Wolfgang Merri\n",
            "λ=0.05: best_val_acc=0.7997, final_val_acc=0.7872, prompt_ppl=6428.86\n",
            "\n",
            "--- Testing λ=0.1 ---\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 1/5, batch 50 | joint=17.1886 task=16.2912 ppl_loss=8.9740 ppl=12594.40\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 1/5, batch 100 | joint=17.3301 task=16.4429 ppl_loss=8.8722 ppl=11159.63\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 1/5, batch 150 | joint=17.3005 task=16.4174 ppl_loss=8.8317 ppl=10127.38\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 1/5, batch 200 | joint=17.3048 task=16.4218 ppl_loss=8.8294 ppl=10089.87\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 1/5, batch 250 | joint=17.3546 task=16.4724 ppl_loss=8.8216 ppl=10311.69\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 1/5, batch 300 | joint=17.3381 task=16.4577 ppl_loss=8.8040 ppl=10098.46\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 1/5, batch 350 | joint=17.3297 task=16.4539 ppl_loss=8.7583 ppl=10014.09\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 1/5, batch 400 | joint=17.3158 task=16.4409 ppl_loss=8.7494 ppl=10003.15\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 1/5, batch 450 | joint=17.2838 task=16.4085 ppl_loss=8.7531 ppl=10117.19\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 1/5, batch 500 | joint=17.2551 task=16.3798 ppl_loss=8.7536 ppl=10769.95\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 1/5, batch 550 | joint=17.2727 task=16.3996 ppl_loss=8.7308 ppl=10452.68\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 1/5 | joint=17.2922 task=16.4215 ppl_loss=8.7070 ppl=10223.94 val_loss=20.1335 val_acc=0.7832 (true=0.7944 false=0.7648) prompt_ppl=1510.34\n",
            "Prompt: Dimensiunirandul viteze gib coordonnée bucătări cru Pirate intreb urmeaza\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 2/5, batch 50 | joint=17.2009 task=16.3399 ppl_loss=8.6094 ppl=7870.03\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 2/5, batch 100 | joint=17.2946 task=16.4296 ppl_loss=8.6492 ppl=8156.25\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 2/5, batch 150 | joint=17.2703 task=16.4047 ppl_loss=8.6564 ppl=9192.97\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 2/5, batch 200 | joint=17.2426 task=16.3768 ppl_loss=8.6575 ppl=8937.95\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 2/5, batch 250 | joint=17.2257 task=16.3591 ppl_loss=8.6663 ppl=9545.92\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 2/5, batch 300 | joint=17.2387 task=16.3693 ppl_loss=8.6942 ppl=9843.64\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 2/5, batch 350 | joint=17.2487 task=16.3767 ppl_loss=8.7208 ppl=10399.58\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 2/5, batch 400 | joint=17.2541 task=16.3844 ppl_loss=8.6966 ppl=10128.65\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 2/5, batch 450 | joint=17.2530 task=16.3865 ppl_loss=8.6656 ppl=9854.41\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 2/5, batch 500 | joint=17.2373 task=16.3696 ppl_loss=8.6775 ppl=9881.16\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 2/5, batch 550 | joint=17.2277 task=16.3598 ppl_loss=8.6784 ppl=9847.11\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 2/5 | joint=17.2458 task=16.3785 ppl_loss=8.6731 ppl=9839.86 val_loss=20.1990 val_acc=0.7881 (true=0.7846 false=0.7939) prompt_ppl=8517.97\n",
            "Prompt: Spitze Wunder pacate ofera SapFrüh Olympicateurs Copberlin\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 3/5, batch 50 | joint=17.4391 task=16.5708 ppl_loss=8.6823 ppl=8896.64\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 3/5, batch 100 | joint=17.3091 task=16.4437 ppl_loss=8.6542 ppl=10438.60\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 3/5, batch 150 | joint=17.3086 task=16.4425 ppl_loss=8.6602 ppl=10121.38\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 3/5, batch 200 | joint=17.2429 task=16.3810 ppl_loss=8.6192 ppl=9901.86\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 3/5, batch 250 | joint=17.2653 task=16.4013 ppl_loss=8.6409 ppl=9872.42\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 3/5, batch 300 | joint=17.2602 task=16.3962 ppl_loss=8.6403 ppl=9774.63\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 3/5, batch 350 | joint=17.2480 task=16.3832 ppl_loss=8.6484 ppl=9837.59\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 3/5, batch 400 | joint=17.2609 task=16.3918 ppl_loss=8.6909 ppl=10138.64\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 3/5, batch 450 | joint=17.2592 task=16.3914 ppl_loss=8.6776 ppl=9901.62\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 3/5, batch 500 | joint=17.2431 task=16.3754 ppl_loss=8.6767 ppl=10142.70\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 3/5, batch 550 | joint=17.2458 task=16.3786 ppl_loss=8.6717 ppl=9956.43\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 3/5 | joint=17.2464 task=16.3806 ppl_loss=8.6571 ppl=9712.61 val_loss=21.3810 val_acc=0.7939 (true=0.7978 false=0.7874) prompt_ppl=4097.35\n",
            "Prompt: Valentineblastlutewick români acasa MuzicChrist umplutrick\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 4/5, batch 50 | joint=17.0935 task=16.1773 ppl_loss=9.1621 ppl=19613.29\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 4/5, batch 100 | joint=17.2539 task=16.3749 ppl_loss=8.7898 ppl=13642.30\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 4/5, batch 150 | joint=17.2502 task=16.3782 ppl_loss=8.7204 ppl=12008.82\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 4/5, batch 200 | joint=17.2020 task=16.3325 ppl_loss=8.6954 ppl=11517.39\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 4/5, batch 250 | joint=17.2524 task=16.3793 ppl_loss=8.7312 ppl=14092.59\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 4/5, batch 300 | joint=17.2393 task=16.3653 ppl_loss=8.7401 ppl=13801.56\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 4/5, batch 350 | joint=17.2526 task=16.3797 ppl_loss=8.7291 ppl=13293.28\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 4/5, batch 400 | joint=17.2408 task=16.3694 ppl_loss=8.7140 ppl=12993.91\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 4/5, batch 450 | joint=17.2363 task=16.3647 ppl_loss=8.7163 ppl=12717.10\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 4/5, batch 500 | joint=17.2565 task=16.3832 ppl_loss=8.7332 ppl=12689.83\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 4/5, batch 550 | joint=17.2553 task=16.3825 ppl_loss=8.7271 ppl=12538.51\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 4/5 | joint=17.2436 task=16.3715 ppl_loss=8.7208 ppl=12254.97 val_loss=21.8229 val_acc=0.7942 (true=0.8003 false=0.7842) prompt_ppl=8099.46\n",
            "Prompt: automat axle TudorVP portablehier Raduhydrate suflet prevazut\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 5/5, batch 50 | joint=17.3772 task=16.5183 ppl_loss=8.5893 ppl=8443.62\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 5/5, batch 100 | joint=17.3094 task=16.4555 ppl_loss=8.5394 ppl=8486.60\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 5/5, batch 150 | joint=17.2775 task=16.4211 ppl_loss=8.5642 ppl=9637.16\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 5/5, batch 200 | joint=17.2444 task=16.3931 ppl_loss=8.5134 ppl=8764.06\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 5/5, batch 250 | joint=17.1882 task=16.3330 ppl_loss=8.5525 ppl=9003.50\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 5/5, batch 300 | joint=17.1926 task=16.3333 ppl_loss=8.5936 ppl=9158.61\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 5/5, batch 350 | joint=17.1994 task=16.3417 ppl_loss=8.5774 ppl=8951.56\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 5/5, batch 400 | joint=17.2134 task=16.3527 ppl_loss=8.6065 ppl=9540.30\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 5/5, batch 450 | joint=17.2185 task=16.3577 ppl_loss=8.6079 ppl=9329.59\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 5/5, batch 500 | joint=17.2132 task=16.3537 ppl_loss=8.5957 ppl=9329.93\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 5/5, batch 550 | joint=17.2335 task=16.3722 ppl_loss=8.6129 ppl=9621.69\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 5/5 | joint=17.2290 task=16.3692 ppl_loss=8.5980 ppl=9444.12 val_loss=22.3378 val_acc=0.7942 (true=0.7949 false=0.7930) prompt_ppl=609.18\n",
            "Prompt: omul căt săptămână albumsRALusziehbar culorimnuluimetre aluat\n",
            "λ=0.1: best_val_acc=0.7942, final_val_acc=0.7942, prompt_ppl=609.18\n",
            "\n",
            "--- Testing λ=0.25 ---\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 1/5, batch 50 | joint=18.7823 task=16.6115 ppl_loss=8.6833 ppl=9717.82\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 1/5, batch 100 | joint=18.6633 task=16.4825 ppl_loss=8.7235 ppl=9912.35\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 1/5, batch 150 | joint=18.6765 task=16.5173 ppl_loss=8.6368 ppl=9090.62\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 1/5, batch 200 | joint=18.6481 task=16.4982 ppl_loss=8.5999 ppl=8869.10\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 1/5, batch 250 | joint=18.6708 task=16.5238 ppl_loss=8.5878 ppl=8709.87\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 1/5, batch 300 | joint=18.6457 task=16.4882 ppl_loss=8.6299 ppl=9166.79\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 1/5, batch 350 | joint=18.6398 task=16.4858 ppl_loss=8.6163 ppl=8935.49\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 1/5, batch 400 | joint=18.6416 task=16.4917 ppl_loss=8.5996 ppl=8694.60\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 1/5, batch 450 | joint=18.6025 task=16.4553 ppl_loss=8.5887 ppl=8574.89\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 1/5, batch 500 | joint=18.6118 task=16.4587 ppl_loss=8.6125 ppl=8953.83\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 1/5, batch 550 | joint=18.6240 task=16.4682 ppl_loss=8.6235 ppl=8975.75\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 1/5 | joint=18.6351 task=16.4732 ppl_loss=8.6474 ppl=9471.77 val_loss=21.8953 val_acc=0.7954 (true=0.8057 false=0.7785) prompt_ppl=2860.31\n",
            "Prompt: supplements masuri refugi Refrigerat Container intelegeSIA dimanche profesionistizate\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 2/5, batch 50 | joint=18.6156 task=16.4466 ppl_loss=8.6760 ppl=8295.40\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 2/5, batch 100 | joint=18.4389 task=16.2905 ppl_loss=8.5937 ppl=7837.06\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 2/5, batch 150 | joint=18.4437 task=16.2938 ppl_loss=8.5997 ppl=8387.73\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 2/5, batch 200 | joint=18.4701 task=16.3160 ppl_loss=8.6165 ppl=8445.01\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 2/5, batch 250 | joint=18.5236 task=16.3648 ppl_loss=8.6353 ppl=8711.23\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 2/5, batch 300 | joint=18.5301 task=16.3648 ppl_loss=8.6613 ppl=9325.36\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 2/5, batch 350 | joint=18.5295 task=16.3658 ppl_loss=8.6546 ppl=9304.61\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 2/5, batch 400 | joint=18.5425 task=16.3774 ppl_loss=8.6607 ppl=9504.35\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 2/5, batch 450 | joint=18.5522 task=16.3803 ppl_loss=8.6874 ppl=10008.87\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 2/5, batch 500 | joint=18.5652 task=16.3904 ppl_loss=8.6991 ppl=9919.67\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 2/5, batch 550 | joint=18.5584 task=16.3910 ppl_loss=8.6699 ppl=9568.10\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 2/5 | joint=18.5637 task=16.3987 ppl_loss=8.6599 ppl=9581.98 val_loss=21.1572 val_acc=0.7908 (true=0.7826 false=0.8044) prompt_ppl=2595.42\n",
            "Prompt: didactic interesel Drupal evrei dam contine Iaşi végétashes insa\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 3/5, batch 50 | joint=18.6003 task=16.4051 ppl_loss=8.7809 ppl=8463.35\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 3/5, batch 100 | joint=18.6190 task=16.4628 ppl_loss=8.6248 ppl=7950.27\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 3/5, batch 150 | joint=18.5946 task=16.4428 ppl_loss=8.6072 ppl=9081.13\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 3/5, batch 200 | joint=18.5773 task=16.4307 ppl_loss=8.5865 ppl=9253.46\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 3/5, batch 250 | joint=18.5480 task=16.4056 ppl_loss=8.5694 ppl=8833.70\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 3/5, batch 300 | joint=18.5728 task=16.4246 ppl_loss=8.5930 ppl=9413.67\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 3/5, batch 350 | joint=18.5722 task=16.4247 ppl_loss=8.5900 ppl=9284.35\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 3/5, batch 400 | joint=18.5667 task=16.4145 ppl_loss=8.6090 ppl=9352.49\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 3/5, batch 450 | joint=18.5287 task=16.3776 ppl_loss=8.6043 ppl=9246.13\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 3/5, batch 500 | joint=18.5357 task=16.3838 ppl_loss=8.6076 ppl=9354.07\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 3/5, batch 550 | joint=18.5522 task=16.3979 ppl_loss=8.6174 ppl=9430.94\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 3/5 | joint=18.5502 task=16.3924 ppl_loss=8.6310 ppl=9476.18 val_loss=21.5308 val_acc=0.7948 (true=0.8047 false=0.7785) prompt_ppl=1757.32\n",
            "Prompt: varstaschönstenturi scuz ramanelângăpermalink sarbatori hijackpers\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 4/5, batch 50 | joint=18.4684 task=16.2379 ppl_loss=8.9219 ppl=15067.71\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 4/5, batch 100 | joint=18.4022 task=16.1941 ppl_loss=8.8323 ppl=13591.40\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 4/5, batch 150 | joint=18.4393 task=16.2422 ppl_loss=8.7884 ppl=12501.46\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 4/5, batch 200 | joint=18.5375 task=16.3518 ppl_loss=8.7430 ppl=11399.98\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 4/5, batch 250 | joint=18.5513 task=16.3718 ppl_loss=8.7178 ppl=10993.35\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 4/5, batch 300 | joint=18.5367 task=16.3622 ppl_loss=8.6979 ppl=10913.16\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 4/5, batch 350 | joint=18.5148 task=16.3441 ppl_loss=8.6831 ppl=10766.94\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 4/5, batch 400 | joint=18.5112 task=16.3437 ppl_loss=8.6698 ppl=10540.81\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 4/5, batch 450 | joint=18.5198 task=16.3554 ppl_loss=8.6576 ppl=10241.78\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 4/5, batch 500 | joint=18.5090 task=16.3524 ppl_loss=8.6264 ppl=9793.92\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 4/5, batch 550 | joint=18.5166 task=16.3639 ppl_loss=8.6107 ppl=9470.66\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 4/5 | joint=18.5303 task=16.3796 ppl_loss=8.6030 ppl=9322.87 val_loss=21.6808 val_acc=0.7976 (true=0.8077 false=0.7809) prompt_ppl=4385.56\n",
            "Prompt: SfântulcalissentieuseivismPort bombardînd plimbescu\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 5/5, batch 50 | joint=18.4727 task=16.3105 ppl_loss=8.6489 ppl=8938.07\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 5/5, batch 100 | joint=18.4956 task=16.3114 ppl_loss=8.7369 ppl=10607.35\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 5/5, batch 150 | joint=18.5239 task=16.3350 ppl_loss=8.7556 ppl=11030.73\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 5/5, batch 200 | joint=18.5619 task=16.3807 ppl_loss=8.7248 ppl=10947.26\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 5/5, batch 250 | joint=18.5581 task=16.3746 ppl_loss=8.7342 ppl=11996.65\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 5/5, batch 300 | joint=18.5397 task=16.3578 ppl_loss=8.7275 ppl=11803.93\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 5/5, batch 350 | joint=18.5446 task=16.3724 ppl_loss=8.6892 ppl=11068.99\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 5/5, batch 400 | joint=18.5389 task=16.3718 ppl_loss=8.6683 ppl=10536.71\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 5/5, batch 450 | joint=18.5290 task=16.3632 ppl_loss=8.6632 ppl=11103.16\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 5/5, batch 500 | joint=18.5354 task=16.3715 ppl_loss=8.6557 ppl=10797.53\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 5/5, batch 550 | joint=18.5274 task=16.3652 ppl_loss=8.6486 ppl=10590.81\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 5/5 | joint=18.5342 task=16.3717 ppl_loss=8.6500 ppl=10478.42 val_loss=20.8517 val_acc=0.7908 (true=0.7983 false=0.7785) prompt_ppl=3945.12\n",
            "Prompt: UTE clientilor inspirat cablu portofoliuoireophil Britanie achizitiona Berliner\n",
            "λ=0.25: best_val_acc=0.7976, final_val_acc=0.7908, prompt_ppl=3945.12\n",
            "\n",
            "--- Testing λ=0.5 ---\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 1/5, batch 50 | joint=20.9246 task=16.6211 ppl_loss=8.6069 ppl=7917.98\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 1/5, batch 100 | joint=20.8845 task=16.5758 ppl_loss=8.6174 ppl=7953.70\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 1/5, batch 150 | joint=20.8584 task=16.5476 ppl_loss=8.6217 ppl=8043.63\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 1/5, batch 200 | joint=20.7900 task=16.4475 ppl_loss=8.6851 ppl=9768.78\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 1/5, batch 250 | joint=20.7441 task=16.3915 ppl_loss=8.7052 ppl=10652.72\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 1/5, batch 300 | joint=20.7316 task=16.3678 ppl_loss=8.7276 ppl=10633.50\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 1/5, batch 350 | joint=20.7081 task=16.3277 ppl_loss=8.7607 ppl=10762.10\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 1/5, batch 400 | joint=20.7101 task=16.3175 ppl_loss=8.7852 ppl=10940.48\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 1/5, batch 450 | joint=20.6921 task=16.3059 ppl_loss=8.7723 ppl=10834.17\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 1/5, batch 500 | joint=20.6979 task=16.3171 ppl_loss=8.7616 ppl=10711.29\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 1/5, batch 550 | joint=20.6808 task=16.3118 ppl_loss=8.7382 ppl=10358.97\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 1/5 | joint=20.6922 task=16.3217 ppl_loss=8.7411 ppl=10266.98 val_loss=22.1210 val_acc=0.7862 (true=0.7890 false=0.7817) prompt_ppl=7549.71\n",
            "Prompt: evrei Bitteblin functioneazaOK Dragnea vindec clientilorAssuranceDatorita\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 2/5, batch 50 | joint=20.6995 task=16.4677 ppl_loss=8.4635 ppl=7000.21\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 2/5, batch 100 | joint=20.7807 task=16.4934 ppl_loss=8.5746 ppl=8468.51\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 2/5, batch 150 | joint=20.6616 task=16.3878 ppl_loss=8.5477 ppl=8701.72\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 2/5, batch 200 | joint=20.6768 task=16.3746 ppl_loss=8.6044 ppl=8906.38\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 2/5, batch 250 | joint=20.7282 task=16.4125 ppl_loss=8.6313 ppl=9279.46\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 2/5, batch 300 | joint=20.7522 task=16.4248 ppl_loss=8.6548 ppl=9555.46\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 2/5, batch 350 | joint=20.7503 task=16.4121 ppl_loss=8.6764 ppl=10119.85\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 2/5, batch 400 | joint=20.7439 task=16.4204 ppl_loss=8.6470 ppl=9734.78\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 2/5, batch 450 | joint=20.7687 task=16.4453 ppl_loss=8.6469 ppl=9680.32\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 2/5, batch 500 | joint=20.7714 task=16.4516 ppl_loss=8.6395 ppl=9545.87\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 2/5, batch 550 | joint=20.7800 task=16.4574 ppl_loss=8.6452 ppl=9517.34\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 2/5 | joint=20.7795 task=16.4480 ppl_loss=8.6630 ppl=9840.96 val_loss=21.1267 val_acc=0.7942 (true=0.7983 false=0.7874) prompt_ppl=13091.68\n",
            "Prompt: lager solutietippbleed clientilor bruscgger Vermont piept iesit\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 3/5, batch 50 | joint=20.7374 task=16.4509 ppl_loss=8.5730 ppl=7181.42\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 3/5, batch 100 | joint=20.7215 task=16.4098 ppl_loss=8.6234 ppl=12058.03\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 3/5, batch 150 | joint=20.6270 task=16.3264 ppl_loss=8.6013 ppl=10797.50\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 3/5, batch 200 | joint=20.6824 task=16.3600 ppl_loss=8.6449 ppl=11145.97\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 3/5, batch 250 | joint=20.7000 task=16.3811 ppl_loss=8.6378 ppl=10849.57\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 3/5, batch 300 | joint=20.7297 task=16.4212 ppl_loss=8.6172 ppl=10587.87\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 3/5, batch 350 | joint=20.7152 task=16.4108 ppl_loss=8.6087 ppl=10106.31\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 3/5, batch 400 | joint=20.7209 task=16.4117 ppl_loss=8.6183 ppl=10104.82\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 3/5, batch 450 | joint=20.7050 task=16.4077 ppl_loss=8.5946 ppl=10868.59\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 3/5, batch 500 | joint=20.7248 task=16.4249 ppl_loss=8.5997 ppl=10906.54\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 3/5, batch 550 | joint=20.7299 task=16.4249 ppl_loss=8.6101 ppl=10827.11\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 3/5 | joint=20.7358 task=16.4289 ppl_loss=8.6138 ppl=10718.90 val_loss=20.6820 val_acc=0.7942 (true=0.8003 false=0.7842) prompt_ppl=1974.25\n",
            "Prompt: prevazutvetteBB Nagbraking Stotrecută reprezentanți Süd pietre\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 4/5, batch 50 | joint=20.5710 task=16.2161 ppl_loss=8.7097 ppl=8831.29\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 4/5, batch 100 | joint=20.6725 task=16.3315 ppl_loss=8.6819 ppl=10671.39\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 4/5, batch 150 | joint=20.6483 task=16.2961 ppl_loss=8.7043 ppl=10217.32\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 4/5, batch 200 | joint=20.7431 task=16.3947 ppl_loss=8.6968 ppl=10903.40\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 4/5, batch 250 | joint=20.7478 task=16.3928 ppl_loss=8.7101 ppl=10679.80\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 4/5, batch 300 | joint=20.7339 task=16.3951 ppl_loss=8.6774 ppl=10206.78\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 4/5, batch 350 | joint=20.7215 task=16.3816 ppl_loss=8.6798 ppl=10273.45\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 4/5, batch 400 | joint=20.6947 task=16.3713 ppl_loss=8.6469 ppl=9890.80\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 4/5, batch 450 | joint=20.6833 task=16.3563 ppl_loss=8.6540 ppl=10041.29\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 4/5, batch 500 | joint=20.6653 task=16.3352 ppl_loss=8.6603 ppl=9960.28\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 4/5, batch 550 | joint=20.6725 task=16.3474 ppl_loss=8.6502 ppl=9794.09\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 4/5 | joint=20.6665 task=16.3422 ppl_loss=8.6487 ppl=9678.03 val_loss=21.1985 val_acc=0.7969 (true=0.8047 false=0.7842) prompt_ppl=5570.64\n",
            "Prompt: owedcrest PAR Freaza Sonne ediți Lok Dou Dia\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 5/5, batch 50 | joint=20.8044 task=16.5607 ppl_loss=8.4874 ppl=6666.70\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 5/5, batch 100 | joint=20.8001 task=16.4944 ppl_loss=8.6115 ppl=8337.89\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 5/5, batch 150 | joint=20.8212 task=16.5249 ppl_loss=8.5926 ppl=7981.01\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 5/5, batch 200 | joint=20.7443 task=16.4019 ppl_loss=8.6849 ppl=9000.73\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 5/5, batch 250 | joint=20.7732 task=16.4175 ppl_loss=8.7114 ppl=10935.06\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 5/5, batch 300 | joint=20.7647 task=16.4267 ppl_loss=8.6761 ppl=10313.30\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 5/5, batch 350 | joint=20.7393 task=16.4076 ppl_loss=8.6633 ppl=10119.52\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 5/5, batch 400 | joint=20.7116 task=16.3798 ppl_loss=8.6636 ppl=9950.27\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 5/5, batch 450 | joint=20.7180 task=16.3731 ppl_loss=8.6897 ppl=10303.90\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 5/5, batch 500 | joint=20.7018 task=16.3559 ppl_loss=8.6919 ppl=10460.49\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 5/5, batch 550 | joint=20.7063 task=16.3654 ppl_loss=8.6818 ppl=10260.41\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 5/5 | joint=20.7071 task=16.3625 ppl_loss=8.6892 ppl=10225.37 val_loss=21.4768 val_acc=0.8003 (true=0.8146 false=0.7769) prompt_ppl=8591.91\n",
            "Prompt: irkEuro urmeazariyaègeropsuingidadunicipiului Qui\n",
            "λ=0.5: best_val_acc=0.8003, final_val_acc=0.8003, prompt_ppl=8591.91\n",
            "\n",
            "--- Testing λ=0.75 ---\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 1/5, batch 50 | joint=22.7310 task=16.3747 ppl_loss=8.4752 ppl=9927.88\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 1/5, batch 100 | joint=22.7271 task=16.3763 ppl_loss=8.4678 ppl=8273.22\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 1/5, batch 150 | joint=22.8431 task=16.4298 ppl_loss=8.5511 ppl=9445.72\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 1/5, batch 200 | joint=22.8351 task=16.4418 ppl_loss=8.5244 ppl=8663.13\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 1/5, batch 250 | joint=22.7868 task=16.4172 ppl_loss=8.4928 ppl=8267.59\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 1/5, batch 300 | joint=22.8671 task=16.4501 ppl_loss=8.5560 ppl=8672.03\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 1/5, batch 350 | joint=22.8611 task=16.4428 ppl_loss=8.5577 ppl=8581.38\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 1/5, batch 400 | joint=22.8840 task=16.4615 ppl_loss=8.5634 ppl=8517.40\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 1/5, batch 450 | joint=22.8568 task=16.4144 ppl_loss=8.5900 ppl=8747.14\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 1/5, batch 500 | joint=22.8528 task=16.4200 ppl_loss=8.5770 ppl=8828.69\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 1/5, batch 550 | joint=22.8713 task=16.4451 ppl_loss=8.5683 ppl=8695.77\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 1/5 | joint=22.8590 task=16.4338 ppl_loss=8.5669 ppl=9010.65 val_loss=20.9691 val_acc=0.7963 (true=0.8136 false=0.7680) prompt_ppl=2069.56\n",
            "Prompt: Campbellutilizatoriivitezăzanoasegrafettyzol glutmut\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 2/5, batch 50 | joint=22.6666 task=16.2672 ppl_loss=8.5326 ppl=7308.18\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 2/5, batch 100 | joint=22.8476 task=16.4363 ppl_loss=8.5483 ppl=7982.50\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 2/5, batch 150 | joint=22.9420 task=16.5051 ppl_loss=8.5826 ppl=9561.11\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 2/5, batch 200 | joint=22.9608 task=16.4835 ppl_loss=8.6364 ppl=10017.53\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 2/5, batch 250 | joint=22.9732 task=16.4714 ppl_loss=8.6692 ppl=11140.73\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 2/5, batch 300 | joint=22.9548 task=16.4639 ppl_loss=8.6545 ppl=10733.84\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 2/5, batch 350 | joint=22.9816 task=16.4655 ppl_loss=8.6882 ppl=11083.80\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 2/5, batch 400 | joint=22.9617 task=16.4519 ppl_loss=8.6797 ppl=10888.89\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 2/5, batch 450 | joint=22.9344 task=16.4420 ppl_loss=8.6565 ppl=10966.97\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 2/5, batch 500 | joint=22.9345 task=16.4288 ppl_loss=8.6742 ppl=10907.04\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 2/5, batch 550 | joint=22.9160 task=16.4177 ppl_loss=8.6643 ppl=10575.56\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 2/5 | joint=22.9380 task=16.4378 ppl_loss=8.6669 ppl=10510.82 val_loss=20.9055 val_acc=0.7850 (true=0.7777 false=0.7971) prompt_ppl=15239.82\n",
            "Prompt: TokyoECO partitionceputul Pir organismului complément Griffpaz Emp\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 3/5, batch 50 | joint=22.8321 task=16.5107 ppl_loss=8.4285 ppl=8123.40\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 3/5, batch 100 | joint=22.8226 task=16.4056 ppl_loss=8.5560 ppl=9789.14\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 3/5, batch 150 | joint=22.7110 task=16.3463 ppl_loss=8.4863 ppl=8644.53\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 3/5, batch 200 | joint=22.7255 task=16.3245 ppl_loss=8.5347 ppl=9205.67\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 3/5, batch 250 | joint=22.7702 task=16.3135 ppl_loss=8.6090 ppl=9373.30\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 3/5, batch 300 | joint=22.7854 task=16.3167 ppl_loss=8.6250 ppl=9597.25\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 3/5, batch 350 | joint=22.7533 task=16.3042 ppl_loss=8.5989 ppl=9206.36\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 3/5, batch 400 | joint=22.7603 task=16.3112 ppl_loss=8.5987 ppl=9411.82\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 3/5, batch 450 | joint=22.7703 task=16.3244 ppl_loss=8.5946 ppl=9408.21\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 3/5, batch 500 | joint=22.7654 task=16.3326 ppl_loss=8.5770 ppl=9151.21\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 3/5, batch 550 | joint=22.7767 task=16.3419 ppl_loss=8.5797 ppl=9322.56\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 3/5 | joint=22.7753 task=16.3406 ppl_loss=8.5796 ppl=9355.86 val_loss=21.6885 val_acc=0.7972 (true=0.8200 false=0.7599) prompt_ppl=5040.96\n",
            "Prompt: Talk jocuriQCoilea Brothertiti rosii varstaMolecular Dragnea\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 4/5, batch 50 | joint=22.7209 task=16.0966 ppl_loss=8.8324 ppl=10164.64\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 4/5, batch 100 | joint=22.7647 task=16.1648 ppl_loss=8.7998 ppl=10437.21\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 4/5, batch 150 | joint=22.7533 task=16.1941 ppl_loss=8.7457 ppl=10031.82\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 4/5, batch 200 | joint=22.8016 task=16.2835 ppl_loss=8.6908 ppl=9401.20\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 4/5, batch 250 | joint=22.8509 task=16.3608 ppl_loss=8.6535 ppl=9015.61\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 4/5, batch 300 | joint=22.8682 task=16.3738 ppl_loss=8.6592 ppl=9445.54\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 4/5, batch 350 | joint=22.8453 task=16.3724 ppl_loss=8.6305 ppl=9422.72\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 4/5, batch 400 | joint=22.8576 task=16.3670 ppl_loss=8.6541 ppl=9784.75\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 4/5, batch 450 | joint=22.8810 task=16.3896 ppl_loss=8.6551 ppl=9646.03\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 4/5, batch 500 | joint=22.8743 task=16.3771 ppl_loss=8.6630 ppl=9760.74\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 4/5, batch 550 | joint=22.8581 task=16.3623 ppl_loss=8.6611 ppl=9679.44\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 4/5 | joint=22.8641 task=16.3712 ppl_loss=8.6572 ppl=9554.43 val_loss=21.0708 val_acc=0.7948 (true=0.8032 false=0.7809) prompt_ppl=1855.09\n",
            "Prompt: indexedlogic clic Einladung Gestaltgres Griff lei Folgri\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 5/5, batch 50 | joint=22.9384 task=16.4253 ppl_loss=8.6842 ppl=9483.42\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 5/5, batch 100 | joint=22.8542 task=16.3408 ppl_loss=8.6846 ppl=9279.36\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 5/5, batch 150 | joint=22.8518 task=16.3481 ppl_loss=8.6717 ppl=9590.61\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 5/5, batch 200 | joint=22.8790 task=16.3314 ppl_loss=8.7302 ppl=10848.06\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 5/5, batch 250 | joint=22.8644 task=16.3197 ppl_loss=8.7262 ppl=10340.41\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 5/5, batch 300 | joint=22.8120 task=16.3093 ppl_loss=8.6702 ppl=9628.63\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 5/5, batch 350 | joint=22.8032 task=16.2891 ppl_loss=8.6855 ppl=9546.55\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 5/5, batch 400 | joint=22.8623 task=16.3287 ppl_loss=8.7114 ppl=9975.11\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 5/5, batch 450 | joint=22.8615 task=16.3300 ppl_loss=8.7087 ppl=10054.18\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 5/5, batch 500 | joint=22.8764 task=16.3568 ppl_loss=8.6927 ppl=9838.02\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 5/5, batch 550 | joint=22.8801 task=16.3710 ppl_loss=8.6789 ppl=9814.43\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 5/5 | joint=22.8683 task=16.3718 ppl_loss=8.6620 ppl=9621.99 val_loss=20.4697 val_acc=0.7869 (true=0.7846 false=0.7906) prompt_ppl=9555.51\n",
            "Prompt: Cruci urmeaza clientilor cobor frumoasa Sinnkhihari proprietatijou\n",
            "λ=0.75: best_val_acc=0.7972, final_val_acc=0.7869, prompt_ppl=9555.51\n",
            "\n",
            "--- Testing λ=1.0 ---\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 1/5, batch 50 | joint=25.2021 task=16.4311 ppl_loss=8.7709 ppl=19430.27\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 1/5, batch 100 | joint=25.1706 task=16.3363 ppl_loss=8.8343 ppl=14957.02\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 1/5, batch 150 | joint=25.1139 task=16.2586 ppl_loss=8.8553 ppl=14152.74\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 1/5, batch 200 | joint=25.0633 task=16.2648 ppl_loss=8.7985 ppl=12618.64\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 1/5, batch 250 | joint=25.0247 task=16.3029 ppl_loss=8.7218 ppl=11684.06\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 1/5, batch 300 | joint=25.0247 task=16.3155 ppl_loss=8.7092 ppl=11402.52\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 1/5, batch 350 | joint=25.0156 task=16.3115 ppl_loss=8.7042 ppl=11041.85\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 1/5, batch 400 | joint=25.0101 task=16.3062 ppl_loss=8.7039 ppl=10733.64\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 1/5, batch 450 | joint=25.0138 task=16.3154 ppl_loss=8.6985 ppl=10799.70\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 1/5, batch 500 | joint=25.0159 task=16.3299 ppl_loss=8.6860 ppl=10709.31\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 1/5, batch 550 | joint=25.0160 task=16.3215 ppl_loss=8.6945 ppl=10817.84\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 1/5 | joint=25.0152 task=16.3217 ppl_loss=8.6935 ppl=10675.42 val_loss=21.5426 val_acc=0.7924 (true=0.7993 false=0.7809) prompt_ppl=2794.16\n",
            "Prompt: amenajatcoulier ciocolatblew descent Footiens moraparut\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 2/5, batch 50 | joint=25.2913 task=16.6244 ppl_loss=8.6669 ppl=8779.42\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 2/5, batch 100 | joint=25.2526 task=16.5748 ppl_loss=8.6778 ppl=9528.04\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 2/5, batch 150 | joint=25.1211 task=16.4554 ppl_loss=8.6657 ppl=9757.70\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 2/5, batch 200 | joint=25.0774 task=16.3874 ppl_loss=8.6900 ppl=10004.94\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 2/5, batch 250 | joint=25.0581 task=16.3849 ppl_loss=8.6732 ppl=9680.25\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 2/5, batch 300 | joint=25.0744 task=16.3804 ppl_loss=8.6939 ppl=10153.57\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 2/5, batch 350 | joint=25.1050 task=16.3946 ppl_loss=8.7104 ppl=10427.98\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 2/5, batch 400 | joint=25.0988 task=16.3851 ppl_loss=8.7137 ppl=10463.38\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 2/5, batch 450 | joint=25.1042 task=16.3932 ppl_loss=8.7111 ppl=10438.12\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 2/5, batch 500 | joint=25.1043 task=16.3882 ppl_loss=8.7161 ppl=10416.09\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 2/5, batch 550 | joint=25.0940 task=16.3864 ppl_loss=8.7076 ppl=10196.78\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 2/5 | joint=25.0892 task=16.3881 ppl_loss=8.7011 ppl=10110.43 val_loss=19.9966 val_acc=0.7982 (true=0.8121 false=0.7753) prompt_ppl=5238.66\n",
            "Prompt: Abstracthectareafli Herbstdoiembre Colombiaodeur spațicazurile\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 3/5, batch 50 | joint=25.0807 task=16.3682 ppl_loss=8.7126 ppl=10477.74\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 3/5, batch 100 | joint=25.2057 task=16.4363 ppl_loss=8.7694 ppl=11267.61\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 3/5, batch 150 | joint=25.0996 task=16.3492 ppl_loss=8.7504 ppl=10879.36\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 3/5, batch 200 | joint=25.2172 task=16.3800 ppl_loss=8.8372 ppl=13653.52\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 3/5, batch 250 | joint=25.1377 task=16.3669 ppl_loss=8.7708 ppl=12345.31\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 3/5, batch 300 | joint=25.1267 task=16.3693 ppl_loss=8.7574 ppl=11549.85\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 3/5, batch 350 | joint=25.1552 task=16.3685 ppl_loss=8.7867 ppl=12147.69\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 3/5, batch 400 | joint=25.1304 task=16.3630 ppl_loss=8.7674 ppl=11839.75\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 3/5, batch 450 | joint=25.0904 task=16.3445 ppl_loss=8.7459 ppl=11614.21\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 3/5, batch 500 | joint=25.1140 task=16.3608 ppl_loss=8.7532 ppl=11697.82\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 3/5, batch 550 | joint=25.0986 task=16.3692 ppl_loss=8.7294 ppl=11305.64\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 3/5 | joint=25.0929 task=16.3683 ppl_loss=8.7246 ppl=11344.69 val_loss=21.6432 val_acc=0.7936 (true=0.8032 false=0.7777) prompt_ppl=1013.97\n",
            "Prompt: plimblude saveieuse aplicatii invataătăUneoriprindere Bran\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 4/5, batch 50 | joint=25.0512 task=16.4798 ppl_loss=8.5713 ppl=9509.89\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 4/5, batch 100 | joint=24.9165 task=16.4688 ppl_loss=8.4477 ppl=7967.28\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 4/5, batch 150 | joint=24.8824 task=16.3703 ppl_loss=8.5120 ppl=8303.29\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 4/5, batch 200 | joint=24.9204 task=16.4218 ppl_loss=8.4986 ppl=8874.34\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 4/5, batch 250 | joint=25.0038 task=16.4052 ppl_loss=8.5985 ppl=9822.29\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 4/5, batch 300 | joint=25.0085 task=16.3304 ppl_loss=8.6781 ppl=11586.97\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 4/5, batch 350 | joint=25.0014 task=16.3595 ppl_loss=8.6419 ppl=10848.72\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 4/5, batch 400 | joint=25.0271 task=16.3728 ppl_loss=8.6543 ppl=10694.42\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 4/5, batch 450 | joint=25.0086 task=16.3634 ppl_loss=8.6452 ppl=10383.08\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 4/5, batch 500 | joint=25.0107 task=16.3523 ppl_loss=8.6584 ppl=10506.08\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 4/5, batch 550 | joint=25.0076 task=16.3605 ppl_loss=8.6471 ppl=10332.43\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 4/5 | joint=24.9993 task=16.3568 ppl_loss=8.6425 ppl=10214.30 val_loss=21.1428 val_acc=0.7979 (true=0.8229 false=0.7567) prompt_ppl=14466.82\n",
            "Prompt: lasiidineinselelul Federation lambRIA GuillaumekrautHi\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 5/5, batch 50 | joint=24.7331 task=16.0322 ppl_loss=8.7010 ppl=10157.81\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 5/5, batch 100 | joint=24.8585 task=16.1331 ppl_loss=8.7254 ppl=10248.07\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 5/5, batch 150 | joint=24.9477 task=16.1953 ppl_loss=8.7524 ppl=10607.79\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 5/5, batch 200 | joint=24.9323 task=16.2187 ppl_loss=8.7136 ppl=9951.72\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 5/5, batch 250 | joint=24.9700 task=16.2749 ppl_loss=8.6951 ppl=9992.51\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 5/5, batch 300 | joint=24.9541 task=16.2843 ppl_loss=8.6697 ppl=9626.29\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 5/5, batch 350 | joint=24.9998 task=16.3043 ppl_loss=8.6955 ppl=10038.77\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 5/5, batch 400 | joint=25.0341 task=16.3220 ppl_loss=8.7121 ppl=10187.05\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 5/5, batch 450 | joint=25.0457 task=16.3445 ppl_loss=8.7012 ppl=10044.62\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 5/5, batch 500 | joint=25.0459 task=16.3432 ppl_loss=8.7027 ppl=9902.52\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 5/5, batch 550 | joint=25.0361 task=16.3305 ppl_loss=8.7056 ppl=10308.53\n",
            "[PEZ λ=1.0 NON-ADV] Epoch 5/5 | joint=25.0112 task=16.3145 ppl_loss=8.6967 ppl=10125.85 val_loss=19.8652 val_acc=0.7887 (true=0.7782 false=0.8060) prompt_ppl=12897.00\n",
            "Prompt: Max Sind pacateumming imprumut imobilrmând peisaj pieleaamour\n",
            "λ=1.0: best_val_acc=0.7982, final_val_acc=0.7887, prompt_ppl=12897.00\n",
            "\n",
            "================================================================================\n",
            "PEZ Grid Search Results (sorted by best_val_acc):\n",
            "================================================================================\n",
            "λ=0.00: best_val_acc=0.8006, final_val_acc=0.7896, prompt_ppl=0.00\n",
            "λ=0.50: best_val_acc=0.8003, final_val_acc=0.8003, prompt_ppl=8591.91\n",
            "λ=0.05: best_val_acc=0.7997, final_val_acc=0.7872, prompt_ppl=6428.86\n",
            "λ=1.00: best_val_acc=0.7982, final_val_acc=0.7887, prompt_ppl=12897.00\n",
            "λ=0.25: best_val_acc=0.7976, final_val_acc=0.7908, prompt_ppl=3945.12\n",
            "λ=0.75: best_val_acc=0.7972, final_val_acc=0.7869, prompt_ppl=9555.51\n",
            "λ=0.01: best_val_acc=0.7966, final_val_acc=0.7957, prompt_ppl=3565.22\n",
            "λ=0.10: best_val_acc=0.7942, final_val_acc=0.7942, prompt_ppl=609.18\n",
            "\n",
            "Best λ: 0.00\n",
            "  best_val_acc=0.8006, final_val_acc=0.7896\n"
          ]
        }
      ],
      "source": [
        "# Grid search over lambda for PEZ (balanced loader, non-adversarial)\n",
        "# Note: PEZ uses hard one-hot updates (argmin), so it doesn't use learning rate\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"GRID SEARCH: Lambda for PEZ (Non-Adversarial, Balanced Loader)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "lambda_grid = [0.0, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1.0]\n",
        "pez_grid_results = []\n",
        "\n",
        "for lam in lambda_grid:\n",
        "    print(f\"\\n--- Testing λ={lam} ---\")\n",
        "    \n",
        "    result = train_pez(\n",
        "        cfg,\n",
        "        tokenizer,\n",
        "        gpt2_model,\n",
        "        gpt2_tokenizer,\n",
        "        train_dl,\n",
        "        val_dl,\n",
        "        lambda_ppl=lam,\n",
        "        adversarial=False,\n",
        "    )\n",
        "    \n",
        "    best_val_acc = max(result[\"history\"][\"val_acc\"])\n",
        "    final_val_acc = result[\"history\"][\"val_acc\"][-1]\n",
        "    prompt_ppl = result[\"history\"][\"prompt_ppl_ppx\"][-1] if result[\"history\"][\"prompt_ppl_ppx\"] else 0.0\n",
        "    \n",
        "    pez_grid_results.append({\n",
        "        \"lambda\": lam,\n",
        "        \"best_val_acc\": best_val_acc,\n",
        "        \"final_val_acc\": final_val_acc,\n",
        "        \"prompt_ppl\": prompt_ppl,\n",
        "        \"history\": result[\"history\"]\n",
        "    })\n",
        "    print(f\"λ={lam}: best_val_acc={best_val_acc:.4f}, final_val_acc={final_val_acc:.4f}, prompt_ppl={prompt_ppl:.2f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PEZ Grid Search Results (sorted by best_val_acc):\")\n",
        "print(\"=\" * 80)\n",
        "sorted_results = sorted(pez_grid_results, key=lambda x: x[\"best_val_acc\"], reverse=True)\n",
        "for r in sorted_results:\n",
        "    print(f\"λ={r['lambda']:.2f}: best_val_acc={r['best_val_acc']:.4f}, final_val_acc={r['final_val_acc']:.4f}, prompt_ppl={r['prompt_ppl']:.2f}\")\n",
        "\n",
        "best_pez_result = max(pez_grid_results, key=lambda x: x[\"best_val_acc\"])\n",
        "print(f\"\\nBest λ: {best_pez_result['lambda']:.2f}\")\n",
        "print(f\"  best_val_acc={best_pez_result['best_val_acc']:.4f}, final_val_acc={best_pez_result['final_val_acc']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved full grid results (including histories) to /mnt/polished-lake/home/annabelma/other/results/unbalanced/pez_grid_results_non_adv.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "save_path = \"/mnt/polished-lake/home/annabelma/other/results/unbalanced/pez_grid_results_non_adv.json\"\n",
        "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "with open(save_path, \"w\") as f:\n",
        "    json.dump(pez_grid_results, f, indent=2)\n",
        "\n",
        "print(f\"Saved full grid results (including histories) to {save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = \"/mnt/polished-lake/home/annabelma/other/results/unbalanced/pez_grid_results_non_adv.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNu8UcNgdH-R",
        "outputId": "c557eb1f-723c-429e-b8ba-aaca93e211d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== PEZ Non-Adversarial (λ=0.0) ===\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 1/5, batch 50 | joint=16.3446 task=16.3446 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 1/5, batch 100 | joint=16.3589 task=16.3589 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 1/5, batch 150 | joint=16.3604 task=16.3604 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 1/5, batch 200 | joint=16.3709 task=16.3709 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 1/5, batch 250 | joint=16.3692 task=16.3692 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 1/5, batch 300 | joint=16.3550 task=16.3550 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 1/5, batch 350 | joint=16.3786 task=16.3786 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 1/5, batch 400 | joint=16.3625 task=16.3625 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 1/5, batch 450 | joint=16.3492 task=16.3492 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 1/5, batch 500 | joint=16.3542 task=16.3542 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 1/5, batch 550 | joint=16.3521 task=16.3521 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 1/5 | joint=16.3470 task=16.3470 ppl_loss=0.0000 ppl=0.00 val_loss=21.2171 val_acc=0.7942 (true=0.7983 false=0.7874) prompt_ppl=0.00\n",
            "Prompt: Schaigue Landkreis staretoataEditura Guard shootlockedrunner\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 2/5, batch 50 | joint=16.3026 task=16.3026 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 2/5, batch 100 | joint=16.3786 task=16.3786 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 2/5, batch 150 | joint=16.3740 task=16.3740 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 2/5, batch 200 | joint=16.3975 task=16.3975 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 2/5, batch 250 | joint=16.3930 task=16.3930 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 2/5, batch 300 | joint=16.3858 task=16.3858 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 2/5, batch 350 | joint=16.3658 task=16.3658 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 2/5, batch 400 | joint=16.3470 task=16.3470 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 2/5, batch 450 | joint=16.3497 task=16.3497 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 2/5, batch 500 | joint=16.3279 task=16.3279 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 2/5, batch 550 | joint=16.3382 task=16.3382 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 2/5 | joint=16.3508 task=16.3508 ppl_loss=0.0000 ppl=0.00 val_loss=21.1492 val_acc=0.7917 (true=0.7934 false=0.7890) prompt_ppl=0.00\n",
            "Prompt: Palatulucun simpla échéan tonight simtirawogarick Sergi\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 3/5, batch 50 | joint=16.4486 task=16.4486 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 3/5, batch 100 | joint=16.3344 task=16.3344 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 3/5, batch 150 | joint=16.4406 task=16.4406 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 3/5, batch 200 | joint=16.4529 task=16.4529 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 3/5, batch 250 | joint=16.4251 task=16.4251 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 3/5, batch 300 | joint=16.4097 task=16.4097 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 3/5, batch 350 | joint=16.4507 task=16.4507 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 3/5, batch 400 | joint=16.4640 task=16.4640 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 3/5, batch 450 | joint=16.4612 task=16.4612 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 3/5, batch 500 | joint=16.4495 task=16.4495 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 3/5, batch 550 | joint=16.4166 task=16.4166 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 3/5 | joint=16.4068 task=16.4068 ppl_loss=0.0000 ppl=0.00 val_loss=20.4916 val_acc=0.7924 (true=0.7895 false=0.7971) prompt_ppl=0.00\n",
            "Prompt: senzati obtine frumoasa închiri Centenar dispoziti Terra simplaablabili\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 4/5, batch 50 | joint=16.4672 task=16.4672 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 4/5, batch 100 | joint=16.5220 task=16.5220 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 4/5, batch 150 | joint=16.5237 task=16.5237 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 4/5, batch 200 | joint=16.4938 task=16.4938 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 4/5, batch 250 | joint=16.5283 task=16.5283 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 4/5, batch 300 | joint=16.4687 task=16.4687 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 4/5, batch 350 | joint=16.4571 task=16.4571 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 4/5, batch 400 | joint=16.4497 task=16.4497 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 4/5, batch 450 | joint=16.4560 task=16.4560 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 4/5, batch 500 | joint=16.4486 task=16.4486 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 4/5, batch 550 | joint=16.4559 task=16.4559 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 4/5 | joint=16.4621 task=16.4621 ppl_loss=0.0000 ppl=0.00 val_loss=21.5719 val_acc=0.7942 (true=0.8032 false=0.7793) prompt_ppl=0.00\n",
            "Prompt: rugamherebyälteste obtinutWalkEmmanuellix calatoriintreaga dispoziti\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 5/5, batch 50 | joint=16.2600 task=16.2600 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 5/5, batch 100 | joint=16.2774 task=16.2774 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 5/5, batch 150 | joint=16.3707 task=16.3707 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 5/5, batch 200 | joint=16.3039 task=16.3039 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 5/5, batch 250 | joint=16.3578 task=16.3578 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 5/5, batch 300 | joint=16.3884 task=16.3884 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 5/5, batch 350 | joint=16.4043 task=16.4043 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 5/5, batch 400 | joint=16.3839 task=16.3839 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 5/5, batch 450 | joint=16.3820 task=16.3820 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 5/5, batch 500 | joint=16.3681 task=16.3681 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 5/5, batch 550 | joint=16.3660 task=16.3660 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 NON-ADV] Epoch 5/5 | joint=16.3797 task=16.3797 ppl_loss=0.0000 ppl=0.00 val_loss=21.3192 val_acc=0.7899 (true=0.7791 false=0.8076) prompt_ppl=0.00\n",
            "Prompt: pielii Q milambogia evenimentului Retirement JusticeDatorita machiajtar\n",
            "\n",
            "=== PEZ Non-Adversarial (λ=0.01) ===\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 1/5, batch 50 | joint=16.6009 task=16.5145 ppl_loss=8.6429 ppl=8971.73\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 1/5, batch 100 | joint=16.6884 task=16.6026 ppl_loss=8.5867 ppl=8070.39\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 1/5, batch 150 | joint=16.5768 task=16.4908 ppl_loss=8.6037 ppl=8171.90\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 1/5, batch 200 | joint=16.5710 task=16.4846 ppl_loss=8.6482 ppl=8635.34\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 1/5, batch 250 | joint=16.5606 task=16.4738 ppl_loss=8.6768 ppl=8752.53\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 1/5, batch 300 | joint=16.5222 task=16.4360 ppl_loss=8.6204 ppl=8507.92\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 1/5, batch 350 | joint=16.5368 task=16.4507 ppl_loss=8.6068 ppl=8449.84\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 1/5, batch 400 | joint=16.5348 task=16.4489 ppl_loss=8.5872 ppl=8397.32\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 1/5, batch 450 | joint=16.5218 task=16.4355 ppl_loss=8.6262 ppl=8879.06\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 1/5, batch 500 | joint=16.5256 task=16.4394 ppl_loss=8.6199 ppl=8992.27\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 1/5, batch 550 | joint=16.5361 task=16.4499 ppl_loss=8.6132 ppl=8870.84\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 1/5 | joint=16.5332 task=16.4472 ppl_loss=8.6041 ppl=8759.79 val_loss=20.5519 val_acc=0.7960 (true=0.8062 false=0.7793) prompt_ppl=28445.55\n",
            "Prompt: ceapa bacteriiOU SfantTrusteesselfgres Ecianuitate\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 2/5, batch 50 | joint=16.4317 task=16.3458 ppl_loss=8.5809 ppl=8636.99\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 2/5, batch 100 | joint=16.4468 task=16.3607 ppl_loss=8.6181 ppl=9104.49\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 2/5, batch 150 | joint=16.3589 task=16.2727 ppl_loss=8.6201 ppl=9968.01\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 2/5, batch 200 | joint=16.3889 task=16.3025 ppl_loss=8.6344 ppl=9938.05\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 2/5, batch 250 | joint=16.3939 task=16.3076 ppl_loss=8.6331 ppl=10560.46\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 2/5, batch 300 | joint=16.3827 task=16.2962 ppl_loss=8.6508 ppl=12431.73\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 2/5, batch 350 | joint=16.4118 task=16.3254 ppl_loss=8.6398 ppl=11799.05\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 2/5, batch 400 | joint=16.4035 task=16.3173 ppl_loss=8.6210 ppl=11537.18\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 2/5, batch 450 | joint=16.4088 task=16.3225 ppl_loss=8.6256 ppl=11181.35\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 2/5, batch 500 | joint=16.4342 task=16.3477 ppl_loss=8.6450 ppl=11350.21\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 2/5, batch 550 | joint=16.4296 task=16.3432 ppl_loss=8.6406 ppl=11153.67\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 2/5 | joint=16.4246 task=16.3382 ppl_loss=8.6400 ppl=10988.22 val_loss=21.0024 val_acc=0.7951 (true=0.8003 false=0.7866) prompt_ppl=3309.09\n",
            "Prompt: glove urcaabiliniste brewery BritanieformațiilematiUneoriurmatoarele\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 3/5, batch 50 | joint=16.2067 task=16.1191 ppl_loss=8.7594 ppl=9229.49\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 3/5, batch 100 | joint=16.4251 task=16.3381 ppl_loss=8.6972 ppl=9011.65\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 3/5, batch 150 | joint=16.5180 task=16.4313 ppl_loss=8.6699 ppl=8453.99\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 3/5, batch 200 | joint=16.5227 task=16.4369 ppl_loss=8.5779 ppl=7792.41\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 3/5, batch 250 | joint=16.5047 task=16.4189 ppl_loss=8.5777 ppl=7949.30\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 3/5, batch 300 | joint=16.4798 task=16.3941 ppl_loss=8.5664 ppl=7753.75\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 3/5, batch 350 | joint=16.4975 task=16.4118 ppl_loss=8.5697 ppl=7901.60\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 3/5, batch 400 | joint=16.4895 task=16.4040 ppl_loss=8.5491 ppl=7691.12\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 3/5, batch 450 | joint=16.4836 task=16.3978 ppl_loss=8.5822 ppl=8312.46\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 3/5, batch 500 | joint=16.4672 task=16.3812 ppl_loss=8.5967 ppl=8475.32\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 3/5, batch 550 | joint=16.4704 task=16.3843 ppl_loss=8.6114 ppl=8674.51\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 3/5 | joint=16.4744 task=16.3884 ppl_loss=8.6080 ppl=8672.68 val_loss=21.0322 val_acc=0.7976 (true=0.8106 false=0.7761) prompt_ppl=1587.78\n",
            "Prompt: chetteambogia ($ răclângă Tu botez apucNumeTEM\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 4/5, batch 50 | joint=16.4621 task=16.3767 ppl_loss=8.5341 ppl=6902.24\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 4/5, batch 100 | joint=16.5326 task=16.4483 ppl_loss=8.4288 ppl=6268.03\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 4/5, batch 150 | joint=16.5109 task=16.4248 ppl_loss=8.6128 ppl=8786.08\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 4/5, batch 200 | joint=16.4922 task=16.4055 ppl_loss=8.6694 ppl=9526.50\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 4/5, batch 250 | joint=16.4555 task=16.3690 ppl_loss=8.6490 ppl=9108.08\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 4/5, batch 300 | joint=16.4603 task=16.3736 ppl_loss=8.6775 ppl=9451.09\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 4/5, batch 350 | joint=16.4456 task=16.3587 ppl_loss=8.6855 ppl=9670.30\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 4/5, batch 400 | joint=16.4167 task=16.3300 ppl_loss=8.6753 ppl=9650.95\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 4/5, batch 450 | joint=16.4090 task=16.3223 ppl_loss=8.6657 ppl=9499.36\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 4/5, batch 500 | joint=16.4076 task=16.3208 ppl_loss=8.6816 ppl=9687.63\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 4/5, batch 550 | joint=16.4058 task=16.3188 ppl_loss=8.6945 ppl=9818.17\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 4/5 | joint=16.4196 task=16.3327 ppl_loss=8.6882 ppl=9710.68 val_loss=19.8230 val_acc=0.7899 (true=0.8013 false=0.7712) prompt_ppl=5310.26\n",
            "Prompt: terravolu Slot senzati spatiu Luxembourgmutmnuluiombre blanche\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 5/5, batch 50 | joint=16.5246 task=16.4408 ppl_loss=8.3800 ppl=7078.48\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 5/5, batch 100 | joint=16.4293 task=16.3440 ppl_loss=8.5248 ppl=10266.98\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 5/5, batch 150 | joint=16.4709 task=16.3852 ppl_loss=8.5698 ppl=12168.93\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 5/5, batch 200 | joint=16.4986 task=16.4128 ppl_loss=8.5832 ppl=11390.53\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 5/5, batch 250 | joint=16.4792 task=16.3930 ppl_loss=8.6202 ppl=11303.48\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 5/5, batch 300 | joint=16.4384 task=16.3519 ppl_loss=8.6417 ppl=11456.10\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 5/5, batch 350 | joint=16.4219 task=16.3355 ppl_loss=8.6347 ppl=11037.26\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 5/5, batch 400 | joint=16.4573 task=16.3706 ppl_loss=8.6725 ppl=11447.88\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 5/5, batch 450 | joint=16.4645 task=16.3778 ppl_loss=8.6714 ppl=11459.44\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 5/5, batch 500 | joint=16.4837 task=16.3970 ppl_loss=8.6641 ppl=11141.63\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 5/5, batch 550 | joint=16.4943 task=16.4075 ppl_loss=8.6799 ppl=11078.14\n",
            "[PEZ λ=0.01 NON-ADV] Epoch 5/5 | joint=16.4870 task=16.4004 ppl_loss=8.6671 ppl=10890.18 val_loss=21.9137 val_acc=0.8040 (true=0.8180 false=0.7809) prompt_ppl=2595.07\n",
            "Prompt: wegachtet accesorii Raymond raspunsoricarstaticKaufentscheidungMLS Texas\n",
            "\n",
            "=== PEZ Non-Adversarial (λ=0.05) ===\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 1/5, batch 50 | joint=17.0055 task=16.5713 ppl_loss=8.6851 ppl=10801.28\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 1/5, batch 100 | joint=16.8839 task=16.4475 ppl_loss=8.7272 ppl=16760.44\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 1/5, batch 150 | joint=16.7979 task=16.3628 ppl_loss=8.7018 ppl=13882.17\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 1/5, batch 200 | joint=16.8186 task=16.3836 ppl_loss=8.6990 ppl=13317.17\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 1/5, batch 250 | joint=16.7992 task=16.3664 ppl_loss=8.6546 ppl=12010.17\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 1/5, batch 300 | joint=16.8274 task=16.3939 ppl_loss=8.6709 ppl=11886.73\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 1/5, batch 350 | joint=16.8536 task=16.4200 ppl_loss=8.6717 ppl=11398.70\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 1/5, batch 400 | joint=16.8344 task=16.4015 ppl_loss=8.6587 ppl=11064.78\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 1/5, batch 450 | joint=16.8159 task=16.3827 ppl_loss=8.6652 ppl=10762.01\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 1/5, batch 500 | joint=16.7917 task=16.3589 ppl_loss=8.6557 ppl=10532.01\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 1/5, batch 550 | joint=16.7891 task=16.3561 ppl_loss=8.6602 ppl=10505.72\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 1/5 | joint=16.7837 task=16.3500 ppl_loss=8.6744 ppl=10531.67 val_loss=21.0181 val_acc=0.7865 (true=0.7757 false=0.8044) prompt_ppl=1348.52\n",
            "Prompt: ASAuleiulvruvâr urmari pastra portofoliu Alfred mașin adica\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 2/5, batch 50 | joint=16.8480 task=16.4097 ppl_loss=8.7663 ppl=13695.54\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 2/5, batch 100 | joint=16.8017 task=16.3651 ppl_loss=8.7304 ppl=11130.77\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 2/5, batch 150 | joint=16.8072 task=16.3702 ppl_loss=8.7410 ppl=11127.56\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 2/5, batch 200 | joint=16.8113 task=16.3744 ppl_loss=8.7375 ppl=10650.84\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 2/5, batch 250 | joint=16.8085 task=16.3718 ppl_loss=8.7336 ppl=10217.84\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 2/5, batch 300 | joint=16.8051 task=16.3693 ppl_loss=8.7162 ppl=10190.73\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 2/5, batch 350 | joint=16.8444 task=16.4088 ppl_loss=8.7131 ppl=10497.46\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 2/5, batch 400 | joint=16.8526 task=16.4183 ppl_loss=8.6867 ppl=10208.40\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 2/5, batch 450 | joint=16.8682 task=16.4344 ppl_loss=8.6746 ppl=10005.67\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 2/5, batch 500 | joint=16.8630 task=16.4291 ppl_loss=8.6797 ppl=9880.18\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 2/5, batch 550 | joint=16.8700 task=16.4368 ppl_loss=8.6652 ppl=9787.96\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 2/5 | joint=16.8824 task=16.4495 ppl_loss=8.6581 ppl=9682.02 val_loss=20.9365 val_acc=0.8009 (true=0.8160 false=0.7761) prompt_ppl=6416.54\n",
            "Prompt: Ukrainianaflibeutel vault util rosiilethor reveleaza athletic\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 3/5, batch 50 | joint=16.9118 task=16.4726 ppl_loss=8.7835 ppl=9971.88\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 3/5, batch 100 | joint=16.8826 task=16.4450 ppl_loss=8.7535 ppl=9324.46\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 3/5, batch 150 | joint=16.8821 task=16.4484 ppl_loss=8.6742 ppl=9044.99\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 3/5, batch 200 | joint=16.8436 task=16.4107 ppl_loss=8.6580 ppl=9197.28\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 3/5, batch 250 | joint=16.8468 task=16.4141 ppl_loss=8.6544 ppl=9344.99\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 3/5, batch 300 | joint=16.8762 task=16.4459 ppl_loss=8.6044 ppl=8699.18\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 3/5, batch 350 | joint=16.8681 task=16.4370 ppl_loss=8.6208 ppl=9303.95\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 3/5, batch 400 | joint=16.8636 task=16.4309 ppl_loss=8.6526 ppl=9652.86\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 3/5, batch 450 | joint=16.8698 task=16.4372 ppl_loss=8.6509 ppl=9561.36\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 3/5, batch 500 | joint=16.8497 task=16.4178 ppl_loss=8.6382 ppl=9606.90\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 3/5, batch 550 | joint=16.8153 task=16.3829 ppl_loss=8.6470 ppl=9817.33\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 3/5 | joint=16.7717 task=16.3395 ppl_loss=8.6433 ppl=9904.06 val_loss=21.4255 val_acc=0.7966 (true=0.8091 false=0.7761) prompt_ppl=2124.18\n",
            "Prompt: eniebiologi răc scaunambogiahoundbutedianailléchir\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 4/5, batch 50 | joint=16.8762 task=16.4427 ppl_loss=8.6698 ppl=12079.74\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 4/5, batch 100 | joint=16.8925 task=16.4560 ppl_loss=8.7312 ppl=10522.44\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 4/5, batch 150 | joint=16.8671 task=16.4266 ppl_loss=8.8106 ppl=13279.42\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 4/5, batch 200 | joint=16.8132 task=16.3714 ppl_loss=8.8346 ppl=13072.12\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 4/5, batch 250 | joint=16.8375 task=16.3980 ppl_loss=8.7899 ppl=12152.61\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 4/5, batch 300 | joint=16.8227 task=16.3828 ppl_loss=8.7978 ppl=12058.13\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 4/5, batch 350 | joint=16.8453 task=16.4069 ppl_loss=8.7683 ppl=11601.60\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 4/5, batch 400 | joint=16.8294 task=16.3922 ppl_loss=8.7431 ppl=11179.12\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 4/5, batch 450 | joint=16.8031 task=16.3668 ppl_loss=8.7270 ppl=10798.53\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 4/5, batch 500 | joint=16.7988 task=16.3621 ppl_loss=8.7352 ppl=11122.77\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 4/5, batch 550 | joint=16.7788 task=16.3425 ppl_loss=8.7263 ppl=11114.13\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 4/5 | joint=16.7824 task=16.3471 ppl_loss=8.7048 ppl=10822.47 val_loss=20.9969 val_acc=0.7945 (true=0.7964 false=0.7914) prompt_ppl=3555.27\n",
            "Prompt: aison răcizari Penn rugamUneori stomac cloud Patspa\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 5/5, batch 50 | joint=16.8005 task=16.3554 ppl_loss=8.9013 ppl=10432.39\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 5/5, batch 100 | joint=16.8626 task=16.4195 ppl_loss=8.8616 ppl=11321.53\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 5/5, batch 150 | joint=16.8756 task=16.4346 ppl_loss=8.8194 ppl=11274.43\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 5/5, batch 200 | joint=16.8256 task=16.3852 ppl_loss=8.8096 ppl=11409.97\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 5/5, batch 250 | joint=16.8357 task=16.3980 ppl_loss=8.7548 ppl=10766.78\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 5/5, batch 300 | joint=16.8142 task=16.3775 ppl_loss=8.7340 ppl=10483.94\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 5/5, batch 350 | joint=16.7898 task=16.3534 ppl_loss=8.7269 ppl=10761.20\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 5/5, batch 400 | joint=16.8097 task=16.3737 ppl_loss=8.7183 ppl=10475.67\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 5/5, batch 450 | joint=16.8193 task=16.3831 ppl_loss=8.7254 ppl=10356.94\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 5/5, batch 500 | joint=16.8013 task=16.3651 ppl_loss=8.7238 ppl=10198.29\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 5/5, batch 550 | joint=16.7982 task=16.3624 ppl_loss=8.7160 ppl=10476.23\n",
            "[PEZ λ=0.05 NON-ADV] Epoch 5/5 | joint=16.7970 task=16.3619 ppl_loss=8.7014 ppl=10215.47 val_loss=21.4930 val_acc=0.7902 (true=0.7737 false=0.8173) prompt_ppl=29582.64\n",
            "Prompt: dru MODpovestival urmariimiOST incadr Universities Leicht\n",
            "\n",
            "=== PEZ Non-Adversarial (λ=0.1) ===\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 1/5, batch 50 | joint=17.1844 task=16.3165 ppl_loss=8.6793 ppl=10565.57\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 1/5, batch 100 | joint=17.2484 task=16.3698 ppl_loss=8.7860 ppl=11949.46\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 1/5, batch 150 | joint=17.2021 task=16.3383 ppl_loss=8.6380 ppl=10107.08\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 1/5, batch 200 | joint=17.2086 task=16.3434 ppl_loss=8.6518 ppl=10164.14\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 1/5, batch 250 | joint=17.1589 task=16.2861 ppl_loss=8.7284 ppl=11461.78\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 1/5, batch 300 | joint=17.1895 task=16.3171 ppl_loss=8.7237 ppl=11748.83\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 1/5, batch 350 | joint=17.1995 task=16.3262 ppl_loss=8.7328 ppl=11677.99\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 1/5, batch 400 | joint=17.2325 task=16.3583 ppl_loss=8.7418 ppl=11756.07\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 1/5, batch 450 | joint=17.2314 task=16.3560 ppl_loss=8.7535 ppl=11577.62\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 1/5, batch 500 | joint=17.2203 task=16.3478 ppl_loss=8.7257 ppl=11176.73\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 1/5, batch 550 | joint=17.1950 task=16.3236 ppl_loss=8.7139 ppl=11345.97\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 1/5 | joint=17.1964 task=16.3259 ppl_loss=8.7054 ppl=11072.63 val_loss=19.9264 val_acc=0.7936 (true=0.8023 false=0.7793) prompt_ppl=4716.19\n",
            "Prompt: giantFAsko Siegbürocedatmatricinsul intelegedate\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 2/5, batch 50 | joint=17.3417 task=16.4907 ppl_loss=8.5100 ppl=7114.38\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 2/5, batch 100 | joint=17.3651 task=16.5147 ppl_loss=8.5037 ppl=7292.94\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 2/5, batch 150 | joint=17.3041 task=16.4557 ppl_loss=8.4838 ppl=7366.97\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 2/5, batch 200 | joint=17.2144 task=16.3656 ppl_loss=8.4884 ppl=8193.65\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 2/5, batch 250 | joint=17.2220 task=16.3685 ppl_loss=8.5347 ppl=8968.36\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 2/5, batch 300 | joint=17.2076 task=16.3496 ppl_loss=8.5796 ppl=9164.30\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 2/5, batch 350 | joint=17.1787 task=16.3184 ppl_loss=8.6033 ppl=9770.26\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 2/5, batch 400 | joint=17.1826 task=16.3190 ppl_loss=8.6356 ppl=9879.28\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 2/5, batch 450 | joint=17.2087 task=16.3456 ppl_loss=8.6309 ppl=9677.26\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 2/5, batch 500 | joint=17.2162 task=16.3509 ppl_loss=8.6529 ppl=10004.22\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 2/5, batch 550 | joint=17.2260 task=16.3593 ppl_loss=8.6670 ppl=10256.20\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 2/5 | joint=17.2414 task=16.3756 ppl_loss=8.6584 ppl=10245.16 val_loss=21.2999 val_acc=0.7878 (true=0.7919 false=0.7809) prompt_ppl=1951.19\n",
            "Prompt: Cosmetic Giurgiu Spa incadrsectiunebeneficiar organismuluiănă Vestusch\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 3/5, batch 50 | joint=17.2703 task=16.4017 ppl_loss=8.6864 ppl=9731.04\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 3/5, batch 100 | joint=17.2873 task=16.4294 ppl_loss=8.5797 ppl=8309.54\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 3/5, batch 150 | joint=17.2833 task=16.4156 ppl_loss=8.6769 ppl=9993.58\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 3/5, batch 200 | joint=17.3147 task=16.4485 ppl_loss=8.6616 ppl=9568.20\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 3/5, batch 250 | joint=17.2973 task=16.4329 ppl_loss=8.6434 ppl=9900.71\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 3/5, batch 300 | joint=17.2951 task=16.4297 ppl_loss=8.6544 ppl=11637.05\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 3/5, batch 350 | joint=17.2850 task=16.4232 ppl_loss=8.6180 ppl=10958.79\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 3/5, batch 400 | joint=17.3023 task=16.4418 ppl_loss=8.6050 ppl=10391.49\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 3/5, batch 450 | joint=17.2702 task=16.4071 ppl_loss=8.6303 ppl=10510.00\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 3/5, batch 500 | joint=17.2791 task=16.4174 ppl_loss=8.6167 ppl=10503.86\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 3/5, batch 550 | joint=17.2627 task=16.4025 ppl_loss=8.6018 ppl=10207.46\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 3/5 | joint=17.2535 task=16.3937 ppl_loss=8.5972 ppl=10258.10 val_loss=22.1925 val_acc=0.7954 (true=0.8116 false=0.7688) prompt_ppl=4120.70\n",
            "Prompt: desfasoreliance competency Printrrachincat replica Bang intelegeChauffe\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 4/5, batch 50 | joint=17.3604 task=16.4772 ppl_loss=8.8322 ppl=11847.16\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 4/5, batch 100 | joint=17.3213 task=16.4542 ppl_loss=8.6710 ppl=10082.28\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 4/5, batch 150 | joint=17.2751 task=16.4079 ppl_loss=8.6712 ppl=9650.84\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 4/5, batch 200 | joint=17.2711 task=16.4027 ppl_loss=8.6849 ppl=9510.50\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 4/5, batch 250 | joint=17.2178 task=16.3485 ppl_loss=8.6927 ppl=9718.30\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 4/5, batch 300 | joint=17.2017 task=16.3335 ppl_loss=8.6825 ppl=9727.51\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 4/5, batch 350 | joint=17.2040 task=16.3382 ppl_loss=8.6578 ppl=9519.29\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 4/5, batch 400 | joint=17.2395 task=16.3707 ppl_loss=8.6870 ppl=10121.94\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 4/5, batch 450 | joint=17.2372 task=16.3701 ppl_loss=8.6709 ppl=9938.79\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 4/5, batch 500 | joint=17.2437 task=16.3755 ppl_loss=8.6816 ppl=10114.44\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 4/5, batch 550 | joint=17.2541 task=16.3836 ppl_loss=8.7045 ppl=10201.89\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 4/5 | joint=17.2532 task=16.3824 ppl_loss=8.7077 ppl=10130.29 val_loss=20.9853 val_acc=0.7988 (true=0.8131 false=0.7753) prompt_ppl=5990.93\n",
            "Prompt: chonimba compressioncine Transilvaniateigiolo Montana fixholz\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 5/5, batch 50 | joint=17.3547 task=16.4842 ppl_loss=8.7052 ppl=9632.12\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 5/5, batch 100 | joint=17.3328 task=16.4695 ppl_loss=8.6330 ppl=9195.52\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 5/5, batch 150 | joint=17.3062 task=16.4455 ppl_loss=8.6062 ppl=8945.61\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 5/5, batch 200 | joint=17.2903 task=16.4290 ppl_loss=8.6124 ppl=8993.48\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 5/5, batch 250 | joint=17.2698 task=16.4071 ppl_loss=8.6267 ppl=13074.01\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 5/5, batch 300 | joint=17.2528 task=16.3920 ppl_loss=8.6079 ppl=12180.75\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 5/5, batch 350 | joint=17.2334 task=16.3722 ppl_loss=8.6118 ppl=11844.92\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 5/5, batch 400 | joint=17.2096 task=16.3486 ppl_loss=8.6100 ppl=11353.58\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 5/5, batch 450 | joint=17.2410 task=16.3793 ppl_loss=8.6169 ppl=11129.88\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 5/5, batch 500 | joint=17.2483 task=16.3861 ppl_loss=8.6224 ppl=11002.51\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 5/5, batch 550 | joint=17.2445 task=16.3808 ppl_loss=8.6366 ppl=10954.54\n",
            "[PEZ λ=0.1 NON-ADV] Epoch 5/5 | joint=17.2344 task=16.3715 ppl_loss=8.6298 ppl=10680.38 val_loss=21.7382 val_acc=0.7951 (true=0.8072 false=0.7753) prompt_ppl=1661.22\n",
            "Prompt: name Kreuz Mean desfaso taiatguinApothekegardgründe relaxare\n",
            "\n",
            "=== PEZ Non-Adversarial (λ=0.25) ===\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 1/5, batch 50 | joint=18.4350 task=16.2170 ppl_loss=8.8722 ppl=9503.21\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 1/5, batch 100 | joint=18.5178 task=16.3346 ppl_loss=8.7326 ppl=8887.60\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 1/5, batch 150 | joint=18.4673 task=16.3010 ppl_loss=8.6654 ppl=8565.85\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 1/5, batch 200 | joint=18.4707 task=16.2949 ppl_loss=8.7029 ppl=9690.61\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 1/5, batch 250 | joint=18.4893 task=16.3206 ppl_loss=8.6746 ppl=9733.91\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 1/5, batch 300 | joint=18.4789 task=16.2916 ppl_loss=8.7492 ppl=10724.33\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 1/5, batch 350 | joint=18.4888 task=16.3027 ppl_loss=8.7444 ppl=10392.56\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 1/5, batch 400 | joint=18.5084 task=16.3231 ppl_loss=8.7414 ppl=10498.23\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 1/5, batch 450 | joint=18.5127 task=16.3314 ppl_loss=8.7252 ppl=10532.10\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 1/5, batch 500 | joint=18.5095 task=16.3288 ppl_loss=8.7229 ppl=10596.74\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 1/5, batch 550 | joint=18.5098 task=16.3269 ppl_loss=8.7317 ppl=10622.67\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 1/5 | joint=18.5052 task=16.3281 ppl_loss=8.7084 ppl=10368.93 val_loss=21.6377 val_acc=0.7933 (true=0.7959 false=0.7890) prompt_ppl=2004.63\n",
            "Prompt: ligjour poat Official zilei Davishibi frapp frumoasa française\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 2/5, batch 50 | joint=18.6829 task=16.4800 ppl_loss=8.8116 ppl=11120.56\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 2/5, batch 100 | joint=18.5737 task=16.4297 ppl_loss=8.5763 ppl=8866.09\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 2/5, batch 150 | joint=18.5284 task=16.3797 ppl_loss=8.5947 ppl=8716.96\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 2/5, batch 200 | joint=18.5429 task=16.3940 ppl_loss=8.5956 ppl=9036.29\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 2/5, batch 250 | joint=18.5606 task=16.4089 ppl_loss=8.6070 ppl=9028.45\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 2/5, batch 300 | joint=18.5381 task=16.3913 ppl_loss=8.5869 ppl=8671.32\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 2/5, batch 350 | joint=18.5466 task=16.3979 ppl_loss=8.5948 ppl=8640.27\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 2/5, batch 400 | joint=18.5561 task=16.4005 ppl_loss=8.6224 ppl=8757.96\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 2/5, batch 450 | joint=18.5701 task=16.4125 ppl_loss=8.6303 ppl=8770.56\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 2/5, batch 500 | joint=18.5549 task=16.3956 ppl_loss=8.6372 ppl=8934.42\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 2/5, batch 550 | joint=18.5699 task=16.4117 ppl_loss=8.6325 ppl=8845.54\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 2/5 | joint=18.5688 task=16.4102 ppl_loss=8.6343 ppl=8870.42 val_loss=21.7050 val_acc=0.7905 (true=0.7954 false=0.7825) prompt_ppl=2775.24\n",
            "Prompt: 0.05 voluntary rugam Scri resilientchette scaun obișnuiütz răc\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 3/5, batch 50 | joint=18.6981 task=16.4757 ppl_loss=8.8896 ppl=14810.52\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 3/5, batch 100 | joint=18.6723 task=16.4608 ppl_loss=8.8458 ppl=11880.55\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 3/5, batch 150 | joint=18.5652 task=16.3592 ppl_loss=8.8239 ppl=11120.41\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 3/5, batch 200 | joint=18.5486 task=16.3653 ppl_loss=8.7330 ppl=10034.45\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 3/5, batch 250 | joint=18.5554 task=16.3683 ppl_loss=8.7483 ppl=10156.45\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 3/5, batch 300 | joint=18.5947 task=16.4065 ppl_loss=8.7530 ppl=10038.98\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 3/5, batch 350 | joint=18.6085 task=16.4151 ppl_loss=8.7737 ppl=10347.75\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 3/5, batch 400 | joint=18.6042 task=16.4167 ppl_loss=8.7498 ppl=10258.36\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 3/5, batch 450 | joint=18.6010 task=16.4208 ppl_loss=8.7210 ppl=9897.98\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 3/5, batch 500 | joint=18.6052 task=16.4248 ppl_loss=8.7214 ppl=9946.58\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 3/5, batch 550 | joint=18.5845 task=16.4040 ppl_loss=8.7220 ppl=10235.62\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 3/5 | joint=18.5922 task=16.4096 ppl_loss=8.7306 ppl=10277.24 val_loss=21.7075 val_acc=0.7801 (true=0.7447 false=0.8383) prompt_ppl=27124.53\n",
            "Prompt: județ Billykro microphone Clothing Swan Cerlucrarea gradini cunoaste\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 4/5, batch 50 | joint=18.6061 task=16.3918 ppl_loss=8.8570 ppl=11600.52\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 4/5, batch 100 | joint=18.6123 task=16.4132 ppl_loss=8.7962 ppl=10754.78\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 4/5, batch 150 | joint=18.6085 task=16.4370 ppl_loss=8.6863 ppl=9322.14\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 4/5, batch 200 | joint=18.6105 task=16.4472 ppl_loss=8.6531 ppl=8814.02\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 4/5, batch 250 | joint=18.5693 task=16.4234 ppl_loss=8.5835 ppl=8143.04\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 4/5, batch 300 | joint=18.5556 task=16.4124 ppl_loss=8.5726 ppl=8168.55\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 4/5, batch 350 | joint=18.5921 task=16.4548 ppl_loss=8.5490 ppl=7967.00\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 4/5, batch 400 | joint=18.5685 task=16.4318 ppl_loss=8.5466 ppl=8214.95\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 4/5, batch 450 | joint=18.5674 task=16.4296 ppl_loss=8.5511 ppl=8095.68\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 4/5, batch 500 | joint=18.5525 task=16.4178 ppl_loss=8.5388 ppl=8048.55\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 4/5, batch 550 | joint=18.5688 task=16.4313 ppl_loss=8.5502 ppl=8188.20\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 4/5 | joint=18.5627 task=16.4197 ppl_loss=8.5719 ppl=8302.97 val_loss=20.8199 val_acc=0.7908 (true=0.7909 false=0.7906) prompt_ppl=1381.22\n",
            "Prompt: GPmontagarrondissementRetrouvez Dacia Feuerwehr Ferr Königijn Settlement\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 5/5, batch 50 | joint=18.7507 task=16.5534 ppl_loss=8.7896 ppl=11708.20\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 5/5, batch 100 | joint=18.5831 task=16.4141 ppl_loss=8.6762 ppl=9792.42\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 5/5, batch 150 | joint=18.6171 task=16.4353 ppl_loss=8.7275 ppl=9657.98\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 5/5, batch 200 | joint=18.6085 task=16.4538 ppl_loss=8.6188 ppl=9133.94\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 5/5, batch 250 | joint=18.6202 task=16.4664 ppl_loss=8.6149 ppl=8878.56\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 5/5, batch 300 | joint=18.6118 task=16.4409 ppl_loss=8.6834 ppl=10550.39\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 5/5, batch 350 | joint=18.6275 task=16.4526 ppl_loss=8.6997 ppl=10339.43\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 5/5, batch 400 | joint=18.5924 task=16.4252 ppl_loss=8.6687 ppl=9810.71\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 5/5, batch 450 | joint=18.5917 task=16.4128 ppl_loss=8.7157 ppl=10616.51\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 5/5, batch 500 | joint=18.6015 task=16.4220 ppl_loss=8.7179 ppl=10460.28\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 5/5, batch 550 | joint=18.5921 task=16.4114 ppl_loss=8.7224 ppl=10737.54\n",
            "[PEZ λ=0.25 NON-ADV] Epoch 5/5 | joint=18.5911 task=16.4138 ppl_loss=8.7090 ppl=10527.52 val_loss=21.8613 val_acc=0.7963 (true=0.8072 false=0.7785) prompt_ppl=4581.97\n",
            "Prompt: exoticcontabil Recomand studiiSfântulhrew situatiermând Tabellen tensiune\n",
            "\n",
            "=== PEZ Non-Adversarial (λ=0.5) ===\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 1/5, batch 50 | joint=20.8437 task=16.4002 ppl_loss=8.8871 ppl=14202.40\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 1/5, batch 100 | joint=20.8431 task=16.4343 ppl_loss=8.8176 ppl=12296.76\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 1/5, batch 150 | joint=20.8369 task=16.4377 ppl_loss=8.7985 ppl=12657.95\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 1/5, batch 200 | joint=20.8177 task=16.4524 ppl_loss=8.7306 ppl=11500.94\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 1/5, batch 250 | joint=20.8470 task=16.4865 ppl_loss=8.7209 ppl=10898.21\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 1/5, batch 300 | joint=20.8353 task=16.4777 ppl_loss=8.7152 ppl=11785.65\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 1/5, batch 350 | joint=20.7998 task=16.4425 ppl_loss=8.7144 ppl=11651.79\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 1/5, batch 400 | joint=20.8165 task=16.4559 ppl_loss=8.7213 ppl=11563.59\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 1/5, batch 450 | joint=20.8111 task=16.4396 ppl_loss=8.7430 ppl=11817.04\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 1/5, batch 500 | joint=20.8059 task=16.4430 ppl_loss=8.7257 ppl=11511.05\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 1/5, batch 550 | joint=20.7842 task=16.4221 ppl_loss=8.7242 ppl=11663.01\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 1/5 | joint=20.7892 task=16.4308 ppl_loss=8.7168 ppl=11515.97 val_loss=21.2016 val_acc=0.7966 (true=0.8052 false=0.7825) prompt_ppl=1647.48\n",
            "Prompt: Sorinquo plecphyomnițării animé Rivprobierteignen\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 2/5, batch 50 | joint=20.8775 task=16.4642 ppl_loss=8.8266 ppl=189114.32\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 2/5, batch 100 | joint=20.7890 task=16.4017 ppl_loss=8.7747 ppl=99477.91\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 2/5, batch 150 | joint=20.7690 task=16.4081 ppl_loss=8.7220 ppl=69295.52\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 2/5, batch 200 | joint=20.7301 task=16.4095 ppl_loss=8.6411 ppl=53535.87\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 2/5, batch 250 | joint=20.7044 task=16.3949 ppl_loss=8.6191 ppl=44824.54\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 2/5, batch 300 | joint=20.7556 task=16.4220 ppl_loss=8.6673 ppl=39990.14\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 2/5, batch 350 | joint=20.7531 task=16.4085 ppl_loss=8.6891 ppl=35844.27\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 2/5, batch 400 | joint=20.7545 task=16.4055 ppl_loss=8.6979 ppl=32588.59\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 2/5, batch 450 | joint=20.7501 task=16.4092 ppl_loss=8.6817 ppl=29841.79\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 2/5, batch 500 | joint=20.7367 task=16.4032 ppl_loss=8.6670 ppl=27612.75\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 2/5, batch 550 | joint=20.7484 task=16.4133 ppl_loss=8.6703 ppl=26298.86\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 2/5 | joint=20.7328 task=16.4027 ppl_loss=8.6603 ppl=25215.24 val_loss=21.3905 val_acc=0.7969 (true=0.8126 false=0.7712) prompt_ppl=737.64\n",
            "Prompt: üben Stuttgart Drehkreuz intrebariWürttembergclafixed Franz categorie\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 3/5, batch 50 | joint=20.5875 task=16.2669 ppl_loss=8.6412 ppl=13501.31\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 3/5, batch 100 | joint=20.6212 task=16.2979 ppl_loss=8.6466 ppl=10877.12\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 3/5, batch 150 | joint=20.6904 task=16.3509 ppl_loss=8.6790 ppl=10401.56\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 3/5, batch 200 | joint=20.6771 task=16.3287 ppl_loss=8.6968 ppl=10378.09\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 3/5, batch 250 | joint=20.6946 task=16.3153 ppl_loss=8.7585 ppl=11186.09\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 3/5, batch 300 | joint=20.6985 task=16.3448 ppl_loss=8.7073 ppl=11047.36\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 3/5, batch 350 | joint=20.6880 task=16.3317 ppl_loss=8.7125 ppl=10882.59\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 3/5, batch 400 | joint=20.6655 task=16.3103 ppl_loss=8.7104 ppl=10631.83\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 3/5, batch 450 | joint=20.6847 task=16.3235 ppl_loss=8.7222 ppl=11451.71\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 3/5, batch 500 | joint=20.6721 task=16.3008 ppl_loss=8.7425 ppl=11805.03\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 3/5, batch 550 | joint=20.6844 task=16.3249 ppl_loss=8.7190 ppl=11482.65\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 3/5 | joint=20.6896 task=16.3288 ppl_loss=8.7217 ppl=11483.23 val_loss=22.0229 val_acc=0.7960 (true=0.7964 false=0.7955) prompt_ppl=3433.84\n",
            "Prompt: usziehbardatorita botez cunoaste astazi PopescuRhône sfânt Casual boug\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 4/5, batch 50 | joint=20.5783 task=16.3430 ppl_loss=8.4705 ppl=7256.42\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 4/5, batch 100 | joint=20.7240 task=16.4454 ppl_loss=8.5570 ppl=8458.21\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 4/5, batch 150 | joint=20.7265 task=16.4534 ppl_loss=8.5462 ppl=8933.07\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 4/5, batch 200 | joint=20.7630 task=16.4432 ppl_loss=8.6396 ppl=9459.43\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 4/5, batch 250 | joint=20.7539 task=16.4364 ppl_loss=8.6352 ppl=9240.50\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 4/5, batch 300 | joint=20.7603 task=16.4526 ppl_loss=8.6154 ppl=8888.51\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 4/5, batch 350 | joint=20.7942 task=16.4740 ppl_loss=8.6403 ppl=9926.95\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 4/5, batch 400 | joint=20.7729 task=16.4487 ppl_loss=8.6485 ppl=10181.44\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 4/5, batch 450 | joint=20.7576 task=16.4275 ppl_loss=8.6602 ppl=10097.85\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 4/5, batch 500 | joint=20.7680 task=16.4389 ppl_loss=8.6581 ppl=10349.75\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 4/5, batch 550 | joint=20.7517 task=16.4274 ppl_loss=8.6486 ppl=10210.16\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 4/5 | joint=20.7629 task=16.4317 ppl_loss=8.6625 ppl=10459.69 val_loss=20.9343 val_acc=0.7976 (true=0.8155 false=0.7680) prompt_ppl=8615.37\n",
            "Prompt: OTT plimbPASS ChasebabuciionismGigUneorilei\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 5/5, batch 50 | joint=20.7472 task=16.3438 ppl_loss=8.8068 ppl=9936.62\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 5/5, batch 100 | joint=20.6403 task=16.3039 ppl_loss=8.6729 ppl=8718.67\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 5/5, batch 150 | joint=20.6269 task=16.3044 ppl_loss=8.6450 ppl=9792.69\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 5/5, batch 200 | joint=20.6669 task=16.3546 ppl_loss=8.6247 ppl=9879.51\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 5/5, batch 250 | joint=20.7025 task=16.3799 ppl_loss=8.6451 ppl=9802.93\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 5/5, batch 300 | joint=20.6830 task=16.3479 ppl_loss=8.6702 ppl=9800.12\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 5/5, batch 350 | joint=20.6879 task=16.3636 ppl_loss=8.6486 ppl=9404.84\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 5/5, batch 400 | joint=20.6819 task=16.3651 ppl_loss=8.6336 ppl=9419.32\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 5/5, batch 450 | joint=20.6980 task=16.3733 ppl_loss=8.6493 ppl=9470.48\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 5/5, batch 500 | joint=20.7135 task=16.3909 ppl_loss=8.6454 ppl=9391.16\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 5/5, batch 550 | joint=20.7227 task=16.3919 ppl_loss=8.6616 ppl=9424.36\n",
            "[PEZ λ=0.5 NON-ADV] Epoch 5/5 | joint=20.7248 task=16.4017 ppl_loss=8.6462 ppl=9239.21 val_loss=20.9862 val_acc=0.7847 (true=0.7727 false=0.8044) prompt_ppl=14340.24\n",
            "Prompt: incercat prote desfasoDamegentpore whale bot Travis calatori\n",
            "\n",
            "=== PEZ Non-Adversarial (λ=0.75) ===\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 1/5, batch 50 | joint=22.9230 task=16.4303 ppl_loss=8.6570 ppl=11858.63\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 1/5, batch 100 | joint=22.7867 task=16.3221 ppl_loss=8.6194 ppl=9522.75\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 1/5, batch 150 | joint=22.8312 task=16.3346 ppl_loss=8.6620 ppl=10432.27\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 1/5, batch 200 | joint=22.8053 task=16.3292 ppl_loss=8.6348 ppl=9828.96\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 1/5, batch 250 | joint=22.8466 task=16.3404 ppl_loss=8.6749 ppl=10074.59\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 1/5, batch 300 | joint=22.8477 task=16.3469 ppl_loss=8.6678 ppl=9988.55\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 1/5, batch 350 | joint=22.8467 task=16.3362 ppl_loss=8.6806 ppl=9996.10\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 1/5, batch 400 | joint=22.8404 task=16.3221 ppl_loss=8.6910 ppl=10317.79\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 1/5, batch 450 | joint=22.8241 task=16.3013 ppl_loss=8.6971 ppl=10185.94\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 1/5, batch 500 | joint=22.8345 task=16.3174 ppl_loss=8.6894 ppl=9925.63\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 1/5, batch 550 | joint=22.8454 task=16.3301 ppl_loss=8.6870 ppl=9881.10\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 1/5 | joint=22.8549 task=16.3366 ppl_loss=8.6910 ppl=9889.38 val_loss=20.2118 val_acc=0.7924 (true=0.7944 false=0.7890) prompt_ppl=5695.86\n",
            "Prompt: licateArticolultempoUneorirmând clientilorCopiii TotGEStură\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 2/5, batch 50 | joint=22.7318 task=16.4788 ppl_loss=8.3373 ppl=8271.55\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 2/5, batch 100 | joint=22.8113 task=16.4917 ppl_loss=8.4262 ppl=7680.00\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 2/5, batch 150 | joint=22.7859 task=16.3579 ppl_loss=8.5707 ppl=9752.89\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 2/5, batch 200 | joint=22.8071 task=16.3594 ppl_loss=8.5969 ppl=9612.44\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 2/5, batch 250 | joint=22.7527 task=16.3090 ppl_loss=8.5916 ppl=10396.99\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 2/5, batch 300 | joint=22.7355 task=16.2784 ppl_loss=8.6095 ppl=10272.40\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 2/5, batch 350 | joint=22.7254 task=16.2724 ppl_loss=8.6040 ppl=9857.48\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 2/5, batch 400 | joint=22.7405 task=16.2918 ppl_loss=8.5982 ppl=9724.09\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 2/5, batch 450 | joint=22.7500 task=16.2882 ppl_loss=8.6158 ppl=10032.83\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 2/5, batch 500 | joint=22.7632 task=16.2866 ppl_loss=8.6355 ppl=10069.40\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 2/5, batch 550 | joint=22.7577 task=16.2827 ppl_loss=8.6333 ppl=9995.25\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 2/5 | joint=22.7813 task=16.3053 ppl_loss=8.6347 ppl=9922.58 val_loss=21.3505 val_acc=0.8009 (true=0.8146 false=0.7785) prompt_ppl=21533.14\n",
            "Prompt: plex harbour Joshua thrustugijour închirinselOU Mol\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 3/5, batch 50 | joint=22.5199 task=16.2967 ppl_loss=8.2976 ppl=6124.98\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 3/5, batch 100 | joint=22.8281 task=16.4738 ppl_loss=8.4724 ppl=7331.60\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 3/5, batch 150 | joint=22.8893 task=16.3558 ppl_loss=8.7114 ppl=10840.45\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 3/5, batch 200 | joint=22.8406 task=16.3577 ppl_loss=8.6439 ppl=10117.00\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 3/5, batch 250 | joint=22.8544 task=16.3880 ppl_loss=8.6218 ppl=9785.28\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 3/5, batch 300 | joint=22.8095 task=16.3531 ppl_loss=8.6085 ppl=9445.70\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 3/5, batch 350 | joint=22.8110 task=16.3632 ppl_loss=8.5972 ppl=9365.87\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 3/5, batch 400 | joint=22.8172 task=16.3590 ppl_loss=8.6108 ppl=9355.25\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 3/5, batch 450 | joint=22.8398 task=16.3630 ppl_loss=8.6358 ppl=9772.69\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 3/5, batch 500 | joint=22.8430 task=16.3711 ppl_loss=8.6292 ppl=9599.02\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 3/5, batch 550 | joint=22.8324 task=16.3592 ppl_loss=8.6310 ppl=9577.16\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 3/5 | joint=22.8378 task=16.3586 ppl_loss=8.6390 ppl=10586.32 val_loss=20.0751 val_acc=0.7820 (true=0.7609 false=0.8165) prompt_ppl=3971.04\n",
            "Prompt: iga carriage echipe reccarvedradeCF Salvador voilà Trag\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 4/5, batch 50 | joint=22.9433 task=16.3342 ppl_loss=8.8122 ppl=9348.97\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 4/5, batch 100 | joint=22.8798 task=16.2819 ppl_loss=8.7972 ppl=11322.85\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 4/5, batch 150 | joint=22.8281 task=16.3062 ppl_loss=8.6959 ppl=9920.89\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 4/5, batch 200 | joint=22.8129 task=16.3151 ppl_loss=8.6638 ppl=9793.38\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 4/5, batch 250 | joint=22.8483 task=16.3659 ppl_loss=8.6432 ppl=10293.40\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 4/5, batch 300 | joint=22.8426 task=16.3728 ppl_loss=8.6265 ppl=9819.34\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 4/5, batch 350 | joint=22.8395 task=16.3594 ppl_loss=8.6402 ppl=9853.91\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 4/5, batch 400 | joint=22.8495 task=16.3719 ppl_loss=8.6368 ppl=9780.43\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 4/5, batch 450 | joint=22.8614 task=16.3729 ppl_loss=8.6514 ppl=9883.53\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 4/5, batch 500 | joint=22.8784 task=16.3870 ppl_loss=8.6552 ppl=9885.50\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 4/5, batch 550 | joint=22.8845 task=16.3916 ppl_loss=8.6572 ppl=9747.15\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 4/5 | joint=22.8885 task=16.4118 ppl_loss=8.6357 ppl=9493.16 val_loss=20.1555 val_acc=0.7930 (true=0.7909 false=0.7963) prompt_ppl=1278.26\n",
            "Prompt: masuri parintipetit răc Heimelte Stuhltentbling campanii\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 5/5, batch 50 | joint=22.8232 task=16.2661 ppl_loss=8.7428 ppl=10238.17\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 5/5, batch 100 | joint=22.8493 task=16.3467 ppl_loss=8.6702 ppl=9351.85\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 5/5, batch 150 | joint=22.9330 task=16.4565 ppl_loss=8.6353 ppl=8986.45\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 5/5, batch 200 | joint=22.9080 task=16.4358 ppl_loss=8.6296 ppl=8976.59\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 5/5, batch 250 | joint=22.9273 task=16.4610 ppl_loss=8.6218 ppl=9212.21\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 5/5, batch 300 | joint=22.9142 task=16.4390 ppl_loss=8.6336 ppl=9202.28\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 5/5, batch 350 | joint=22.8954 task=16.4227 ppl_loss=8.6303 ppl=9086.13\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 5/5, batch 400 | joint=22.8940 task=16.4178 ppl_loss=8.6349 ppl=8941.37\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 5/5, batch 450 | joint=22.9125 task=16.4350 ppl_loss=8.6367 ppl=8953.45\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 5/5, batch 500 | joint=22.9022 task=16.4238 ppl_loss=8.6378 ppl=8933.88\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 5/5, batch 550 | joint=22.8872 task=16.4097 ppl_loss=8.6367 ppl=9020.79\n",
            "[PEZ λ=0.75 NON-ADV] Epoch 5/5 | joint=22.8739 task=16.3833 ppl_loss=8.6541 ppl=9122.38 val_loss=22.6479 val_acc=0.8009 (true=0.8219 false=0.7664) prompt_ppl=9078.36\n",
            "Prompt: obligatoriu Brust etajsighted Hüt dureri masura BrüAssociatedudder\n",
            "\n",
            "=== PEZ Non-Adversarial (λ=1.0) ===\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 139.81 GiB of which 10.81 MiB is free. Process 1998502 has 42.81 GiB memory in use. Process 2104507 has 16.25 GiB memory in use. Process 3802138 has 80.72 GiB memory in use. Of the allocated memory 40.06 GiB is allocated by PyTorch, and 2.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lam \u001b[38;5;129;01min\u001b[39;00m lambda_grid:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== PEZ Non-Adversarial (λ=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     pez_non_adv \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_pez\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgpt2_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgpt2_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlambda_ppl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43madversarial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     pez_runs\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpez_non_adv\u001b[39m\u001b[38;5;124m\"\u001b[39m, lam, pez_non_adv))\n",
            "Cell \u001b[0;32mIn[10], line 52\u001b[0m, in \u001b[0;36mtrain_pez\u001b[0;34m(cfg, tokenizer, gpt2_model, gpt2_tokenizer, train_dl, val_dl, lambda_ppl, adversarial, log_every)\u001b[0m\n\u001b[1;32m     48\u001b[0m labels         \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     50\u001b[0m model\u001b[38;5;241m.\u001b[39mprompt\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m task_loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# ---- perplexity term ----\u001b[39;00m\n",
            "File \u001b[0;32m~/other/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/other/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[6], line 67\u001b[0m, in \u001b[0;36mT5PEZPrompt.forward\u001b[0;34m(self, input_ids, attention_mask, labels)\u001b[0m\n\u001b[1;32m     64\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([prompt_mask, attention_mask], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# 5) Standard T5 forward\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt5\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
            "File \u001b[0;32m~/other/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/other/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/other/.venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1764\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1761\u001b[0m         decoder_attention_mask \u001b[38;5;241m=\u001b[39m decoder_attention_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[1;32m   1763\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[0;32m-> 1764\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1767\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1773\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1774\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1775\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1778\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1780\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m decoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
            "File \u001b[0;32m~/other/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/other/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/other/.venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1100\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m   1098\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[0;32m-> 1100\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1116\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;66;03m# We share the position biases between the layers - the first layer store them\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;66;03m# layer_outputs = hidden-states, key-value-states (self-attention position bias), (self-attention weights),\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;66;03m# (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n",
            "File \u001b[0;32m~/other/.venv/lib/python3.10/site-packages/transformers/modeling_layers.py:94\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning_once(message)\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/other/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/other/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/other/.venv/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/other/.venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:711\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_values, use_cache, output_attentions, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    709\u001b[0m do_cross_attention \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;129;01mand\u001b[39;00m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_cross_attention:\n\u001b[0;32m--> 711\u001b[0m     cross_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    722\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;66;03m# clamp inf values to enable fp16 training\u001b[39;00m\n",
            "File \u001b[0;32m~/other/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/other/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/other/.venv/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/other/.venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:640\u001b[0m, in \u001b[0;36mT5LayerCrossAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, attention_mask, position_bias, layer_head_mask, past_key_values, use_cache, query_length, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_value\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.58\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    637\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    638\u001b[0m ):\n\u001b[1;32m    639\u001b[0m     normed_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 640\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEncDecAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_value_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    652\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_output[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    653\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m attention_output[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
            "File \u001b[0;32m~/other/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/other/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/other/.venv/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/other/.venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:521\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_values, layer_head_mask, query_length, use_cache, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;66;03m# save all key/value_states to cache to be re-used for fast auto-regressive generation\u001b[39;00m\n\u001b[1;32m    520\u001b[0m     cache_position \u001b[38;5;241m=\u001b[39m cache_position \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cross_attention \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 521\u001b[0m     key_states, value_states \u001b[38;5;241m=\u001b[39m \u001b[43mcurr_past_key_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcache_position\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;66;03m# set flag that curr layer for cross-attn is already updated so we can re-use in subsequent calls\u001b[39;00m\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_cross_attention \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(past_key_values, EncoderDecoderCache):\n",
            "File \u001b[0;32m~/other/.venv/lib/python3.10/site-packages/transformers/cache_utils.py:776\u001b[0m, in \u001b[0;36mCache.update\u001b[0;34m(self, key_states, value_states, layer_idx, cache_kwargs)\u001b[0m\n\u001b[1;32m    773\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_stream(key_states\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mwait_stream(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefetch_stream)\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefetch(layer_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39monly_non_sliding)\n\u001b[0;32m--> 776\u001b[0m keys, values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffloading:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffload(layer_idx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39monly_non_sliding)\n",
            "File \u001b[0;32m~/other/.venv/lib/python3.10/site-packages/transformers/cache_utils.py:120\u001b[0m, in \u001b[0;36mDynamicLayer.update\u001b[0;34m(self, key_states, value_states, cache_kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy_initialization(key_states)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys, key_states], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 139.81 GiB of which 10.81 MiB is free. Process 1998502 has 42.81 GiB memory in use. Process 2104507 has 16.25 GiB memory in use. Process 3802138 has 80.72 GiB memory in use. Of the allocated memory 40.06 GiB is allocated by PyTorch, and 2.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "# PEZ runs over lambda grid\n",
        "pez_runs = []\n",
        "lambda_grid = [0.0, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1.0]\n",
        "for lam in lambda_grid:\n",
        "    print(f\"\\n=== PEZ Non-Adversarial (λ={lam}) ===\")\n",
        "    pez_non_adv = train_pez(\n",
        "        cfg,\n",
        "        tokenizer,\n",
        "        gpt2_model,\n",
        "        gpt2_tokenizer,\n",
        "        train_dl,\n",
        "        val_dl,\n",
        "        lambda_ppl=lam,\n",
        "        adversarial=False,\n",
        "    )\n",
        "    pez_runs.append((\"pez_non_adv\", lam, pez_non_adv))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved all non-adv models + histories.\n"
          ]
        }
      ],
      "source": [
        "import torch, json, os\n",
        "\n",
        "base_dir = \"/mnt/polished-lake/home/annabelma/other/results/unbalanced/pez_non_adv_models\"\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "for model_name, lam, result in pez_runs:\n",
        "    model = result[\"model\"]\n",
        "    \n",
        "    # Save model weights\n",
        "    torch.save(model.state_dict(), f\"{base_dir}/model_lambda_{lam}.pt\")\n",
        "    \n",
        "    # Save history\n",
        "    with open(f\"{base_dir}/history_lambda_{lam}.json\", \"w\") as f:\n",
        "        json.dump(result[\"history\"], f, indent=2)\n",
        "\n",
        "print(\"Saved all non-adv models + histories.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3px3Kpl6IvG",
        "outputId": "bb4f6831-ee58-400d-f39f-54d7be1f4d57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== PEZ Adversarial (λ=0.0) ===\n",
            "[PEZ λ=0.0 ADV] Epoch 1/5, batch 50 | joint=16.6345 task=16.6345 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 1/5, batch 100 | joint=16.4913 task=16.4913 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 1/5, batch 150 | joint=16.4590 task=16.4590 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 1/5, batch 200 | joint=16.4226 task=16.4226 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 1/5, batch 250 | joint=16.4320 task=16.4320 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 1/5, batch 300 | joint=16.4185 task=16.4185 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 1/5, batch 350 | joint=16.4215 task=16.4215 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 1/5, batch 400 | joint=16.4405 task=16.4405 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 1/5, batch 450 | joint=16.4304 task=16.4304 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 1/5, batch 500 | joint=16.4147 task=16.4147 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 1/5, batch 550 | joint=16.3935 task=16.3935 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 1/5 | joint=16.3875 task=16.3875 ppl_loss=0.0000 ppl=0.00 val_loss=19.3548 val_acc=0.7853 (true=0.7688 false=0.8124) prompt_ppl=0.00\n",
            "Prompt: simti senzatitreu Wur propane McGhaltFahr stiu procurori\n",
            "[PEZ λ=0.0 ADV] Epoch 2/5, batch 50 | joint=16.5829 task=16.5829 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 2/5, batch 100 | joint=16.4858 task=16.4858 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 2/5, batch 150 | joint=16.4945 task=16.4945 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 2/5, batch 200 | joint=16.4832 task=16.4832 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 2/5, batch 250 | joint=16.4675 task=16.4675 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 2/5, batch 300 | joint=16.4421 task=16.4421 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 2/5, batch 350 | joint=16.4739 task=16.4739 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 2/5, batch 400 | joint=16.4445 task=16.4445 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 2/5, batch 450 | joint=16.4091 task=16.4091 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 2/5, batch 500 | joint=16.3953 task=16.3953 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 2/5, batch 550 | joint=16.4050 task=16.4050 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 2/5 | joint=16.4024 task=16.4024 ppl_loss=0.0000 ppl=0.00 val_loss=20.0206 val_acc=0.7890 (true=0.7969 false=0.7761) prompt_ppl=0.00\n",
            "Prompt: äck situatie suprafeteEdituracurgêt ceilalti elev litrischl\n",
            "[PEZ λ=0.0 ADV] Epoch 3/5, batch 50 | joint=16.3029 task=16.3029 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 3/5, batch 100 | joint=16.4288 task=16.4288 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 3/5, batch 150 | joint=16.4369 task=16.4369 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 3/5, batch 200 | joint=16.4788 task=16.4788 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 3/5, batch 250 | joint=16.4844 task=16.4844 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 3/5, batch 300 | joint=16.4197 task=16.4197 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 3/5, batch 350 | joint=16.3953 task=16.3953 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 3/5, batch 400 | joint=16.3780 task=16.3780 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 3/5, batch 450 | joint=16.3580 task=16.3580 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 3/5, batch 500 | joint=16.3537 task=16.3537 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 3/5, batch 550 | joint=16.3728 task=16.3728 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 3/5 | joint=16.3801 task=16.3801 ppl_loss=0.0000 ppl=0.00 val_loss=21.4175 val_acc=0.7896 (true=0.7865 false=0.7947) prompt_ppl=0.00\n",
            "Prompt: stomacpendant dimineata clientilorvâr metadata obtinut carcas obtine tara\n",
            "[PEZ λ=0.0 ADV] Epoch 4/5, batch 50 | joint=16.4013 task=16.4013 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 4/5, batch 100 | joint=16.3071 task=16.3071 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 4/5, batch 150 | joint=16.3546 task=16.3546 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 4/5, batch 200 | joint=16.3479 task=16.3479 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 4/5, batch 250 | joint=16.3603 task=16.3603 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 4/5, batch 300 | joint=16.3248 task=16.3248 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 4/5, batch 350 | joint=16.3324 task=16.3324 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 4/5, batch 400 | joint=16.3383 task=16.3383 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 4/5, batch 450 | joint=16.3482 task=16.3482 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 4/5, batch 500 | joint=16.3520 task=16.3520 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 4/5, batch 550 | joint=16.3766 task=16.3766 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 4/5 | joint=16.3839 task=16.3839 ppl_loss=0.0000 ppl=0.00 val_loss=20.5516 val_acc=0.7948 (true=0.8062 false=0.7761) prompt_ppl=0.00\n",
            "Prompt: majPalatul Ras superioara clientilorigi Ioan NicolaeGiro fizic\n",
            "[PEZ λ=0.0 ADV] Epoch 5/5, batch 50 | joint=16.5508 task=16.5508 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 5/5, batch 100 | joint=16.4985 task=16.4985 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 5/5, batch 150 | joint=16.4649 task=16.4649 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 5/5, batch 200 | joint=16.4472 task=16.4472 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 5/5, batch 250 | joint=16.4225 task=16.4225 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 5/5, batch 300 | joint=16.4292 task=16.4292 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 5/5, batch 350 | joint=16.4361 task=16.4361 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 5/5, batch 400 | joint=16.4455 task=16.4455 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 5/5, batch 450 | joint=16.4316 task=16.4316 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 5/5, batch 500 | joint=16.4354 task=16.4354 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 5/5, batch 550 | joint=16.4279 task=16.4279 ppl_loss=0.0000 ppl=0.00\n",
            "[PEZ λ=0.0 ADV] Epoch 5/5 | joint=16.4521 task=16.4521 ppl_loss=0.0000 ppl=0.00 val_loss=20.9786 val_acc=0.7887 (true=0.7855 false=0.7939) prompt_ppl=0.00\n",
            "Prompt: intreb absentoara senzati parinti închiriChauffeescent Bahrainută\n",
            "\n",
            "=== PEZ Adversarial (λ=0.01) ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PEZ λ=0.01 ADV] Epoch 1/5, batch 50 | joint=16.3217 task=16.2353 ppl_loss=8.6480 ppl=8719.34\n",
            "[PEZ λ=0.01 ADV] Epoch 1/5, batch 100 | joint=16.3826 task=16.2963 ppl_loss=8.6297 ppl=8560.89\n",
            "[PEZ λ=0.01 ADV] Epoch 1/5, batch 150 | joint=16.3746 task=16.2873 ppl_loss=8.7316 ppl=10547.45\n",
            "[PEZ λ=0.01 ADV] Epoch 1/5, batch 200 | joint=16.3962 task=16.3095 ppl_loss=8.6736 ppl=10024.85\n",
            "[PEZ λ=0.01 ADV] Epoch 1/5, batch 250 | joint=16.3999 task=16.3132 ppl_loss=8.6701 ppl=10031.68\n",
            "[PEZ λ=0.01 ADV] Epoch 1/5, batch 300 | joint=16.4219 task=16.3347 ppl_loss=8.7141 ppl=10683.38\n",
            "[PEZ λ=0.01 ADV] Epoch 1/5, batch 350 | joint=16.4579 task=16.3707 ppl_loss=8.7149 ppl=10459.44\n",
            "[PEZ λ=0.01 ADV] Epoch 1/5, batch 400 | joint=16.4614 task=16.3743 ppl_loss=8.7041 ppl=10253.65\n",
            "[PEZ λ=0.01 ADV] Epoch 1/5, batch 450 | joint=16.4762 task=16.3891 ppl_loss=8.7109 ppl=10652.06\n",
            "[PEZ λ=0.01 ADV] Epoch 1/5, batch 500 | joint=16.4896 task=16.4027 ppl_loss=8.6950 ppl=10575.08\n",
            "[PEZ λ=0.01 ADV] Epoch 1/5, batch 550 | joint=16.4798 task=16.3930 ppl_loss=8.6772 ppl=10332.08\n",
            "[PEZ λ=0.01 ADV] Epoch 1/5 | joint=16.4740 task=16.3873 ppl_loss=8.6691 ppl=10267.91 val_loss=21.1479 val_acc=0.7911 (true=0.7939 false=0.7866) prompt_ppl=1125.18\n",
            "Prompt: uleiul couchesilletDatoritaPF sănătos prevazutKollektmajpli\n",
            "[PEZ λ=0.01 ADV] Epoch 2/5, batch 50 | joint=16.2835 task=16.1970 ppl_loss=8.6469 ppl=7400.76\n",
            "[PEZ λ=0.01 ADV] Epoch 2/5, batch 100 | joint=16.4017 task=16.3148 ppl_loss=8.6871 ppl=8169.07\n",
            "[PEZ λ=0.01 ADV] Epoch 2/5, batch 150 | joint=16.4571 task=16.3708 ppl_loss=8.6294 ppl=9386.52\n",
            "[PEZ λ=0.01 ADV] Epoch 2/5, batch 200 | joint=16.4168 task=16.3307 ppl_loss=8.6127 ppl=9273.68\n",
            "[PEZ λ=0.01 ADV] Epoch 2/5, batch 250 | joint=16.4250 task=16.3391 ppl_loss=8.5920 ppl=8757.72\n",
            "[PEZ λ=0.01 ADV] Epoch 2/5, batch 300 | joint=16.4296 task=16.3434 ppl_loss=8.6222 ppl=9345.14\n",
            "[PEZ λ=0.01 ADV] Epoch 2/5, batch 350 | joint=16.4445 task=16.3581 ppl_loss=8.6443 ppl=11103.28\n",
            "[PEZ λ=0.01 ADV] Epoch 2/5, batch 400 | joint=16.4630 task=16.3762 ppl_loss=8.6712 ppl=11521.53\n",
            "[PEZ λ=0.01 ADV] Epoch 2/5, batch 450 | joint=16.4745 task=16.3876 ppl_loss=8.6850 ppl=11974.67\n",
            "[PEZ λ=0.01 ADV] Epoch 2/5, batch 500 | joint=16.4629 task=16.3762 ppl_loss=8.6662 ppl=11745.50\n",
            "[PEZ λ=0.01 ADV] Epoch 2/5, batch 550 | joint=16.4887 task=16.4022 ppl_loss=8.6493 ppl=11341.28\n",
            "[PEZ λ=0.01 ADV] Epoch 2/5 | joint=16.4813 task=16.3948 ppl_loss=8.6442 ppl=11367.43 val_loss=22.2877 val_acc=0.7908 (true=0.7801 false=0.8084) prompt_ppl=2731.12\n",
            "Prompt: chauffeur stâng inregistrat mars mecaniclexicBisericaAppeals inlocui rugam\n",
            "[PEZ λ=0.01 ADV] Epoch 3/5, batch 50 | joint=16.5026 task=16.4182 ppl_loss=8.4328 ppl=7414.95\n",
            "[PEZ λ=0.01 ADV] Epoch 3/5, batch 100 | joint=16.4535 task=16.3679 ppl_loss=8.5575 ppl=7860.67\n",
            "[PEZ λ=0.01 ADV] Epoch 3/5, batch 150 | joint=16.5581 task=16.4730 ppl_loss=8.5085 ppl=8188.67\n",
            "[PEZ λ=0.01 ADV] Epoch 3/5, batch 200 | joint=16.5310 task=16.4459 ppl_loss=8.5171 ppl=7872.23\n",
            "[PEZ λ=0.01 ADV] Epoch 3/5, batch 250 | joint=16.5515 task=16.4661 ppl_loss=8.5358 ppl=7757.00\n",
            "[PEZ λ=0.01 ADV] Epoch 3/5, batch 300 | joint=16.5669 task=16.4815 ppl_loss=8.5343 ppl=7645.98\n",
            "[PEZ λ=0.01 ADV] Epoch 3/5, batch 350 | joint=16.5715 task=16.4861 ppl_loss=8.5442 ppl=7597.54\n",
            "[PEZ λ=0.01 ADV] Epoch 3/5, batch 400 | joint=16.5586 task=16.4727 ppl_loss=8.5886 ppl=8280.99\n",
            "[PEZ λ=0.01 ADV] Epoch 3/5, batch 450 | joint=16.5241 task=16.4382 ppl_loss=8.5921 ppl=8506.01\n",
            "[PEZ λ=0.01 ADV] Epoch 3/5, batch 500 | joint=16.5087 task=16.4226 ppl_loss=8.6153 ppl=8971.34\n",
            "[PEZ λ=0.01 ADV] Epoch 3/5, batch 550 | joint=16.5234 task=16.4373 ppl_loss=8.6128 ppl=8940.47\n",
            "[PEZ λ=0.01 ADV] Epoch 3/5 | joint=16.4897 task=16.4033 ppl_loss=8.6372 ppl=9289.88 val_loss=21.3949 val_acc=0.7899 (true=0.7885 false=0.7922) prompt_ppl=12126.26\n",
            "Prompt: dunkel Fl machiajgonIOgrove Jackudi Ruf intelege\n",
            "[PEZ λ=0.01 ADV] Epoch 4/5, batch 50 | joint=16.3479 task=16.2628 ppl_loss=8.5081 ppl=6685.23\n",
            "[PEZ λ=0.01 ADV] Epoch 4/5, batch 100 | joint=16.4386 task=16.3526 ppl_loss=8.5979 ppl=8167.46\n",
            "[PEZ λ=0.01 ADV] Epoch 4/5, batch 150 | joint=16.4641 task=16.3773 ppl_loss=8.6847 ppl=10472.36\n",
            "[PEZ λ=0.01 ADV] Epoch 4/5, batch 200 | joint=16.4316 task=16.3449 ppl_loss=8.6794 ppl=9991.44\n",
            "[PEZ λ=0.01 ADV] Epoch 4/5, batch 250 | joint=16.4419 task=16.3552 ppl_loss=8.6684 ppl=10297.97\n",
            "[PEZ λ=0.01 ADV] Epoch 4/5, batch 300 | joint=16.4151 task=16.3286 ppl_loss=8.6544 ppl=10058.20\n",
            "[PEZ λ=0.01 ADV] Epoch 4/5, batch 350 | joint=16.4320 task=16.3455 ppl_loss=8.6531 ppl=10364.88\n",
            "[PEZ λ=0.01 ADV] Epoch 4/5, batch 400 | joint=16.4399 task=16.3536 ppl_loss=8.6288 ppl=10188.89\n",
            "[PEZ λ=0.01 ADV] Epoch 4/5, batch 450 | joint=16.4598 task=16.3736 ppl_loss=8.6179 ppl=10160.99\n",
            "[PEZ λ=0.01 ADV] Epoch 4/5, batch 500 | joint=16.4413 task=16.3550 ppl_loss=8.6342 ppl=10179.25\n",
            "[PEZ λ=0.01 ADV] Epoch 4/5, batch 550 | joint=16.4303 task=16.3438 ppl_loss=8.6518 ppl=10228.65\n",
            "[PEZ λ=0.01 ADV] Epoch 4/5 | joint=16.4491 task=16.3626 ppl_loss=8.6500 ppl=10497.38 val_loss=20.4550 val_acc=0.7887 (true=0.7791 false=0.8044) prompt_ppl=19909.69\n",
            "Prompt: gardinenDatorita Sfant parcare Belfast prilej portofoliu Hum imagination calatori\n",
            "[PEZ λ=0.01 ADV] Epoch 5/5, batch 50 | joint=16.4780 task=16.3911 ppl_loss=8.6866 ppl=9070.79\n",
            "[PEZ λ=0.01 ADV] Epoch 5/5, batch 100 | joint=16.3593 task=16.2721 ppl_loss=8.7232 ppl=10396.41\n",
            "[PEZ λ=0.01 ADV] Epoch 5/5, batch 150 | joint=16.3814 task=16.2938 ppl_loss=8.7619 ppl=10440.28\n",
            "[PEZ λ=0.01 ADV] Epoch 5/5, batch 200 | joint=16.4007 task=16.3131 ppl_loss=8.7589 ppl=10643.75\n",
            "[PEZ λ=0.01 ADV] Epoch 5/5, batch 250 | joint=16.4378 task=16.3507 ppl_loss=8.7142 ppl=10268.30\n",
            "[PEZ λ=0.01 ADV] Epoch 5/5, batch 300 | joint=16.4739 task=16.3866 ppl_loss=8.7327 ppl=10233.62\n",
            "[PEZ λ=0.01 ADV] Epoch 5/5, batch 350 | joint=16.4735 task=16.3862 ppl_loss=8.7233 ppl=10227.15\n",
            "[PEZ λ=0.01 ADV] Epoch 5/5, batch 400 | joint=16.4486 task=16.3611 ppl_loss=8.7492 ppl=12205.37\n",
            "[PEZ λ=0.01 ADV] Epoch 5/5, batch 450 | joint=16.4377 task=16.3500 ppl_loss=8.7670 ppl=12221.17\n",
            "[PEZ λ=0.01 ADV] Epoch 5/5, batch 500 | joint=16.4299 task=16.3424 ppl_loss=8.7467 ppl=11779.71\n",
            "[PEZ λ=0.01 ADV] Epoch 5/5, batch 550 | joint=16.4425 task=16.3550 ppl_loss=8.7502 ppl=11608.19\n",
            "[PEZ λ=0.01 ADV] Epoch 5/5 | joint=16.4459 task=16.3586 ppl_loss=8.7273 ppl=11400.48 val_loss=21.1720 val_acc=0.7948 (true=0.8052 false=0.7777) prompt_ppl=2582.60\n",
            "Prompt: perechentrepid ofera ascend baletapaServiciul intampla clientilorntrepid\n",
            "\n",
            "=== PEZ Adversarial (λ=0.05) ===\n",
            "[PEZ λ=0.05 ADV] Epoch 1/5, batch 50 | joint=16.7807 task=16.3507 ppl_loss=8.5992 ppl=8703.72\n",
            "[PEZ λ=0.05 ADV] Epoch 1/5, batch 100 | joint=16.8408 task=16.4143 ppl_loss=8.5315 ppl=8015.90\n",
            "[PEZ λ=0.05 ADV] Epoch 1/5, batch 150 | joint=16.9177 task=16.4874 ppl_loss=8.6054 ppl=10810.68\n",
            "[PEZ λ=0.05 ADV] Epoch 1/5, batch 200 | joint=16.9117 task=16.4785 ppl_loss=8.6640 ppl=10730.48\n",
            "[PEZ λ=0.05 ADV] Epoch 1/5, batch 250 | joint=16.9103 task=16.4780 ppl_loss=8.6452 ppl=10427.01\n",
            "[PEZ λ=0.05 ADV] Epoch 1/5, batch 300 | joint=16.9127 task=16.4802 ppl_loss=8.6497 ppl=10173.79\n",
            "[PEZ λ=0.05 ADV] Epoch 1/5, batch 350 | joint=16.9087 task=16.4739 ppl_loss=8.6963 ppl=10625.31\n",
            "[PEZ λ=0.05 ADV] Epoch 1/5, batch 400 | joint=16.8964 task=16.4619 ppl_loss=8.6903 ppl=10403.82\n",
            "[PEZ λ=0.05 ADV] Epoch 1/5, batch 450 | joint=16.9088 task=16.4744 ppl_loss=8.6875 ppl=10513.81\n",
            "[PEZ λ=0.05 ADV] Epoch 1/5, batch 500 | joint=16.9211 task=16.4866 ppl_loss=8.6897 ppl=10338.33\n",
            "[PEZ λ=0.05 ADV] Epoch 1/5, batch 550 | joint=16.8903 task=16.4549 ppl_loss=8.7073 ppl=10979.07\n",
            "[PEZ λ=0.05 ADV] Epoch 1/5 | joint=16.8889 task=16.4542 ppl_loss=8.6952 ppl=10767.39 val_loss=21.5187 val_acc=0.7927 (true=0.8018 false=0.7777) prompt_ppl=3712.18\n",
            "Prompt: Wur formularul fulfilpoleneusistemeleulescu voluntarambultrecută\n",
            "[PEZ λ=0.05 ADV] Epoch 2/5, batch 50 | joint=16.8534 task=16.4244 ppl_loss=8.5803 ppl=9900.60\n",
            "[PEZ λ=0.05 ADV] Epoch 2/5, batch 100 | joint=16.9964 task=16.5683 ppl_loss=8.5623 ppl=9462.94\n",
            "[PEZ λ=0.05 ADV] Epoch 2/5, batch 150 | joint=16.9689 task=16.5398 ppl_loss=8.5827 ppl=9130.75\n",
            "[PEZ λ=0.05 ADV] Epoch 2/5, batch 200 | joint=16.9399 task=16.5119 ppl_loss=8.5601 ppl=8865.39\n",
            "[PEZ λ=0.05 ADV] Epoch 2/5, batch 250 | joint=16.9290 task=16.5000 ppl_loss=8.5803 ppl=8783.74\n",
            "[PEZ λ=0.05 ADV] Epoch 2/5, batch 300 | joint=16.9151 task=16.4844 ppl_loss=8.6131 ppl=9520.64\n",
            "[PEZ λ=0.05 ADV] Epoch 2/5, batch 350 | joint=16.8876 task=16.4559 ppl_loss=8.6340 ppl=9503.80\n",
            "[PEZ λ=0.05 ADV] Epoch 2/5, batch 400 | joint=16.8696 task=16.4385 ppl_loss=8.6228 ppl=9501.18\n",
            "[PEZ λ=0.05 ADV] Epoch 2/5, batch 450 | joint=16.8603 task=16.4294 ppl_loss=8.6168 ppl=9350.17\n",
            "[PEZ λ=0.05 ADV] Epoch 2/5, batch 500 | joint=16.8462 task=16.4160 ppl_loss=8.6030 ppl=9068.19\n",
            "[PEZ λ=0.05 ADV] Epoch 2/5, batch 550 | joint=16.8336 task=16.4027 ppl_loss=8.6179 ppl=9249.66\n",
            "[PEZ λ=0.05 ADV] Epoch 2/5 | joint=16.8421 task=16.4103 ppl_loss=8.6372 ppl=9580.31 val_loss=22.3444 val_acc=0.7979 (true=0.8160 false=0.7680) prompt_ppl=4758.77\n",
            "Prompt: Log serruriergam PreisvergleichströmelasticityCESProvencestudborough\n",
            "[PEZ λ=0.05 ADV] Epoch 3/5, batch 50 | joint=16.5962 task=16.1599 ppl_loss=8.7243 ppl=10937.96\n",
            "[PEZ λ=0.05 ADV] Epoch 3/5, batch 100 | joint=16.7231 task=16.2881 ppl_loss=8.6988 ppl=10404.14\n",
            "[PEZ λ=0.05 ADV] Epoch 3/5, batch 150 | joint=16.7848 task=16.3512 ppl_loss=8.6721 ppl=9622.36\n",
            "[PEZ λ=0.05 ADV] Epoch 3/5, batch 200 | joint=16.7494 task=16.3143 ppl_loss=8.7037 ppl=9770.23\n",
            "[PEZ λ=0.05 ADV] Epoch 3/5, batch 250 | joint=16.7781 task=16.3451 ppl_loss=8.6581 ppl=9126.07\n",
            "[PEZ λ=0.05 ADV] Epoch 3/5, batch 300 | joint=16.7510 task=16.3172 ppl_loss=8.6755 ppl=9622.21\n",
            "[PEZ λ=0.05 ADV] Epoch 3/5, batch 350 | joint=16.7614 task=16.3271 ppl_loss=8.6860 ppl=9724.32\n",
            "[PEZ λ=0.05 ADV] Epoch 3/5, batch 400 | joint=16.7620 task=16.3282 ppl_loss=8.6760 ppl=9739.31\n",
            "[PEZ λ=0.05 ADV] Epoch 3/5, batch 450 | joint=16.7570 task=16.3238 ppl_loss=8.6644 ppl=9698.91\n",
            "[PEZ λ=0.05 ADV] Epoch 3/5, batch 500 | joint=16.7576 task=16.3245 ppl_loss=8.6612 ppl=9733.41\n",
            "[PEZ λ=0.05 ADV] Epoch 3/5, batch 550 | joint=16.7529 task=16.3208 ppl_loss=8.6428 ppl=9545.91\n",
            "[PEZ λ=0.05 ADV] Epoch 3/5 | joint=16.7701 task=16.3375 ppl_loss=8.6507 ppl=9661.42 val_loss=21.5881 val_acc=0.7917 (true=0.7983 false=0.7809) prompt_ppl=6252.12\n",
            "Prompt: gradini preturi Domnuluineuve bluraparatulgliudelBiserica corpului\n",
            "[PEZ λ=0.05 ADV] Epoch 4/5, batch 50 | joint=16.8304 task=16.3823 ppl_loss=8.9622 ppl=14194.77\n",
            "[PEZ λ=0.05 ADV] Epoch 4/5, batch 100 | joint=16.7902 task=16.3497 ppl_loss=8.8093 ppl=12135.20\n",
            "[PEZ λ=0.05 ADV] Epoch 4/5, batch 150 | joint=16.7990 task=16.3614 ppl_loss=8.7531 ppl=10600.63\n",
            "[PEZ λ=0.05 ADV] Epoch 4/5, batch 200 | joint=16.8109 task=16.3772 ppl_loss=8.6741 ppl=9864.18\n",
            "[PEZ λ=0.05 ADV] Epoch 4/5, batch 250 | joint=16.8093 task=16.3778 ppl_loss=8.6296 ppl=9267.21\n",
            "[PEZ λ=0.05 ADV] Epoch 4/5, batch 300 | joint=16.8565 task=16.4235 ppl_loss=8.6614 ppl=9371.95\n",
            "[PEZ λ=0.05 ADV] Epoch 4/5, batch 350 | joint=16.8257 task=16.3939 ppl_loss=8.6362 ppl=9001.87\n",
            "[PEZ λ=0.05 ADV] Epoch 4/5, batch 400 | joint=16.8337 task=16.4023 ppl_loss=8.6290 ppl=8981.41\n",
            "[PEZ λ=0.05 ADV] Epoch 4/5, batch 450 | joint=16.8224 task=16.3920 ppl_loss=8.6072 ppl=8686.38\n",
            "[PEZ λ=0.05 ADV] Epoch 4/5, batch 500 | joint=16.8391 task=16.4069 ppl_loss=8.6438 ppl=9005.21\n",
            "[PEZ λ=0.05 ADV] Epoch 4/5, batch 550 | joint=16.8334 task=16.4007 ppl_loss=8.6550 ppl=9065.95\n",
            "[PEZ λ=0.05 ADV] Epoch 4/5 | joint=16.8351 task=16.4026 ppl_loss=8.6490 ppl=9112.19 val_loss=21.0737 val_acc=0.7914 (true=0.7964 false=0.7833) prompt_ppl=5067.00\n",
            "Prompt: sectiune Suceavautzionar mun Tale erkennenrandulchi protectie\n",
            "[PEZ λ=0.05 ADV] Epoch 5/5, batch 50 | joint=16.7074 task=16.2690 ppl_loss=8.7682 ppl=10161.08\n",
            "[PEZ λ=0.05 ADV] Epoch 5/5, batch 100 | joint=16.6611 task=16.2181 ppl_loss=8.8593 ppl=11434.23\n",
            "[PEZ λ=0.05 ADV] Epoch 5/5, batch 150 | joint=16.7704 task=16.3283 ppl_loss=8.8427 ppl=11086.46\n",
            "[PEZ λ=0.05 ADV] Epoch 5/5, batch 200 | joint=16.7914 task=16.3516 ppl_loss=8.7962 ppl=10857.00\n",
            "[PEZ λ=0.05 ADV] Epoch 5/5, batch 250 | joint=16.7988 task=16.3622 ppl_loss=8.7334 ppl=10156.78\n",
            "[PEZ λ=0.05 ADV] Epoch 5/5, batch 300 | joint=16.8119 task=16.3764 ppl_loss=8.7102 ppl=9853.03\n",
            "[PEZ λ=0.05 ADV] Epoch 5/5, batch 350 | joint=16.8380 task=16.4021 ppl_loss=8.7182 ppl=9808.18\n",
            "[PEZ λ=0.05 ADV] Epoch 5/5, batch 400 | joint=16.8437 task=16.4078 ppl_loss=8.7174 ppl=10114.45\n",
            "[PEZ λ=0.05 ADV] Epoch 5/5, batch 450 | joint=16.8580 task=16.4220 ppl_loss=8.7203 ppl=10485.53\n",
            "[PEZ λ=0.05 ADV] Epoch 5/5, batch 500 | joint=16.8666 task=16.4314 ppl_loss=8.7049 ppl=10446.94\n",
            "[PEZ λ=0.05 ADV] Epoch 5/5, batch 550 | joint=16.8539 task=16.4186 ppl_loss=8.7068 ppl=10528.42\n",
            "[PEZ λ=0.05 ADV] Epoch 5/5 | joint=16.8566 task=16.4217 ppl_loss=8.6981 ppl=10643.44 val_loss=21.3127 val_acc=0.7988 (true=0.8165 false=0.7696) prompt_ppl=8901.16\n",
            "Prompt: concessioncône Bahamas lucraribiologi paharitulcino Marriott Compare\n",
            "\n",
            "=== PEZ Adversarial (λ=0.1) ===\n",
            "[PEZ λ=0.1 ADV] Epoch 1/5, batch 50 | joint=17.2395 task=16.3417 ppl_loss=8.9785 ppl=14215.55\n",
            "[PEZ λ=0.1 ADV] Epoch 1/5, batch 100 | joint=17.1708 task=16.3002 ppl_loss=8.7065 ppl=10419.65\n",
            "[PEZ λ=0.1 ADV] Epoch 1/5, batch 150 | joint=17.2463 task=16.3775 ppl_loss=8.6881 ppl=9571.71\n",
            "[PEZ λ=0.1 ADV] Epoch 1/5, batch 200 | joint=17.2659 task=16.3943 ppl_loss=8.7158 ppl=9649.33\n",
            "[PEZ λ=0.1 ADV] Epoch 1/5, batch 250 | joint=17.2842 task=16.4158 ppl_loss=8.6844 ppl=9208.09\n",
            "[PEZ λ=0.1 ADV] Epoch 1/5, batch 300 | joint=17.2792 task=16.4142 ppl_loss=8.6498 ppl=9510.28\n",
            "[PEZ λ=0.1 ADV] Epoch 1/5, batch 350 | joint=17.2592 task=16.3980 ppl_loss=8.6125 ppl=9109.20\n",
            "[PEZ λ=0.1 ADV] Epoch 1/5, batch 400 | joint=17.2419 task=16.3784 ppl_loss=8.6348 ppl=9766.32\n",
            "[PEZ λ=0.1 ADV] Epoch 1/5, batch 450 | joint=17.2694 task=16.4045 ppl_loss=8.6487 ppl=9864.46\n",
            "[PEZ λ=0.1 ADV] Epoch 1/5, batch 500 | joint=17.2971 task=16.4320 ppl_loss=8.6503 ppl=9696.91\n",
            "[PEZ λ=0.1 ADV] Epoch 1/5, batch 550 | joint=17.2826 task=16.4191 ppl_loss=8.6343 ppl=9669.99\n",
            "[PEZ λ=0.1 ADV] Epoch 1/5 | joint=17.2780 task=16.4137 ppl_loss=8.6436 ppl=9622.38 val_loss=21.9254 val_acc=0.7945 (true=0.8096 false=0.7696) prompt_ppl=8742.24\n",
            "Prompt: plimbGC Rockyleger societati imbunatati pielea definit Newtonhav\n",
            "[PEZ λ=0.1 ADV] Epoch 2/5, batch 50 | joint=17.2876 task=16.4286 ppl_loss=8.5902 ppl=8167.97\n",
            "[PEZ λ=0.1 ADV] Epoch 2/5, batch 100 | joint=17.4135 task=16.5547 ppl_loss=8.5873 ppl=8268.92\n",
            "[PEZ λ=0.1 ADV] Epoch 2/5, batch 150 | joint=17.4082 task=16.5424 ppl_loss=8.6578 ppl=8612.63\n",
            "[PEZ λ=0.1 ADV] Epoch 2/5, batch 200 | joint=17.3504 task=16.4845 ppl_loss=8.6593 ppl=9224.94\n",
            "[PEZ λ=0.1 ADV] Epoch 2/5, batch 250 | joint=17.3019 task=16.4373 ppl_loss=8.6462 ppl=10337.27\n",
            "[PEZ λ=0.1 ADV] Epoch 2/5, batch 300 | joint=17.2927 task=16.4254 ppl_loss=8.6729 ppl=10961.72\n",
            "[PEZ λ=0.1 ADV] Epoch 2/5, batch 350 | joint=17.2855 task=16.4144 ppl_loss=8.7118 ppl=12014.38\n",
            "[PEZ λ=0.1 ADV] Epoch 2/5, batch 400 | joint=17.2784 task=16.4037 ppl_loss=8.7468 ppl=14262.10\n",
            "[PEZ λ=0.1 ADV] Epoch 2/5, batch 450 | joint=17.2486 task=16.3749 ppl_loss=8.7373 ppl=13808.20\n",
            "[PEZ λ=0.1 ADV] Epoch 2/5, batch 500 | joint=17.2372 task=16.3643 ppl_loss=8.7297 ppl=14056.38\n",
            "[PEZ λ=0.1 ADV] Epoch 2/5, batch 550 | joint=17.2322 task=16.3600 ppl_loss=8.7221 ppl=13563.67\n",
            "[PEZ λ=0.1 ADV] Epoch 2/5 | joint=17.2261 task=16.3547 ppl_loss=8.7136 ppl=13273.15 val_loss=21.7325 val_acc=0.7924 (true=0.7821 false=0.8092) prompt_ppl=1789.42\n",
            "Prompt: simtiromâniiplateété Sergizan românesc cunoaste Vezi simti\n",
            "[PEZ λ=0.1 ADV] Epoch 3/5, batch 50 | joint=17.2320 task=16.3475 ppl_loss=8.8443 ppl=10631.50\n",
            "[PEZ λ=0.1 ADV] Epoch 3/5, batch 100 | joint=17.1265 task=16.2402 ppl_loss=8.8636 ppl=12977.33\n",
            "[PEZ λ=0.1 ADV] Epoch 3/5, batch 150 | joint=17.2177 task=16.3330 ppl_loss=8.8461 ppl=12853.85\n",
            "[PEZ λ=0.1 ADV] Epoch 3/5, batch 200 | joint=17.1708 task=16.2911 ppl_loss=8.7973 ppl=12496.55\n",
            "[PEZ λ=0.1 ADV] Epoch 3/5, batch 250 | joint=17.2112 task=16.3310 ppl_loss=8.8022 ppl=13214.96\n",
            "[PEZ λ=0.1 ADV] Epoch 3/5, batch 300 | joint=17.2311 task=16.3557 ppl_loss=8.7534 ppl=12070.73\n",
            "[PEZ λ=0.1 ADV] Epoch 3/5, batch 350 | joint=17.2397 task=16.3668 ppl_loss=8.7298 ppl=11714.86\n",
            "[PEZ λ=0.1 ADV] Epoch 3/5, batch 400 | joint=17.2278 task=16.3548 ppl_loss=8.7297 ppl=11944.01\n",
            "[PEZ λ=0.1 ADV] Epoch 3/5, batch 450 | joint=17.2416 task=16.3701 ppl_loss=8.7147 ppl=11545.47\n",
            "[PEZ λ=0.1 ADV] Epoch 3/5, batch 500 | joint=17.2212 task=16.3517 ppl_loss=8.6942 ppl=11119.39\n",
            "[PEZ λ=0.1 ADV] Epoch 3/5, batch 550 | joint=17.2449 task=16.3752 ppl_loss=8.6973 ppl=11208.19\n",
            "[PEZ λ=0.1 ADV] Epoch 3/5 | joint=17.2491 task=16.3788 ppl_loss=8.7028 ppl=11484.83 val_loss=21.7693 val_acc=0.7930 (true=0.7978 false=0.7850) prompt_ppl=210844.23\n",
            "Prompt: cartoficumvariqueYArama Preston Friedrich Hernandez Dou adj\n",
            "[PEZ λ=0.1 ADV] Epoch 4/5, batch 50 | joint=17.4555 task=16.5831 ppl_loss=8.7239 ppl=12768.84\n",
            "[PEZ λ=0.1 ADV] Epoch 4/5, batch 100 | joint=17.2318 task=16.3552 ppl_loss=8.7653 ppl=12148.57\n",
            "[PEZ λ=0.1 ADV] Epoch 4/5, batch 150 | joint=17.1942 task=16.3224 ppl_loss=8.7180 ppl=11193.99\n",
            "[PEZ λ=0.1 ADV] Epoch 4/5, batch 200 | joint=17.1422 task=16.2698 ppl_loss=8.7244 ppl=12666.55\n",
            "[PEZ λ=0.1 ADV] Epoch 4/5, batch 250 | joint=17.1672 task=16.2999 ppl_loss=8.6726 ppl=11744.99\n",
            "[PEZ λ=0.1 ADV] Epoch 4/5, batch 300 | joint=17.2108 task=16.3438 ppl_loss=8.6698 ppl=11309.22\n",
            "[PEZ λ=0.1 ADV] Epoch 4/5, batch 350 | joint=17.2169 task=16.3517 ppl_loss=8.6514 ppl=10777.97\n",
            "[PEZ λ=0.1 ADV] Epoch 4/5, batch 400 | joint=17.2549 task=16.3892 ppl_loss=8.6574 ppl=10626.57\n",
            "[PEZ λ=0.1 ADV] Epoch 4/5, batch 450 | joint=17.2772 task=16.4106 ppl_loss=8.6659 ppl=10540.78\n",
            "[PEZ λ=0.1 ADV] Epoch 4/5, batch 500 | joint=17.2972 task=16.4276 ppl_loss=8.6960 ppl=11005.44\n",
            "[PEZ λ=0.1 ADV] Epoch 4/5, batch 550 | joint=17.3089 task=16.4381 ppl_loss=8.7077 ppl=11025.95\n",
            "[PEZ λ=0.1 ADV] Epoch 4/5 | joint=17.2982 task=16.4275 ppl_loss=8.7068 ppl=10866.04 val_loss=18.9669 val_acc=0.7951 (true=0.8160 false=0.7607) prompt_ppl=11520.86\n",
            "Prompt: psychiatrist IuliaEditura situatiaKG incredereillard wondered simpatinick\n",
            "[PEZ λ=0.1 ADV] Epoch 5/5, batch 50 | joint=17.0827 task=16.2069 ppl_loss=8.7584 ppl=16083.22\n",
            "[PEZ λ=0.1 ADV] Epoch 5/5, batch 100 | joint=17.1772 task=16.2938 ppl_loss=8.8337 ppl=14578.55\n",
            "[PEZ λ=0.1 ADV] Epoch 5/5, batch 150 | joint=17.1912 task=16.3084 ppl_loss=8.8287 ppl=13423.72\n",
            "[PEZ λ=0.1 ADV] Epoch 5/5, batch 200 | joint=17.2495 task=16.3680 ppl_loss=8.8146 ppl=13432.82\n",
            "[PEZ λ=0.1 ADV] Epoch 5/5, batch 250 | joint=17.2071 task=16.3306 ppl_loss=8.7659 ppl=12744.17\n",
            "[PEZ λ=0.1 ADV] Epoch 5/5, batch 300 | joint=17.2032 task=16.3301 ppl_loss=8.7317 ppl=11969.02\n",
            "[PEZ λ=0.1 ADV] Epoch 5/5, batch 350 | joint=17.2152 task=16.3417 ppl_loss=8.7356 ppl=12034.67\n",
            "[PEZ λ=0.1 ADV] Epoch 5/5, batch 400 | joint=17.2264 task=16.3568 ppl_loss=8.6965 ppl=11344.39\n",
            "[PEZ λ=0.1 ADV] Epoch 5/5, batch 450 | joint=17.2113 task=16.3417 ppl_loss=8.6962 ppl=10972.34\n",
            "[PEZ λ=0.1 ADV] Epoch 5/5, batch 500 | joint=17.2269 task=16.3558 ppl_loss=8.7106 ppl=11118.05\n",
            "[PEZ λ=0.1 ADV] Epoch 5/5, batch 550 | joint=17.2453 task=16.3746 ppl_loss=8.7067 ppl=10919.61\n",
            "[PEZ λ=0.1 ADV] Epoch 5/5 | joint=17.2536 task=16.3820 ppl_loss=8.7158 ppl=10975.62 val_loss=22.4261 val_acc=0.7942 (true=0.7983 false=0.7874) prompt_ppl=2261.88\n",
            "Prompt: comentariu secureprofessionaltial incadrrade incercat avant amintekannte\n",
            "\n",
            "=== PEZ Adversarial (λ=0.25) ===\n",
            "[PEZ λ=0.25 ADV] Epoch 1/5, batch 50 | joint=18.6186 task=16.4825 ppl_loss=8.5444 ppl=9101.57\n",
            "[PEZ λ=0.25 ADV] Epoch 1/5, batch 100 | joint=18.5784 task=16.4571 ppl_loss=8.4850 ppl=7903.65\n",
            "[PEZ λ=0.25 ADV] Epoch 1/5, batch 150 | joint=18.5497 task=16.4145 ppl_loss=8.5409 ppl=8064.66\n",
            "[PEZ λ=0.25 ADV] Epoch 1/5, batch 200 | joint=18.5278 task=16.3839 ppl_loss=8.5755 ppl=8292.53\n",
            "[PEZ λ=0.25 ADV] Epoch 1/5, batch 250 | joint=18.5404 task=16.3749 ppl_loss=8.6620 ppl=9105.35\n",
            "[PEZ λ=0.25 ADV] Epoch 1/5, batch 300 | joint=18.5255 task=16.3582 ppl_loss=8.6691 ppl=9185.76\n",
            "[PEZ λ=0.25 ADV] Epoch 1/5, batch 350 | joint=18.5644 task=16.4000 ppl_loss=8.6576 ppl=9081.06\n",
            "[PEZ λ=0.25 ADV] Epoch 1/5, batch 400 | joint=18.5806 task=16.4169 ppl_loss=8.6547 ppl=9154.85\n",
            "[PEZ λ=0.25 ADV] Epoch 1/5, batch 450 | joint=18.5756 task=16.4115 ppl_loss=8.6564 ppl=9194.89\n",
            "[PEZ λ=0.25 ADV] Epoch 1/5, batch 500 | joint=18.6062 task=16.4396 ppl_loss=8.6666 ppl=9763.97\n",
            "[PEZ λ=0.25 ADV] Epoch 1/5, batch 550 | joint=18.5984 task=16.4374 ppl_loss=8.6442 ppl=9428.92\n",
            "[PEZ λ=0.25 ADV] Epoch 1/5 | joint=18.5998 task=16.4393 ppl_loss=8.6422 ppl=9412.36 val_loss=21.4403 val_acc=0.7976 (true=0.8131 false=0.7720) prompt_ppl=69092.72\n",
            "Prompt: aşez Hart spellagingück SabMPraz archtroph\n",
            "[PEZ λ=0.25 ADV] Epoch 2/5, batch 50 | joint=18.5137 task=16.3565 ppl_loss=8.6291 ppl=9843.19\n",
            "[PEZ λ=0.25 ADV] Epoch 2/5, batch 100 | joint=18.6794 task=16.5024 ppl_loss=8.7080 ppl=10272.65\n",
            "[PEZ λ=0.25 ADV] Epoch 2/5, batch 150 | joint=18.7020 task=16.5392 ppl_loss=8.6511 ppl=9352.15\n",
            "[PEZ λ=0.25 ADV] Epoch 2/5, batch 200 | joint=18.6184 task=16.4624 ppl_loss=8.6239 ppl=8857.74\n",
            "[PEZ λ=0.25 ADV] Epoch 2/5, batch 250 | joint=18.6180 task=16.4532 ppl_loss=8.6594 ppl=9026.39\n",
            "[PEZ λ=0.25 ADV] Epoch 2/5, batch 300 | joint=18.6128 task=16.4430 ppl_loss=8.6795 ppl=9219.95\n",
            "[PEZ λ=0.25 ADV] Epoch 2/5, batch 350 | joint=18.6531 task=16.4820 ppl_loss=8.6847 ppl=9239.25\n",
            "[PEZ λ=0.25 ADV] Epoch 2/5, batch 400 | joint=18.6382 task=16.4695 ppl_loss=8.6748 ppl=9417.94\n",
            "[PEZ λ=0.25 ADV] Epoch 2/5, batch 450 | joint=18.6161 task=16.4489 ppl_loss=8.6691 ppl=9243.76\n",
            "[PEZ λ=0.25 ADV] Epoch 2/5, batch 500 | joint=18.6378 task=16.4697 ppl_loss=8.6724 ppl=9496.20\n",
            "[PEZ λ=0.25 ADV] Epoch 2/5, batch 550 | joint=18.6446 task=16.4763 ppl_loss=8.6732 ppl=9303.32\n",
            "[PEZ λ=0.25 ADV] Epoch 2/5 | joint=18.6357 task=16.4685 ppl_loss=8.6687 ppl=9196.63 val_loss=20.9202 val_acc=0.7859 (true=0.7811 false=0.7939) prompt_ppl=3409.31\n",
            "Prompt: Westfalenggereaux Richard Juliphro Guillaumetră celule Kli\n",
            "[PEZ λ=0.25 ADV] Epoch 3/5, batch 50 | joint=18.7621 task=16.6028 ppl_loss=8.6372 ppl=8229.93\n",
            "[PEZ λ=0.25 ADV] Epoch 3/5, batch 100 | joint=18.7177 task=16.5522 ppl_loss=8.6620 ppl=8951.67\n",
            "[PEZ λ=0.25 ADV] Epoch 3/5, batch 150 | joint=18.5887 task=16.4148 ppl_loss=8.6954 ppl=9130.45\n",
            "[PEZ λ=0.25 ADV] Epoch 3/5, batch 200 | joint=18.6051 task=16.4393 ppl_loss=8.6634 ppl=8756.62\n",
            "[PEZ λ=0.25 ADV] Epoch 3/5, batch 250 | joint=18.6192 task=16.4602 ppl_loss=8.6361 ppl=8388.83\n",
            "[PEZ λ=0.25 ADV] Epoch 3/5, batch 300 | joint=18.6358 task=16.4642 ppl_loss=8.6863 ppl=9251.42\n",
            "[PEZ λ=0.25 ADV] Epoch 3/5, batch 350 | joint=18.6697 task=16.4971 ppl_loss=8.6904 ppl=9169.55\n",
            "[PEZ λ=0.25 ADV] Epoch 3/5, batch 400 | joint=18.6552 task=16.4836 ppl_loss=8.6866 ppl=9005.04\n",
            "[PEZ λ=0.25 ADV] Epoch 3/5, batch 450 | joint=18.6648 task=16.4960 ppl_loss=8.6753 ppl=8742.64\n",
            "[PEZ λ=0.25 ADV] Epoch 3/5, batch 500 | joint=18.6490 task=16.4763 ppl_loss=8.6908 ppl=9198.38\n",
            "[PEZ λ=0.25 ADV] Epoch 3/5, batch 550 | joint=18.6342 task=16.4664 ppl_loss=8.6712 ppl=8939.49\n",
            "[PEZ λ=0.25 ADV] Epoch 3/5 | joint=18.6322 task=16.4639 ppl_loss=8.6731 ppl=8889.07 val_loss=22.0103 val_acc=0.7948 (true=0.8047 false=0.7785) prompt_ppl=3309.60\n",
            "Prompt: Gestalt Conceptaffininte Maintenancemaz Vililliersoire răc\n",
            "[PEZ λ=0.25 ADV] Epoch 4/5, batch 50 | joint=18.6834 task=16.4864 ppl_loss=8.7880 ppl=8910.96\n",
            "[PEZ λ=0.25 ADV] Epoch 4/5, batch 100 | joint=18.5749 task=16.3869 ppl_loss=8.7520 ppl=9103.66\n",
            "[PEZ λ=0.25 ADV] Epoch 4/5, batch 150 | joint=18.5333 task=16.3718 ppl_loss=8.6462 ppl=8458.00\n",
            "[PEZ λ=0.25 ADV] Epoch 4/5, batch 200 | joint=18.4836 task=16.3295 ppl_loss=8.6167 ppl=8795.88\n",
            "[PEZ λ=0.25 ADV] Epoch 4/5, batch 250 | joint=18.5085 task=16.3448 ppl_loss=8.6548 ppl=8766.36\n",
            "[PEZ λ=0.25 ADV] Epoch 4/5, batch 300 | joint=18.4746 task=16.3092 ppl_loss=8.6616 ppl=8936.68\n",
            "[PEZ λ=0.25 ADV] Epoch 4/5, batch 350 | joint=18.4925 task=16.3277 ppl_loss=8.6593 ppl=9107.89\n",
            "[PEZ λ=0.25 ADV] Epoch 4/5, batch 400 | joint=18.5192 task=16.3580 ppl_loss=8.6447 ppl=8974.87\n",
            "[PEZ λ=0.25 ADV] Epoch 4/5, batch 450 | joint=18.5467 task=16.3824 ppl_loss=8.6574 ppl=9007.68\n",
            "[PEZ λ=0.25 ADV] Epoch 4/5, batch 500 | joint=18.5628 task=16.3988 ppl_loss=8.6559 ppl=8954.59\n",
            "[PEZ λ=0.25 ADV] Epoch 4/5, batch 550 | joint=18.5709 task=16.4055 ppl_loss=8.6620 ppl=8973.66\n",
            "[PEZ λ=0.25 ADV] Epoch 4/5 | joint=18.5727 task=16.4070 ppl_loss=8.6628 ppl=8918.24 val_loss=21.7450 val_acc=0.7902 (true=0.7782 false=0.8100) prompt_ppl=629.21\n",
            "Prompt: Kreuz mieremaz săptămână gradini Sheffield ofera instalatarni usor\n",
            "[PEZ λ=0.25 ADV] Epoch 5/5, batch 50 | joint=18.5280 task=16.3553 ppl_loss=8.6908 ppl=13838.26\n",
            "[PEZ λ=0.25 ADV] Epoch 5/5, batch 100 | joint=18.4399 task=16.2594 ppl_loss=8.7219 ppl=25877.82\n",
            "[PEZ λ=0.25 ADV] Epoch 5/5, batch 150 | joint=18.5337 task=16.3997 ppl_loss=8.5360 ppl=18897.91\n",
            "[PEZ λ=0.25 ADV] Epoch 5/5, batch 200 | joint=18.5537 task=16.4256 ppl_loss=8.5127 ppl=15770.65\n",
            "[PEZ λ=0.25 ADV] Epoch 5/5, batch 250 | joint=18.5791 task=16.4390 ppl_loss=8.5605 ppl=14508.56\n",
            "[PEZ λ=0.25 ADV] Epoch 5/5, batch 300 | joint=18.5462 task=16.4083 ppl_loss=8.5515 ppl=13265.23\n",
            "[PEZ λ=0.25 ADV] Epoch 5/5, batch 350 | joint=18.5615 task=16.4257 ppl_loss=8.5430 ppl=12730.72\n",
            "[PEZ λ=0.25 ADV] Epoch 5/5, batch 400 | joint=18.5438 task=16.4013 ppl_loss=8.5700 ppl=12753.82\n",
            "[PEZ λ=0.25 ADV] Epoch 5/5, batch 450 | joint=18.5655 task=16.4197 ppl_loss=8.5833 ppl=12300.60\n",
            "[PEZ λ=0.25 ADV] Epoch 5/5, batch 500 | joint=18.5310 task=16.3869 ppl_loss=8.5764 ppl=11896.31\n",
            "[PEZ λ=0.25 ADV] Epoch 5/5, batch 550 | joint=18.5365 task=16.3949 ppl_loss=8.5663 ppl=11510.74\n",
            "[PEZ λ=0.25 ADV] Epoch 5/5 | joint=18.5438 task=16.3990 ppl_loss=8.5793 ppl=11334.95 val_loss=20.7790 val_acc=0.7905 (true=0.7880 false=0.7947) prompt_ppl=1124.69\n",
            "Prompt: datoritaunicipiului proprietati categoriapozacy săptămână écrCAP illicit\n",
            "\n",
            "=== PEZ Adversarial (λ=0.5) ===\n",
            "[PEZ λ=0.5 ADV] Epoch 1/5, batch 50 | joint=20.8557 task=16.4875 ppl_loss=8.7364 ppl=12933.48\n",
            "[PEZ λ=0.5 ADV] Epoch 1/5, batch 100 | joint=20.6960 task=16.4360 ppl_loss=8.5201 ppl=9509.50\n",
            "[PEZ λ=0.5 ADV] Epoch 1/5, batch 150 | joint=20.7047 task=16.4265 ppl_loss=8.5564 ppl=9539.43\n",
            "[PEZ λ=0.5 ADV] Epoch 1/5, batch 200 | joint=20.7230 task=16.4112 ppl_loss=8.6236 ppl=9779.22\n",
            "[PEZ λ=0.5 ADV] Epoch 1/5, batch 250 | joint=20.7732 task=16.4222 ppl_loss=8.7021 ppl=15155.53\n",
            "[PEZ λ=0.5 ADV] Epoch 1/5, batch 300 | joint=20.7573 task=16.4065 ppl_loss=8.7015 ppl=14295.56\n",
            "[PEZ λ=0.5 ADV] Epoch 1/5, batch 350 | joint=20.7698 task=16.4284 ppl_loss=8.6829 ppl=13649.83\n",
            "[PEZ λ=0.5 ADV] Epoch 1/5, batch 400 | joint=20.7473 task=16.4024 ppl_loss=8.6898 ppl=13299.47\n",
            "[PEZ λ=0.5 ADV] Epoch 1/5, batch 450 | joint=20.7099 task=16.3885 ppl_loss=8.6428 ppl=13087.38\n",
            "[PEZ λ=0.5 ADV] Epoch 1/5, batch 500 | joint=20.7303 task=16.3996 ppl_loss=8.6614 ppl=12961.47\n",
            "[PEZ λ=0.5 ADV] Epoch 1/5, batch 550 | joint=20.7350 task=16.3987 ppl_loss=8.6728 ppl=12711.41\n",
            "[PEZ λ=0.5 ADV] Epoch 1/5 | joint=20.7490 task=16.4138 ppl_loss=8.6703 ppl=12602.54 val_loss=21.4899 val_acc=0.7884 (true=0.7796 false=0.8027) prompt_ppl=23257.97\n",
            "Prompt: piele protection Smash sanatateélis ApollophysicalOTT Moldovei prob\n",
            "[PEZ λ=0.5 ADV] Epoch 2/5, batch 50 | joint=20.9995 task=16.6098 ppl_loss=8.7795 ppl=10973.41\n",
            "[PEZ λ=0.5 ADV] Epoch 2/5, batch 100 | joint=20.7800 task=16.4327 ppl_loss=8.6945 ppl=9879.18\n",
            "[PEZ λ=0.5 ADV] Epoch 2/5, batch 150 | joint=20.8456 task=16.4956 ppl_loss=8.7001 ppl=9354.03\n",
            "[PEZ λ=0.5 ADV] Epoch 2/5, batch 200 | joint=20.8612 task=16.4985 ppl_loss=8.7255 ppl=12243.72\n",
            "[PEZ λ=0.5 ADV] Epoch 2/5, batch 250 | joint=20.8361 task=16.4687 ppl_loss=8.7347 ppl=12184.06\n",
            "[PEZ λ=0.5 ADV] Epoch 2/5, batch 300 | joint=20.8205 task=16.4790 ppl_loss=8.6830 ppl=11200.30\n",
            "[PEZ λ=0.5 ADV] Epoch 2/5, batch 350 | joint=20.8266 task=16.4851 ppl_loss=8.6831 ppl=10850.40\n",
            "[PEZ λ=0.5 ADV] Epoch 2/5, batch 400 | joint=20.8191 task=16.4996 ppl_loss=8.6389 ppl=10249.57\n",
            "[PEZ λ=0.5 ADV] Epoch 2/5, batch 450 | joint=20.8002 task=16.4898 ppl_loss=8.6208 ppl=9889.32\n",
            "[PEZ λ=0.5 ADV] Epoch 2/5, batch 500 | joint=20.7801 task=16.4698 ppl_loss=8.6206 ppl=9782.35\n",
            "[PEZ λ=0.5 ADV] Epoch 2/5, batch 550 | joint=20.8040 task=16.4838 ppl_loss=8.6403 ppl=10231.27\n",
            "[PEZ λ=0.5 ADV] Epoch 2/5 | joint=20.7950 task=16.4710 ppl_loss=8.6479 ppl=10129.04 val_loss=21.8604 val_acc=0.7887 (true=0.7806 false=0.8019) prompt_ppl=4071.92\n",
            "Prompt: dorint dragoste ZusatzLiviu suprafete Imppov gasest piele iarna\n",
            "[PEZ λ=0.5 ADV] Epoch 3/5, batch 50 | joint=21.1175 task=16.5061 ppl_loss=9.2227 ppl=18727.57\n",
            "[PEZ λ=0.5 ADV] Epoch 3/5, batch 100 | joint=20.9961 task=16.5223 ppl_loss=8.9476 ppl=14872.67\n",
            "[PEZ λ=0.5 ADV] Epoch 3/5, batch 150 | joint=20.9854 task=16.5158 ppl_loss=8.9392 ppl=13565.41\n",
            "[PEZ λ=0.5 ADV] Epoch 3/5, batch 200 | joint=20.9262 task=16.4748 ppl_loss=8.9028 ppl=12885.52\n",
            "[PEZ λ=0.5 ADV] Epoch 3/5, batch 250 | joint=20.8843 task=16.4548 ppl_loss=8.8590 ppl=12357.27\n",
            "[PEZ λ=0.5 ADV] Epoch 3/5, batch 300 | joint=20.8371 task=16.4229 ppl_loss=8.8284 ppl=11870.09\n",
            "[PEZ λ=0.5 ADV] Epoch 3/5, batch 350 | joint=20.8181 task=16.4164 ppl_loss=8.8034 ppl=12202.45\n",
            "[PEZ λ=0.5 ADV] Epoch 3/5, batch 400 | joint=20.8153 task=16.4228 ppl_loss=8.7851 ppl=11910.74\n",
            "[PEZ λ=0.5 ADV] Epoch 3/5, batch 450 | joint=20.8013 task=16.4221 ppl_loss=8.7584 ppl=11574.34\n",
            "[PEZ λ=0.5 ADV] Epoch 3/5, batch 500 | joint=20.7950 task=16.4287 ppl_loss=8.7326 ppl=11037.65\n",
            "[PEZ λ=0.5 ADV] Epoch 3/5, batch 550 | joint=20.7820 task=16.4224 ppl_loss=8.7192 ppl=10800.64\n",
            "[PEZ λ=0.5 ADV] Epoch 3/5 | joint=20.7779 task=16.4155 ppl_loss=8.7247 ppl=10862.55 val_loss=21.3761 val_acc=0.7991 (true=0.8259 false=0.7551) prompt_ppl=28534.99\n",
            "Prompt: tagsrierroisvouszahn endureilliersischlander Erd\n",
            "[PEZ λ=0.5 ADV] Epoch 4/5, batch 50 | joint=20.9283 task=16.4948 ppl_loss=8.8671 ppl=16183.37\n",
            "[PEZ λ=0.5 ADV] Epoch 4/5, batch 100 | joint=20.7126 task=16.3794 ppl_loss=8.6664 ppl=11524.34\n",
            "[PEZ λ=0.5 ADV] Epoch 4/5, batch 150 | joint=20.7775 task=16.4270 ppl_loss=8.7008 ppl=10843.27\n",
            "[PEZ λ=0.5 ADV] Epoch 4/5, batch 200 | joint=20.7816 task=16.4498 ppl_loss=8.6635 ppl=10270.32\n",
            "[PEZ λ=0.5 ADV] Epoch 4/5, batch 250 | joint=20.7638 task=16.4250 ppl_loss=8.6777 ppl=9943.77\n",
            "[PEZ λ=0.5 ADV] Epoch 4/5, batch 300 | joint=20.7903 task=16.4476 ppl_loss=8.6854 ppl=9928.41\n",
            "[PEZ λ=0.5 ADV] Epoch 4/5, batch 350 | joint=20.7945 task=16.4454 ppl_loss=8.6982 ppl=9711.47\n",
            "[PEZ λ=0.5 ADV] Epoch 4/5, batch 400 | joint=20.7966 task=16.4320 ppl_loss=8.7293 ppl=9938.74\n",
            "[PEZ λ=0.5 ADV] Epoch 4/5, batch 450 | joint=20.7656 task=16.4125 ppl_loss=8.7062 ppl=9586.58\n",
            "[PEZ λ=0.5 ADV] Epoch 4/5, batch 500 | joint=20.7889 task=16.4298 ppl_loss=8.7183 ppl=9987.53\n",
            "[PEZ λ=0.5 ADV] Epoch 4/5, batch 550 | joint=20.7678 task=16.4007 ppl_loss=8.7342 ppl=9992.13\n",
            "[PEZ λ=0.5 ADV] Epoch 4/5 | joint=20.7785 task=16.4118 ppl_loss=8.7336 ppl=9864.38 val_loss=20.9009 val_acc=0.8028 (true=0.8185 false=0.7769) prompt_ppl=5702.03\n",
            "Prompt: unicescalierhaudiereffyhull suprafațOUdulci Mouse Photoshop\n",
            "[PEZ λ=0.5 ADV] Epoch 5/5, batch 50 | joint=20.7594 task=16.3804 ppl_loss=8.7582 ppl=10881.98\n",
            "[PEZ λ=0.5 ADV] Epoch 5/5, batch 100 | joint=20.7104 task=16.3781 ppl_loss=8.6646 ppl=10108.07\n",
            "[PEZ λ=0.5 ADV] Epoch 5/5, batch 150 | joint=20.7176 task=16.4055 ppl_loss=8.6242 ppl=10617.88\n",
            "[PEZ λ=0.5 ADV] Epoch 5/5, batch 200 | joint=20.7205 task=16.4305 ppl_loss=8.5800 ppl=9957.31\n",
            "[PEZ λ=0.5 ADV] Epoch 5/5, batch 250 | joint=20.7369 task=16.4183 ppl_loss=8.6372 ppl=10536.95\n",
            "[PEZ λ=0.5 ADV] Epoch 5/5, batch 300 | joint=20.7305 task=16.4155 ppl_loss=8.6301 ppl=10273.01\n",
            "[PEZ λ=0.5 ADV] Epoch 5/5, batch 350 | joint=20.7393 task=16.4014 ppl_loss=8.6759 ppl=10788.15\n",
            "[PEZ λ=0.5 ADV] Epoch 5/5, batch 400 | joint=20.7458 task=16.3940 ppl_loss=8.7036 ppl=11465.02\n",
            "[PEZ λ=0.5 ADV] Epoch 5/5, batch 450 | joint=20.7712 task=16.4057 ppl_loss=8.7310 ppl=12232.13\n",
            "[PEZ λ=0.5 ADV] Epoch 5/5, batch 500 | joint=20.7802 task=16.4185 ppl_loss=8.7235 ppl=12000.77\n",
            "[PEZ λ=0.5 ADV] Epoch 5/5, batch 550 | joint=20.7691 task=16.4042 ppl_loss=8.7299 ppl=11832.30\n",
            "[PEZ λ=0.5 ADV] Epoch 5/5 | joint=20.7769 task=16.4130 ppl_loss=8.7279 ppl=11893.56 val_loss=21.6946 val_acc=0.7991 (true=0.8077 false=0.7850) prompt_ppl=4946.97\n",
            "Prompt: krautVA ivory pielereti mecintinoéritéVac intreb\n",
            "\n",
            "=== PEZ Adversarial (λ=0.75) ===\n",
            "[PEZ λ=0.75 ADV] Epoch 1/5, batch 50 | joint=22.8062 task=16.4493 ppl_loss=8.4758 ppl=8931.50\n",
            "[PEZ λ=0.75 ADV] Epoch 1/5, batch 100 | joint=22.7247 task=16.3749 ppl_loss=8.4664 ppl=7808.09\n",
            "[PEZ λ=0.75 ADV] Epoch 1/5, batch 150 | joint=22.7600 task=16.3689 ppl_loss=8.5215 ppl=7695.69\n",
            "[PEZ λ=0.75 ADV] Epoch 1/5, batch 200 | joint=22.7955 task=16.3591 ppl_loss=8.5819 ppl=8728.05\n",
            "[PEZ λ=0.75 ADV] Epoch 1/5, batch 250 | joint=22.8643 task=16.4024 ppl_loss=8.6159 ppl=12324.14\n",
            "[PEZ λ=0.75 ADV] Epoch 1/5, batch 300 | joint=22.9073 task=16.4306 ppl_loss=8.6355 ppl=12067.77\n",
            "[PEZ λ=0.75 ADV] Epoch 1/5, batch 350 | joint=22.9046 task=16.4183 ppl_loss=8.6484 ppl=11718.39\n",
            "[PEZ λ=0.75 ADV] Epoch 1/5, batch 400 | joint=22.9164 task=16.4308 ppl_loss=8.6475 ppl=11307.87\n",
            "[PEZ λ=0.75 ADV] Epoch 1/5, batch 450 | joint=22.9030 task=16.4098 ppl_loss=8.6577 ppl=11257.62\n",
            "[PEZ λ=0.75 ADV] Epoch 1/5, batch 500 | joint=22.9090 task=16.3973 ppl_loss=8.6823 ppl=11371.73\n",
            "[PEZ λ=0.75 ADV] Epoch 1/5, batch 550 | joint=22.9225 task=16.4168 ppl_loss=8.6743 ppl=11261.52\n",
            "[PEZ λ=0.75 ADV] Epoch 1/5 | joint=22.9242 task=16.4034 ppl_loss=8.6945 ppl=11391.79 val_loss=21.2924 val_acc=0.7966 (true=0.8062 false=0.7809) prompt_ppl=17883.12\n",
            "Prompt: PAC parcare mancare Mol porumbOrientmati Hä copilulmigran\n",
            "[PEZ λ=0.75 ADV] Epoch 2/5, batch 50 | joint=23.2771 task=16.6007 ppl_loss=8.9018 ppl=32042.61\n",
            "[PEZ λ=0.75 ADV] Epoch 2/5, batch 100 | joint=23.0049 task=16.4873 ppl_loss=8.6902 ppl=19425.07\n",
            "[PEZ λ=0.75 ADV] Epoch 2/5, batch 150 | joint=23.0292 task=16.5559 ppl_loss=8.6311 ppl=15603.46\n",
            "[PEZ λ=0.75 ADV] Epoch 2/5, batch 200 | joint=23.0097 task=16.5347 ppl_loss=8.6333 ppl=14470.83\n",
            "[PEZ λ=0.75 ADV] Epoch 2/5, batch 250 | joint=22.9968 task=16.5133 ppl_loss=8.6447 ppl=14189.44\n",
            "[PEZ λ=0.75 ADV] Epoch 2/5, batch 300 | joint=23.0176 task=16.5258 ppl_loss=8.6558 ppl=13732.82\n",
            "[PEZ λ=0.75 ADV] Epoch 2/5, batch 350 | joint=23.0134 task=16.5110 ppl_loss=8.6698 ppl=13779.37\n",
            "[PEZ λ=0.75 ADV] Epoch 2/5, batch 400 | joint=23.0093 task=16.5169 ppl_loss=8.6566 ppl=13271.44\n",
            "[PEZ λ=0.75 ADV] Epoch 2/5, batch 450 | joint=23.0046 task=16.5037 ppl_loss=8.6678 ppl=12963.70\n",
            "[PEZ λ=0.75 ADV] Epoch 2/5, batch 500 | joint=23.0099 task=16.5000 ppl_loss=8.6798 ppl=12709.77\n",
            "[PEZ λ=0.75 ADV] Epoch 2/5, batch 550 | joint=22.9813 task=16.4717 ppl_loss=8.6794 ppl=12609.56\n",
            "[PEZ λ=0.75 ADV] Epoch 2/5 | joint=22.9888 task=16.4811 ppl_loss=8.6770 ppl=12334.66 val_loss=21.6436 val_acc=0.7991 (true=0.8091 false=0.7825) prompt_ppl=21570.20\n",
            "Prompt: matikrandul Sinooilea cursuri angajator Bezirksdependentwagenonic\n",
            "[PEZ λ=0.75 ADV] Epoch 3/5, batch 50 | joint=22.9384 task=16.3532 ppl_loss=8.7802 ppl=13331.17\n",
            "[PEZ λ=0.75 ADV] Epoch 3/5, batch 100 | joint=22.9201 task=16.3897 ppl_loss=8.7072 ppl=12013.10\n",
            "[PEZ λ=0.75 ADV] Epoch 3/5, batch 150 | joint=22.9374 task=16.4280 ppl_loss=8.6791 ppl=10582.14\n",
            "[PEZ λ=0.75 ADV] Epoch 3/5, batch 200 | joint=22.9877 task=16.4607 ppl_loss=8.7027 ppl=11574.92\n",
            "[PEZ λ=0.75 ADV] Epoch 3/5, batch 250 | joint=22.8961 task=16.4060 ppl_loss=8.6534 ppl=10588.41\n",
            "[PEZ λ=0.75 ADV] Epoch 3/5, batch 300 | joint=22.9276 task=16.4056 ppl_loss=8.6959 ppl=10613.33\n",
            "[PEZ λ=0.75 ADV] Epoch 3/5, batch 350 | joint=22.8837 task=16.3585 ppl_loss=8.7004 ppl=12015.62\n",
            "[PEZ λ=0.75 ADV] Epoch 3/5, batch 400 | joint=22.8782 task=16.3685 ppl_loss=8.6795 ppl=11686.95\n",
            "[PEZ λ=0.75 ADV] Epoch 3/5, batch 450 | joint=22.8983 task=16.3858 ppl_loss=8.6833 ppl=11437.92\n",
            "[PEZ λ=0.75 ADV] Epoch 3/5, batch 500 | joint=22.9340 task=16.3997 ppl_loss=8.7125 ppl=11823.57\n",
            "[PEZ λ=0.75 ADV] Epoch 3/5, batch 550 | joint=22.9326 task=16.4047 ppl_loss=8.7039 ppl=11701.70\n",
            "[PEZ λ=0.75 ADV] Epoch 3/5 | joint=22.9455 task=16.3960 ppl_loss=8.7327 ppl=11930.07 val_loss=21.1986 val_acc=0.7954 (true=0.8234 false=0.7494) prompt_ppl=5044.96\n",
            "Prompt: Floydgorge privest identificare clientilor Sfant taiatincat Slovakiaauthorised\n",
            "[PEZ λ=0.75 ADV] Epoch 4/5, batch 50 | joint=22.7439 task=16.3451 ppl_loss=8.5318 ppl=7887.12\n",
            "[PEZ λ=0.75 ADV] Epoch 4/5, batch 100 | joint=22.7941 task=16.2696 ppl_loss=8.6993 ppl=9309.30\n",
            "[PEZ λ=0.75 ADV] Epoch 4/5, batch 150 | joint=22.7768 task=16.2785 ppl_loss=8.6645 ppl=8667.55\n",
            "[PEZ λ=0.75 ADV] Epoch 4/5, batch 200 | joint=22.8157 task=16.3097 ppl_loss=8.6747 ppl=9152.06\n",
            "[PEZ λ=0.75 ADV] Epoch 4/5, batch 250 | joint=22.8001 task=16.2995 ppl_loss=8.6674 ppl=8983.62\n",
            "[PEZ λ=0.75 ADV] Epoch 4/5, batch 300 | joint=22.8457 task=16.3592 ppl_loss=8.6487 ppl=10073.67\n",
            "[PEZ λ=0.75 ADV] Epoch 4/5, batch 350 | joint=22.8387 task=16.3634 ppl_loss=8.6337 ppl=9820.66\n",
            "[PEZ λ=0.75 ADV] Epoch 4/5, batch 400 | joint=22.8336 task=16.3591 ppl_loss=8.6326 ppl=9687.90\n",
            "[PEZ λ=0.75 ADV] Epoch 4/5, batch 450 | joint=22.8363 task=16.3623 ppl_loss=8.6320 ppl=9518.18\n",
            "[PEZ λ=0.75 ADV] Epoch 4/5, batch 500 | joint=22.8668 task=16.3756 ppl_loss=8.6550 ppl=9851.13\n",
            "[PEZ λ=0.75 ADV] Epoch 4/5, batch 550 | joint=22.8886 task=16.3968 ppl_loss=8.6556 ppl=9949.02\n",
            "[PEZ λ=0.75 ADV] Epoch 4/5 | joint=22.8944 task=16.4007 ppl_loss=8.6583 ppl=9956.47 val_loss=21.6549 val_acc=0.7963 (true=0.8062 false=0.7801) prompt_ppl=8171.97\n",
            "Prompt: bowlcuprinsebaldelteMMA Lac ambalaj Britaniecurisunteti\n",
            "[PEZ λ=0.75 ADV] Epoch 5/5, batch 50 | joint=23.0298 task=16.3776 ppl_loss=8.8696 ppl=10239.17\n",
            "[PEZ λ=0.75 ADV] Epoch 5/5, batch 100 | joint=22.7933 task=16.2293 ppl_loss=8.7520 ppl=10962.07\n",
            "[PEZ λ=0.75 ADV] Epoch 5/5, batch 150 | joint=22.8067 task=16.2868 ppl_loss=8.6931 ppl=9653.52\n",
            "[PEZ λ=0.75 ADV] Epoch 5/5, batch 200 | joint=22.8541 task=16.3309 ppl_loss=8.6977 ppl=10412.74\n",
            "[PEZ λ=0.75 ADV] Epoch 5/5, batch 250 | joint=22.8516 task=16.3308 ppl_loss=8.6944 ppl=11053.85\n",
            "[PEZ λ=0.75 ADV] Epoch 5/5, batch 300 | joint=22.8609 task=16.3402 ppl_loss=8.6942 ppl=12261.10\n",
            "[PEZ λ=0.75 ADV] Epoch 5/5, batch 350 | joint=22.8883 task=16.3497 ppl_loss=8.7182 ppl=11997.64\n",
            "[PEZ λ=0.75 ADV] Epoch 5/5, batch 400 | joint=22.8399 task=16.3368 ppl_loss=8.6708 ppl=11453.70\n",
            "[PEZ λ=0.75 ADV] Epoch 5/5, batch 450 | joint=22.8710 task=16.3666 ppl_loss=8.6726 ppl=11309.32\n",
            "[PEZ λ=0.75 ADV] Epoch 5/5, batch 500 | joint=22.8898 task=16.3791 ppl_loss=8.6810 ppl=11220.83\n",
            "[PEZ λ=0.75 ADV] Epoch 5/5, batch 550 | joint=22.8692 task=16.3644 ppl_loss=8.6730 ppl=10930.49\n",
            "[PEZ λ=0.75 ADV] Epoch 5/5 | joint=22.8781 task=16.3844 ppl_loss=8.6583 ppl=10719.64 val_loss=19.8111 val_acc=0.7960 (true=0.8180 false=0.7599) prompt_ppl=6897.46\n",
            "Prompt: ridge sticla saptamana judetambogiaReilly incendiuNIAabl Kil\n",
            "\n",
            "=== PEZ Adversarial (λ=1.0) ===\n",
            "[PEZ λ=1.0 ADV] Epoch 1/5, batch 50 | joint=24.7763 task=16.1547 ppl_loss=8.6216 ppl=8923.88\n",
            "[PEZ λ=1.0 ADV] Epoch 1/5, batch 100 | joint=24.9278 task=16.2457 ppl_loss=8.6821 ppl=10534.60\n",
            "[PEZ λ=1.0 ADV] Epoch 1/5, batch 150 | joint=24.9703 task=16.2238 ppl_loss=8.7465 ppl=11222.72\n",
            "[PEZ λ=1.0 ADV] Epoch 1/5, batch 200 | joint=24.9560 task=16.2753 ppl_loss=8.6806 ppl=10395.86\n",
            "[PEZ λ=1.0 ADV] Epoch 1/5, batch 250 | joint=24.9279 task=16.3003 ppl_loss=8.6276 ppl=10317.64\n",
            "[PEZ λ=1.0 ADV] Epoch 1/5, batch 300 | joint=24.9481 task=16.3205 ppl_loss=8.6276 ppl=9869.23\n",
            "[PEZ λ=1.0 ADV] Epoch 1/5, batch 350 | joint=24.9721 task=16.3406 ppl_loss=8.6315 ppl=10290.45\n",
            "[PEZ λ=1.0 ADV] Epoch 1/5, batch 400 | joint=25.0258 task=16.3767 ppl_loss=8.6490 ppl=10516.42\n",
            "[PEZ λ=1.0 ADV] Epoch 1/5, batch 450 | joint=25.0396 task=16.3834 ppl_loss=8.6562 ppl=10289.92\n",
            "[PEZ λ=1.0 ADV] Epoch 1/5, batch 500 | joint=25.0714 task=16.4122 ppl_loss=8.6592 ppl=10164.87\n",
            "[PEZ λ=1.0 ADV] Epoch 1/5, batch 550 | joint=25.0646 task=16.4147 ppl_loss=8.6500 ppl=9946.51\n",
            "[PEZ λ=1.0 ADV] Epoch 1/5 | joint=25.0612 task=16.4022 ppl_loss=8.6591 ppl=9997.10 val_loss=22.3027 val_acc=0.7997 (true=0.8072 false=0.7874) prompt_ppl=1782.55\n",
            "Prompt: PittRIStină dispus Domnului unterwegsusziehbarectiv ganduri cavity\n",
            "[PEZ λ=1.0 ADV] Epoch 2/5, batch 50 | joint=25.0868 task=16.5044 ppl_loss=8.5824 ppl=8202.83\n",
            "[PEZ λ=1.0 ADV] Epoch 2/5, batch 100 | joint=25.0511 task=16.4240 ppl_loss=8.6271 ppl=9754.87\n",
            "[PEZ λ=1.0 ADV] Epoch 2/5, batch 150 | joint=25.0265 task=16.4323 ppl_loss=8.5943 ppl=9790.32\n",
            "[PEZ λ=1.0 ADV] Epoch 2/5, batch 200 | joint=25.0381 task=16.4239 ppl_loss=8.6143 ppl=10277.03\n",
            "[PEZ λ=1.0 ADV] Epoch 2/5, batch 250 | joint=24.9983 task=16.4217 ppl_loss=8.5766 ppl=9890.45\n",
            "[PEZ λ=1.0 ADV] Epoch 2/5, batch 300 | joint=25.0658 task=16.4051 ppl_loss=8.6607 ppl=10675.19\n",
            "[PEZ λ=1.0 ADV] Epoch 2/5, batch 350 | joint=25.1141 task=16.4483 ppl_loss=8.6658 ppl=10740.59\n",
            "[PEZ λ=1.0 ADV] Epoch 2/5, batch 400 | joint=25.1010 task=16.4456 ppl_loss=8.6555 ppl=10363.73\n",
            "[PEZ λ=1.0 ADV] Epoch 2/5, batch 450 | joint=25.1147 task=16.4332 ppl_loss=8.6815 ppl=10526.12\n",
            "[PEZ λ=1.0 ADV] Epoch 2/5, batch 500 | joint=25.1283 task=16.4355 ppl_loss=8.6929 ppl=10464.94\n",
            "[PEZ λ=1.0 ADV] Epoch 2/5, batch 550 | joint=25.1216 task=16.4216 ppl_loss=8.7000 ppl=10675.41\n",
            "[PEZ λ=1.0 ADV] Epoch 2/5 | joint=25.1185 task=16.4099 ppl_loss=8.7086 ppl=13761.68 val_loss=19.8489 val_acc=0.7957 (true=0.7993 false=0.7898) prompt_ppl=6346.02\n",
            "Prompt: rata proprietatiwaldcommandedpflichtigUneorikel logarhitric\n",
            "[PEZ λ=1.0 ADV] Epoch 3/5, batch 50 | joint=24.9873 task=16.3405 ppl_loss=8.6468 ppl=7451.64\n",
            "[PEZ λ=1.0 ADV] Epoch 3/5, batch 100 | joint=24.9978 task=16.3194 ppl_loss=8.6784 ppl=9386.82\n",
            "[PEZ λ=1.0 ADV] Epoch 3/5, batch 150 | joint=25.1305 task=16.3534 ppl_loss=8.7771 ppl=10235.96\n",
            "[PEZ λ=1.0 ADV] Epoch 3/5, batch 200 | joint=25.0742 task=16.3473 ppl_loss=8.7269 ppl=9745.07\n",
            "[PEZ λ=1.0 ADV] Epoch 3/5, batch 250 | joint=25.0735 task=16.3607 ppl_loss=8.7128 ppl=10032.12\n",
            "[PEZ λ=1.0 ADV] Epoch 3/5, batch 300 | joint=25.0035 task=16.3244 ppl_loss=8.6791 ppl=9854.37\n",
            "[PEZ λ=1.0 ADV] Epoch 3/5, batch 350 | joint=25.0766 task=16.3569 ppl_loss=8.7197 ppl=10393.09\n",
            "[PEZ λ=1.0 ADV] Epoch 3/5, batch 400 | joint=25.0445 task=16.3467 ppl_loss=8.6978 ppl=10078.65\n",
            "[PEZ λ=1.0 ADV] Epoch 3/5, batch 450 | joint=25.0442 task=16.3789 ppl_loss=8.6652 ppl=9663.32\n",
            "[PEZ λ=1.0 ADV] Epoch 3/5, batch 500 | joint=25.0539 task=16.3719 ppl_loss=8.6821 ppl=10120.62\n",
            "[PEZ λ=1.0 ADV] Epoch 3/5, batch 550 | joint=25.0506 task=16.3725 ppl_loss=8.6781 ppl=10302.10\n",
            "[PEZ λ=1.0 ADV] Epoch 3/5 | joint=25.0736 task=16.3658 ppl_loss=8.7078 ppl=10536.24 val_loss=21.7105 val_acc=0.7976 (true=0.8072 false=0.7817) prompt_ppl=2929.49\n",
            "Prompt: usziehbar comenzi Schwe achiziti Coordinat compozititellmeciulice penal\n",
            "[PEZ λ=1.0 ADV] Epoch 4/5, batch 50 | joint=24.7272 task=16.1680 ppl_loss=8.5593 ppl=7833.82\n",
            "[PEZ λ=1.0 ADV] Epoch 4/5, batch 100 | joint=24.9160 task=16.3368 ppl_loss=8.5792 ppl=7792.41\n",
            "[PEZ λ=1.0 ADV] Epoch 4/5, batch 150 | joint=24.8440 task=16.3785 ppl_loss=8.4655 ppl=6879.59\n",
            "[PEZ λ=1.0 ADV] Epoch 4/5, batch 200 | joint=24.8856 task=16.4013 ppl_loss=8.4843 ppl=7053.02\n",
            "[PEZ λ=1.0 ADV] Epoch 4/5, batch 250 | joint=25.0010 task=16.4738 ppl_loss=8.5272 ppl=7936.73\n",
            "[PEZ λ=1.0 ADV] Epoch 4/5, batch 300 | joint=25.0400 task=16.4972 ppl_loss=8.5428 ppl=8139.25\n",
            "[PEZ λ=1.0 ADV] Epoch 4/5, batch 350 | joint=25.0337 task=16.5039 ppl_loss=8.5299 ppl=8149.88\n",
            "[PEZ λ=1.0 ADV] Epoch 4/5, batch 400 | joint=25.0491 task=16.5073 ppl_loss=8.5418 ppl=8851.06\n",
            "[PEZ λ=1.0 ADV] Epoch 4/5, batch 450 | joint=25.0388 task=16.4770 ppl_loss=8.5618 ppl=8780.24\n",
            "[PEZ λ=1.0 ADV] Epoch 4/5, batch 500 | joint=25.0788 task=16.4696 ppl_loss=8.6092 ppl=9262.41\n",
            "[PEZ λ=1.0 ADV] Epoch 4/5, batch 550 | joint=25.0894 task=16.4615 ppl_loss=8.6279 ppl=9443.57\n",
            "[PEZ λ=1.0 ADV] Epoch 4/5 | joint=25.0633 task=16.4369 ppl_loss=8.6264 ppl=9331.65 val_loss=21.2032 val_acc=0.7951 (true=0.8067 false=0.7761) prompt_ppl=989.23\n",
            "Prompt: adica episodschieddachUA streak aparat cumpără stu Bauch\n",
            "[PEZ λ=1.0 ADV] Epoch 5/5, batch 50 | joint=25.2593 task=16.4257 ppl_loss=8.8336 ppl=9913.17\n",
            "[PEZ λ=1.0 ADV] Epoch 5/5, batch 100 | joint=25.1187 task=16.3954 ppl_loss=8.7233 ppl=11623.99\n",
            "[PEZ λ=1.0 ADV] Epoch 5/5, batch 150 | joint=25.0805 task=16.4226 ppl_loss=8.6579 ppl=10587.94\n",
            "[PEZ λ=1.0 ADV] Epoch 5/5, batch 200 | joint=25.0046 task=16.3911 ppl_loss=8.6135 ppl=9850.80\n",
            "[PEZ λ=1.0 ADV] Epoch 5/5, batch 250 | joint=25.0111 task=16.3732 ppl_loss=8.6379 ppl=10271.48\n",
            "[PEZ λ=1.0 ADV] Epoch 5/5, batch 300 | joint=25.0669 task=16.3820 ppl_loss=8.6849 ppl=10953.44\n",
            "[PEZ λ=1.0 ADV] Epoch 5/5, batch 350 | joint=25.0574 task=16.3842 ppl_loss=8.6732 ppl=10619.29\n",
            "[PEZ λ=1.0 ADV] Epoch 5/5, batch 400 | joint=25.0144 task=16.3666 ppl_loss=8.6478 ppl=10224.78\n",
            "[PEZ λ=1.0 ADV] Epoch 5/5, batch 450 | joint=25.0274 task=16.3765 ppl_loss=8.6509 ppl=10134.26\n",
            "[PEZ λ=1.0 ADV] Epoch 5/5, batch 500 | joint=25.0200 task=16.3669 ppl_loss=8.6531 ppl=10256.21\n",
            "[PEZ λ=1.0 ADV] Epoch 5/5, batch 550 | joint=25.0053 task=16.3554 ppl_loss=8.6500 ppl=10064.27\n",
            "[PEZ λ=1.0 ADV] Epoch 5/5 | joint=25.0178 task=16.3528 ppl_loss=8.6650 ppl=10226.86 val_loss=21.3118 val_acc=0.7914 (true=0.7993 false=0.7785) prompt_ppl=8484.86\n",
            "Prompt: serrurerie Twin Tempe Split dureri lumini alignmentgauImmobilierare\n"
          ]
        }
      ],
      "source": [
        "# PEZ runs over lambda grid\n",
        "pez_runs_adv = []\n",
        "for lam in [0.0, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1.0]:\n",
        "    print(f\"\\n=== PEZ Adversarial (λ={lam}) ===\")\n",
        "    pez_adv = train_pez(\n",
        "        cfg,\n",
        "        tokenizer,\n",
        "        gpt2_model,\n",
        "        gpt2_tokenizer,\n",
        "        train_dl,\n",
        "        val_dl,\n",
        "        lambda_ppl=lam,\n",
        "        adversarial=True,\n",
        "    )\n",
        "    pez_runs_adv.append((\"pez_adv\", lam, pez_adv))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved all non-adv models + histories.\n"
          ]
        }
      ],
      "source": [
        "import torch, json, os\n",
        "\n",
        "base_dir = \"/mnt/polished-lake/home/annabelma/other/results/unbalanced/pez_adv_models\"\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "for model_name, lam, result in pez_runs_adv:\n",
        "    model = result[\"model\"]\n",
        "    \n",
        "    # Save model weights\n",
        "    torch.save(model.state_dict(), f\"{base_dir}/model_lambda_{lam}.pt\")\n",
        "    \n",
        "    # Save history\n",
        "    with open(f\"{base_dir}/history_lambda_{lam}.json\", \"w\") as f:\n",
        "        json.dump(result[\"history\"], f, indent=2)\n",
        "\n",
        "print(\"Saved all non-adv models + histories.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n=== Summary (val_acc) ===\")\n",
        "print(\"Continuous Non-Adv:\", cont_non_adv[\"history\"][\"val_acc\"])\n",
        "print(\"Continuous Adv:\", cont_adv[\"history\"][\"val_acc\"])\n",
        "for name, lam, run in pez_runs:\n",
        "    print(f\"{name} λ={lam}: {run['history']['val_acc']}\")\n",
        "for name, lam, run in pez_runs_adv:\n",
        "    print(f\"{name} λ={lam}: {run['history']['val_acc']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grid search over lambda and learning rate for PEZ (balanced loader, non-adversarial)\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"GRID SEARCH: Lambda and Learning Rate for PEZ (Non-Adversarial, Balanced Loader)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "lambda_grid = [0.0, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1.0]\n",
        "lr_grid_pez = [1e-4, 5e-4, 1e-3, 5e-3, 1e-2]\n",
        "pez_grid_results = []\n",
        "\n",
        "for lam in lambda_grid:\n",
        "    for lr in lr_grid_pez:\n",
        "        print(f\"\\n--- Testing λ={lam}, LR={lr} ---\")\n",
        "        # Create a temporary config with this learning rate\n",
        "        temp_cfg = ExperimentConfig()\n",
        "        temp_cfg.lr = lr\n",
        "        \n",
        "        result = train_pez(\n",
        "            temp_cfg,\n",
        "            tokenizer,\n",
        "            gpt2_model,\n",
        "            gpt2_tokenizer,\n",
        "            train_dl,\n",
        "            val_dl,\n",
        "            lambda_ppl=lam,\n",
        "            adversarial=False,\n",
        "        )\n",
        "        \n",
        "        best_val_acc = max(result[\"history\"][\"val_acc\"])\n",
        "        final_val_acc = result[\"history\"][\"val_acc\"][-1]\n",
        "        prompt_ppl = result[\"history\"][\"prompt_ppl_ppx\"][-1] if result[\"history\"][\"prompt_ppl_ppx\"] else 0.0\n",
        "        \n",
        "        pez_grid_results.append({\n",
        "            \"lambda\": lam,\n",
        "            \"lr\": lr,\n",
        "            \"best_val_acc\": best_val_acc,\n",
        "            \"final_val_acc\": final_val_acc,\n",
        "            \"prompt_ppl\": prompt_ppl,\n",
        "            \"history\": result[\"history\"]\n",
        "        })\n",
        "        print(f\"λ={lam}, LR={lr:.0e}: best_val_acc={best_val_acc:.4f}, final_val_acc={final_val_acc:.4f}, prompt_ppl={prompt_ppl:.2f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PEZ Grid Search Results (sorted by best_val_acc):\")\n",
        "print(\"=\" * 80)\n",
        "sorted_results = sorted(pez_grid_results, key=lambda x: x[\"best_val_acc\"], reverse=True)\n",
        "for r in sorted_results[:10]:  # Show top 10\n",
        "    print(f\"λ={r['lambda']:.2f}, LR={r['lr']:.0e}: best_val_acc={r['best_val_acc']:.4f}, final_val_acc={r['final_val_acc']:.4f}, prompt_ppl={r['prompt_ppl']:.2f}\")\n",
        "\n",
        "best_pez_result = max(pez_grid_results, key=lambda x: x[\"best_val_acc\"])\n",
        "print(f\"\\nBest combination: λ={best_pez_result['lambda']:.2f}, LR={best_pez_result['lr']:.0e}\")\n",
        "print(f\"  best_val_acc={best_pez_result['best_val_acc']:.4f}, final_val_acc={best_pez_result['final_val_acc']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n=== Summary (val_acc) ===\")\n",
        "print(\"Continuous Non-Adv:\", cont_non_adv[\"history\"][\"val_acc\"])\n",
        "print(\"Continuous Adv:\", cont_adv[\"history\"][\"val_acc\"])\n",
        "for name, lam, run in pez_runs:\n",
        "    print(f\"{name} λ={lam}: {run['history']['val_acc']}\")\n",
        "for name, lam, run in pez_runs_adv:\n",
        "    print(f\"{name} λ={lam}: {run['history']['val_acc']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n=== Summary (val_acc) ===\")\n",
        "print(\"Continuous Non-Adv:\", cont_non_adv[\"history\"][\"val_acc\"])\n",
        "print(\"Continuous Adv:\", cont_adv[\"history\"][\"val_acc\"])\n",
        "for name, lam, run in pez_runs:\n",
        "    print(f\"{name} λ={lam}: {run['history']['val_acc']}\")\n",
        "for name, lam, run in pez_runs_adv:\n",
        "    print(f\"{name} λ={lam}: {run['history']['val_acc']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hVueorS6SZ6",
        "outputId": "95a70a8c-2d26-48c2-f9eb-9a415f5d96a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Summary (val_acc) ===\n",
            "Continuous Non-Adv: [0.6217125382262997, 0.6217125382262997, 0.6217125382262997]\n",
            "Continuous Adv: [0.3782874617737003, 0.3782874617737003, 0.3782874617737003]\n",
            "pez_non_adv λ=0.0: [0.5996941896024465, 0.3801223241590214, 0.38837920489296635]\n",
            "pez_non_adv λ=0.01: [0.5336391437308868, 0.6085626911314985, 0.3785932721712538]\n",
            "pez_non_adv λ=0.05: [0.3892966360856269, 0.5446483180428134, 0.3782874617737003]\n",
            "pez_non_adv λ=0.1: [0.40336391437308866, 0.40152905198776756, 0.44128440366972477]\n",
            "pez_non_adv λ=0.5: [0.38409785932721713, 0.3856269113149847, 0.37737003058103974]\n",
            "pez_non_adv λ=1.0: [0.40703363914373086, 0.41039755351681956, 0.38623853211009174]\n",
            "pez_adv λ=0.0: [0.5718654434250765, 0.3874617737003058, 0.41681957186544344]\n",
            "pez_adv λ=0.01: [0.39755351681957185, 0.3801223241590214, 0.3782874617737003]\n",
            "pez_adv λ=0.05: [0.3782874617737003, 0.3892966360856269, 0.445565749235474]\n",
            "pez_adv λ=0.1: [0.5440366972477064, 0.3785932721712538, 0.39785932721712536]\n",
            "pez_adv λ=0.5: [0.39785932721712536, 0.3782874617737003, 0.3908256880733945]\n",
            "pez_adv λ=1.0: [0.591743119266055, 0.45168195718654436, 0.38103975535168194]\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n=== Summary (val_acc) ===\")\n",
        "print(\"Continuous Non-Adv:\", cont_non_adv[\"history\"][\"val_acc\"])\n",
        "print(\"Continuous Adv:\", cont_adv[\"history\"][\"val_acc\"])\n",
        "for name, lam, run in pez_runs:\n",
        "    print(f\"{name} λ={lam}: {run['history']['val_acc']}\")for name, lam, run in pez_runs_adv:\n",
        "    print(f\"{name} λ={lam}: {run['history']['val_acc']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyVtfgQvZZKZ",
        "outputId": "61c71c62-772a-46e6-d22e-29fc58e862f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "EXPERIMENT SUMMARY\n",
            "================================================================================\n",
            "\n",
            "=== Continuous Soft Prompt Baselines ===\n",
            "Continuous Non-Adv        | best_val_acc=0.6217  final_val_acc=0.6217\n",
            "Continuous Adv            | best_val_acc=0.3783  final_val_acc=0.3783\n",
            "\n",
            "=== PEZ (Non-Adversarial vs Adversarial) by λ ===\n",
            "     λ | non-adv best non-adv final non-adv prompt_ppl ||   adv best  adv final  adv prompt_ppl\n",
            "-----------------------------------------------------------------------------------------------\n",
            " 0.000 |       0.5997       0.3884              0.00 ||     0.5719     0.4168            0.00\n",
            " 0.010 |       0.6086       0.3786           7338.29 ||     0.3976     0.3783         2189.04\n",
            " 0.050 |       0.5446       0.3783           6141.04 ||     0.4456     0.4456        16442.28\n",
            " 0.100 |       0.4413       0.4413           3583.40 ||     0.5440     0.3979        16234.79\n",
            " 0.500 |       0.3856       0.3774            919.75 ||     0.3979     0.3908         8645.68\n",
            " 1.000 |       0.4104       0.3862           2387.97 ||     0.5917     0.3810        13637.55\n",
            "\n",
            "=== Example Prompts per λ (Non-Adv vs Adv) ===\n",
            "\n",
            "λ = 0.0\n",
            "  [Non-Adv] cerinte pagina calorii trackback placeholder ConstanțaCamereMass senzati\n",
            "  [Adv]     costing căt Famous sticla?\" suprafete Plastic totusi unlike emoți\n",
            "\n",
            "λ = 0.01\n",
            "  [Non-Adv] sunteti ciocolat hypothesis manancOEneeded proaspat zgomotaparatul\n",
            "  [Adv]     praf prevazut gradini caldura clientilor clientilor pastraone totirival\n",
            "\n",
            "λ = 0.05\n",
            "  [Non-Adv] mananc mananc superioara reteta proaspat ingrijire mananc\n",
            "  [Adv]     stunnedney compozitiApplicantsreclining**dial Leicestercyangrav\n",
            "\n",
            "λ = 0.1\n",
            "  [Non-Adv] varf compoziti ingrijire 04/2\n",
            "  [Adv]     Cyber Dayscosting mancare assureddium pharmacist laboratories suprafete producator\n",
            "\n",
            "λ = 0.5\n",
            "  [Non-Adv] awaycît achizitierung senzati taiat suprafete suprafete\n",
            "  [Adv]     pan chlorinechezcône moale Falconcifra 04/2 pretulfoli\n",
            "\n",
            "λ = 1.0\n",
            "  [Non-Adv] bebelus dumneavoastra taiatinability\n",
            "  [Adv]     skeletal no suprafeteabia Correctioncada operations calibration summarize scaun\n",
            "\n",
            "================================================================================\n",
            "End of summary\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"EXPERIMENT SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Continuous soft prompt baselines\n",
        "# -----------------------------\n",
        "def summarize_continuous(name, result):\n",
        "    vals = result[\"history\"][\"val_acc\"]\n",
        "    best = max(vals)\n",
        "    final = vals[-1]\n",
        "    print(f\"{name:25s} | best_val_acc={best:.4f}  final_val_acc={final:.4f}\")\n",
        "\n",
        "print(\"\\n=== Continuous Soft Prompt Baselines ===\")\n",
        "summarize_continuous(\"Continuous Non-Adv\", cont_non_adv)\n",
        "summarize_continuous(\"Continuous Adv\",     cont_adv)\n",
        "\n",
        "# -----------------------------\n",
        "# 2. PEZ: non-adversarial vs adversarial by λ\n",
        "# -----------------------------\n",
        "# pez_runs:      [(name, lam, result_dict), ...]  # non-adv\n",
        "# pez_runs_adv: [(name, lam, result_dict), ...]  # adv\n",
        "\n",
        "nonadv_by_lam = {lam: run for (name, lam, run) in pez_runs}\n",
        "adv_by_lam    = {lam: run for (name, lam, run) in pez_runs_adv}\n",
        "\n",
        "all_lams = sorted(set(nonadv_by_lam.keys()) | set(adv_by_lam.keys()))\n",
        "\n",
        "print(\"\\n=== PEZ (Non-Adversarial vs Adversarial) by λ ===\")\n",
        "header = (\n",
        "    f\"{'λ':>6} | \"\n",
        "    f\"{'non-adv best':>12} {'non-adv final':>12} {'non-adv prompt_ppl':>17} || \"\n",
        "    f\"{'adv best':>10} {'adv final':>10} {'adv prompt_ppl':>15}\"\n",
        ")\n",
        "print(header)\n",
        "print(\"-\" * len(header))\n",
        "\n",
        "for lam in all_lams:\n",
        "    nonadv = nonadv_by_lam.get(lam)\n",
        "    adv    = adv_by_lam.get(lam)\n",
        "\n",
        "    # Non-adv stats\n",
        "    if nonadv is not None:\n",
        "        nav_vals = nonadv[\"history\"][\"val_acc\"]\n",
        "        nav_best = max(nav_vals)\n",
        "        nav_final = nav_vals[-1]\n",
        "        nav_ppl = nonadv[\"history\"].get(\"prompt_ppl_ppx\", [float(\"nan\")])[-1]\n",
        "    else:\n",
        "        nav_best = nav_final = nav_ppl = float(\"nan\")\n",
        "\n",
        "    # Adv stats\n",
        "    if adv is not None:\n",
        "        adv_vals = adv[\"history\"][\"val_acc\"]\n",
        "        adv_best = max(adv_vals)\n",
        "        adv_final = adv_vals[-1]\n",
        "        adv_ppl = adv[\"history\"].get(\"prompt_ppl_ppx\", [float(\"nan\")])[-1]\n",
        "    else:\n",
        "        adv_best = adv_final = adv_ppl = float(\"nan\")\n",
        "\n",
        "    print(\n",
        "        f\"{lam:6.3f} | \"\n",
        "        f\"{nav_best:12.4f} {nav_final:12.4f} {nav_ppl:17.2f} || \"\n",
        "        f\"{adv_best:10.4f} {adv_final:10.4f} {adv_ppl:15.2f}\"\n",
        "    )\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Example prompts per λ\n",
        "# -----------------------------\n",
        "print(\"\\n=== Example Prompts per λ (Non-Adv vs Adv) ===\")\n",
        "for lam in all_lams:\n",
        "    nonadv = nonadv_by_lam.get(lam)\n",
        "    adv    = adv_by_lam.get(lam)\n",
        "\n",
        "    print(f\"\\nλ = {lam}\")\n",
        "    if nonadv is not None:\n",
        "        try:\n",
        "            nav_prompt = nonadv[\"model\"].decode_prompt(tokenizer)\n",
        "        except Exception:\n",
        "            nav_prompt = \"<no decode_prompt method>\"\n",
        "        print(f\"  [Non-Adv] {nav_prompt}\")\n",
        "    else:\n",
        "        print(\"  [Non-Adv] (no run)\")\n",
        "\n",
        "    if adv is not None:\n",
        "        try:\n",
        "            adv_prompt = adv[\"model\"].decode_prompt(tokenizer)\n",
        "        except Exception:\n",
        "            adv_prompt = \"<no decode_prompt method>\"\n",
        "        print(f\"  [Adv]     {adv_prompt}\")\n",
        "    else:\n",
        "        print(\"  [Adv]     (no run)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"End of summary\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ay61XanF52h0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00b47d8727e74846b0f34f5965c1e594": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "085b923e86d04f5eb55cb22d6e2c90fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_863c0a415aee414898b4642b5e8ab66d",
            "placeholder": "​",
            "style": "IPY_MODEL_50b3ede950b743c2b7fbb95e6af6b034",
            "value": " 124/124 [00:00&lt;00:00, 15.9kB/s]"
          }
        },
        "086934b5adb1494c82f3cfd2afad0f34": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c0c7beb4c0e48f19d55760a141462ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c61ad218e38a4f91bee3d2aba749b418",
              "IPY_MODEL_b10cb7508ac449199e8616cecccfc52c",
              "IPY_MODEL_2efead2471ca4a3bb20607bb896e5eb2"
            ],
            "layout": "IPY_MODEL_c177a5639a1f4f1e8bb11d7f4cb423b0"
          }
        },
        "11f0dbd8f0094ee286a5d9fea27b6022": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1282c30469414c189d85af443093d9e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21836b672c2043fa921d15e889089787",
            "placeholder": "​",
            "style": "IPY_MODEL_5b8b5720210447fdb3a94847a1fa2009",
            "value": " 456k/456k [00:00&lt;00:00, 1.08MB/s]"
          }
        },
        "13d38c560176434eb7a59499fc2973d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14da7a720d9149bebc10df04372e1e1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d7599aa26904213bd54da21678646a4",
              "IPY_MODEL_34377ca0f40c40c79dc38262f42acc16",
              "IPY_MODEL_71556d7b286c4276a13f1b2d59e38c90"
            ],
            "layout": "IPY_MODEL_e0855a8f0f544de2bd5bc5d08715ae52"
          }
        },
        "1770a56348fd46faa7dda98fd6e469a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d7caa60ce2e4e8cabd76070d280423b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e51377579ba4abfa992c83c1f6cb813": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43d518174b1f453088029f68b3b6a8e7",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13d38c560176434eb7a59499fc2973d2",
            "value": 456318
          }
        },
        "20243da2ac294c3aacaf5d772e3949b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "215ed698f92440d6a46917aadac3c1c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7713e97d01641be959c80f7f026bdbf",
            "placeholder": "​",
            "style": "IPY_MODEL_fe10d19e5dc54962830988ae3e6a998e",
            "value": "merges.txt: 100%"
          }
        },
        "21836b672c2043fa921d15e889089787": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2efead2471ca4a3bb20607bb896e5eb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a93c739224fe48ae870d8a00619edc9a",
            "placeholder": "​",
            "style": "IPY_MODEL_ddb0f6c766214bc08d2a4cc6ac162723",
            "value": " 3270/3270 [00:06&lt;00:00, 1016.12 examples/s]"
          }
        },
        "2fd09996546e4f2baada745c4db3a97f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34377ca0f40c40c79dc38262f42acc16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2981cf4f6944050937be182e2d5a689",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e58c98d7d1b4985b70746e03ed024d4",
            "value": 1042301
          }
        },
        "39557a0229844ffa8de50a9311459fab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b564b95f24b47018a0c061b713fd2f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff2fd178419e48f0a922f7fb354ccaaa",
            "placeholder": "​",
            "style": "IPY_MODEL_783196c6ba9d4aa4b805d5625f5c9b98",
            "value": "Map: 100%"
          }
        },
        "3cfdcc6ee0024e4c9d196d1de4c5b015": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e58c98d7d1b4985b70746e03ed024d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4342b8d1363941288490c78ba8f9f0bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_632812daab0d4d4b9b0d175989fff0c8",
              "IPY_MODEL_d1072b96a26d410fa10ebf460b27560e",
              "IPY_MODEL_dad7a2483bc74bd280fb5c330a5a717b"
            ],
            "layout": "IPY_MODEL_f7b5c045bc3e45898e4aed56024949a9"
          }
        },
        "43d518174b1f453088029f68b3b6a8e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "470fc6596292403eb23f95be83990ca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a600e223f82494fb6d68e9bf3e0254a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cb307737e234c1680af072581479112": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d752fa70b2740e68d3e4edd94e22fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4fba7520145449a590054610593b8339": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50b3ede950b743c2b7fbb95e6af6b034": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51a225dc368549bdb1a5afcade5afdc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52a9351b0faa4f2aacb9bf49ece031fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "537277c120ca4dd495f0e3b948d81ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3cccc52a75343b28f52bc928d3619df",
            "max": 7106,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b83c602ff4df496f852b03d7c903988d",
            "value": 7106
          }
        },
        "53f3a7e017154ef98643eeaa464f8f48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55d1b5a100854d0589bbd3587273bcfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b8b5720210447fdb3a94847a1fa2009": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d25e89862664bdf9da8514b83074871": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f84e12c24e24469a4d7b0d96cef0f21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f9bd90305a34f1ca9144149d4ba4730": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "632812daab0d4d4b9b0d175989fff0c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cd283a1d6494809ab3b765c265576db",
            "placeholder": "​",
            "style": "IPY_MODEL_ed7aeb2009b1403582f0f227cff4e501",
            "value": "model.safetensors: 100%"
          }
        },
        "6cd283a1d6494809ab3b765c265576db": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f559210513640af97f3766efe23a3a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71556d7b286c4276a13f1b2d59e38c90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53f3a7e017154ef98643eeaa464f8f48",
            "placeholder": "​",
            "style": "IPY_MODEL_eb3d0d180d2e4a038b9fcf9980415f92",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 42.2MB/s]"
          }
        },
        "74a02027c1c54ea9831abcf5eb237a5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "783196c6ba9d4aa4b805d5625f5c9b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a2b7ab2ab7947d0968f00ae131435ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e3ca244fb6d4a248b3798617f150856": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f84e12c24e24469a4d7b0d96cef0f21",
            "placeholder": "​",
            "style": "IPY_MODEL_b29fe5a23ed44819a1c5d07abd6a6ce7",
            "value": " 7106/7106 [00:09&lt;00:00, 214.90 examples/s]"
          }
        },
        "80cd3377e1114fc0a2867d7ddfc139b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d25e89862664bdf9da8514b83074871",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_470fc6596292403eb23f95be83990ca4",
            "value": 26
          }
        },
        "8309bfc4dafb44acaf77c95898e29cca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b076905342de477fae2624ff76fd3882",
              "IPY_MODEL_9fc1258416a349c7a9762b600e85b223",
              "IPY_MODEL_9e3b3ee5f9024d56ac18dfeda824dba6"
            ],
            "layout": "IPY_MODEL_b20e90d9cfb847b7bfc0b42a48b2177e"
          }
        },
        "83e3eff2246d409eaa4da41eebe9cb2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "863c0a415aee414898b4642b5e8ab66d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "863e5e6b0574490687e34f80d592fe97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d015465f6ef45a3a2523436c980115c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d5ca3b68ec44c4d8280112c23209a9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ff27408b9644fb0b98c3124531750fa",
              "IPY_MODEL_d5797b4514b6495a9be7fbe2cc8a3813",
              "IPY_MODEL_085b923e86d04f5eb55cb22d6e2c90fe"
            ],
            "layout": "IPY_MODEL_52a9351b0faa4f2aacb9bf49ece031fb"
          }
        },
        "8fdf5679f14f4dce88cc699459e4ed79": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "967502b1a3514750975abe7dd9fb3eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d7599aa26904213bd54da21678646a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2873877eb504826955030022536b519",
            "placeholder": "​",
            "style": "IPY_MODEL_5f9bd90305a34f1ca9144149d4ba4730",
            "value": "vocab.json: 100%"
          }
        },
        "9e3b3ee5f9024d56ac18dfeda824dba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cb307737e234c1680af072581479112",
            "placeholder": "​",
            "style": "IPY_MODEL_4d752fa70b2740e68d3e4edd94e22fda",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 1.51MB/s]"
          }
        },
        "9fc1258416a349c7a9762b600e85b223": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7f08ad6930247f7afe82da892cf36f1",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51a225dc368549bdb1a5afcade5afdc5",
            "value": 1355256
          }
        },
        "9ff27408b9644fb0b98c3124531750fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddd74b2f17234311a64acd5ad4825181",
            "placeholder": "​",
            "style": "IPY_MODEL_55d1b5a100854d0589bbd3587273bcfd",
            "value": "generation_config.json: 100%"
          }
        },
        "a0cda38cd3f34a958bc37682c22e41ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a17df50c4f204519873f9106027417b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b564b95f24b47018a0c061b713fd2f2",
              "IPY_MODEL_537277c120ca4dd495f0e3b948d81ed7",
              "IPY_MODEL_7e3ca244fb6d4a248b3798617f150856"
            ],
            "layout": "IPY_MODEL_b0a00dfc20db40a3a75a8afde035f4d2"
          }
        },
        "a7b84fbc86d549d2b2d920b6e3e3f0e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1770a56348fd46faa7dda98fd6e469a1",
            "placeholder": "​",
            "style": "IPY_MODEL_8d015465f6ef45a3a2523436c980115c",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a93c739224fe48ae870d8a00619edc9a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b076905342de477fae2624ff76fd3882": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00b47d8727e74846b0f34f5965c1e594",
            "placeholder": "​",
            "style": "IPY_MODEL_1d7caa60ce2e4e8cabd76070d280423b",
            "value": "tokenizer.json: 100%"
          }
        },
        "b0a00dfc20db40a3a75a8afde035f4d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b10cb7508ac449199e8616cecccfc52c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0cda38cd3f34a958bc37682c22e41ac",
            "max": 3270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f559210513640af97f3766efe23a3a9",
            "value": 3270
          }
        },
        "b20e90d9cfb847b7bfc0b42a48b2177e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b264639e6ab844b2b9e82a12d4d416aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b29fe5a23ed44819a1c5d07abd6a6ce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6cea69db3f948d4a87de89ba2219766": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7b84fbc86d549d2b2d920b6e3e3f0e5",
              "IPY_MODEL_80cd3377e1114fc0a2867d7ddfc139b1",
              "IPY_MODEL_d58c3b603b5a4da3a3a7d9ebf688da03"
            ],
            "layout": "IPY_MODEL_20243da2ac294c3aacaf5d772e3949b4"
          }
        },
        "b83c602ff4df496f852b03d7c903988d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c177a5639a1f4f1e8bb11d7f4cb423b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2981cf4f6944050937be182e2d5a689": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c61ad218e38a4f91bee3d2aba749b418": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_086934b5adb1494c82f3cfd2afad0f34",
            "placeholder": "​",
            "style": "IPY_MODEL_863e5e6b0574490687e34f80d592fe97",
            "value": "Map: 100%"
          }
        },
        "c7477dbb47fb435fb346d77f02d608be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1072b96a26d410fa10ebf460b27560e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fba7520145449a590054610593b8339",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7477dbb47fb435fb346d77f02d608be",
            "value": 548105171
          }
        },
        "d4a756c485ed480abdfe51b4301d1e54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5797b4514b6495a9be7fbe2cc8a3813": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f32d7cb08ca24cdf8ada2ef29a808686",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83e3eff2246d409eaa4da41eebe9cb2c",
            "value": 124
          }
        },
        "d58c3b603b5a4da3a3a7d9ebf688da03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b264639e6ab844b2b9e82a12d4d416aa",
            "placeholder": "​",
            "style": "IPY_MODEL_e59b649c3ab24a4c8eee1a467f43bd87",
            "value": " 26.0/26.0 [00:00&lt;00:00, 3.78kB/s]"
          }
        },
        "d7f08ad6930247f7afe82da892cf36f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8b46c27ef8043f595b98f4325e209ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_215ed698f92440d6a46917aadac3c1c7",
              "IPY_MODEL_1e51377579ba4abfa992c83c1f6cb813",
              "IPY_MODEL_1282c30469414c189d85af443093d9e9"
            ],
            "layout": "IPY_MODEL_8fdf5679f14f4dce88cc699459e4ed79"
          }
        },
        "d9c22dc8fb8a4b5089e10d11d15860c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a2b7ab2ab7947d0968f00ae131435ff",
            "placeholder": "​",
            "style": "IPY_MODEL_967502b1a3514750975abe7dd9fb3eff",
            "value": " 665/665 [00:00&lt;00:00, 86.2kB/s]"
          }
        },
        "dad7a2483bc74bd280fb5c330a5a717b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cfdcc6ee0024e4c9d196d1de4c5b015",
            "placeholder": "​",
            "style": "IPY_MODEL_2fd09996546e4f2baada745c4db3a97f",
            "value": " 548M/548M [00:03&lt;00:00, 332MB/s]"
          }
        },
        "ddb0f6c766214bc08d2a4cc6ac162723": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddd74b2f17234311a64acd5ad4825181": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0855a8f0f544de2bd5bc5d08715ae52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0d9e9075bcf460b85dd4a67ff2641c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74a02027c1c54ea9831abcf5eb237a5e",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11f0dbd8f0094ee286a5d9fea27b6022",
            "value": 665
          }
        },
        "e2873877eb504826955030022536b519": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3cccc52a75343b28f52bc928d3619df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e59b649c3ab24a4c8eee1a467f43bd87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7713e97d01641be959c80f7f026bdbf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb3d0d180d2e4a038b9fcf9980415f92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed7aeb2009b1403582f0f227cff4e501": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f32d7cb08ca24cdf8ada2ef29a808686": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f74e787f1ed147c19fb487a581973321": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39557a0229844ffa8de50a9311459fab",
            "placeholder": "​",
            "style": "IPY_MODEL_d4a756c485ed480abdfe51b4301d1e54",
            "value": "config.json: 100%"
          }
        },
        "f7b5c045bc3e45898e4aed56024949a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb0254c92eb444729fca77fa6d1ef4cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f74e787f1ed147c19fb487a581973321",
              "IPY_MODEL_e0d9e9075bcf460b85dd4a67ff2641c9",
              "IPY_MODEL_d9c22dc8fb8a4b5089e10d11d15860c0"
            ],
            "layout": "IPY_MODEL_4a600e223f82494fb6d68e9bf3e0254a"
          }
        },
        "fe10d19e5dc54962830988ae3e6a998e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff2fd178419e48f0a922f7fb354ccaaa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
