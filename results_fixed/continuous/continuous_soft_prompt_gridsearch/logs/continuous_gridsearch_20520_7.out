================================================================================
Continuous Soft Prompt Training
================================================================================
Model: t5-large
Prompt Length: 10
Learning Rate: 0.001
Epochs: 10
Batch Size: 16
Adversarial: False
Device: cuda
Output Dir: /mnt/polished-lake/home/annabelma/other/results_fixed/continuous/continuous_soft_prompt_gridsearch
================================================================================

Loading tokenizer and data...
Balanced BoolQ train: 7106 examples (3553 True, 3553 False)
