================================================================================
Continuous Soft Prompt Training
================================================================================
Model: t5-large
Prompt Length: 20
Learning Rate: 0.0001
Epochs: 10
Batch Size: 16
Adversarial: False
Device: cuda
Output Dir: /mnt/polished-lake/home/annabelma/other/results_fixed/continuous/continuous_soft_prompt_len_10epochs
================================================================================

Loading tokenizer and data...
Balanced BoolQ train: 7106 examples (3553 True, 3553 False)

Training continuous soft prompt (NON-ADVERSARIAL)...
