Using device: cuda
Lambda: 1.0, LR: 0.0001, Adversarial: False

Loading T5 tokenizer...

Loading GPT-2 for prompt perplexity...

Loading BoolQ dataset...
Balanced BoolQ train: 7106 examples (3553 True, 3553 False)
[PEZ λ=1.0 NON-ADV] Epoch 1/10, batch 50 | joint=26.4157 task=16.5797 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 1/10, batch 100 | joint=26.5096 task=16.6735 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 1/10, batch 150 | joint=26.4870 task=16.6510 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 1/10, batch 200 | joint=26.4891 task=16.6530 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 1/10, batch 250 | joint=26.5159 task=16.6798 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 1/10, batch 300 | joint=26.4793 task=16.6432 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 1/10, batch 350 | joint=26.4976 task=16.6615 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 1/10, batch 400 | joint=26.5011 task=16.6651 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 1/10 | joint=26.4933 task=16.6572 ppl_loss=9.8361 ppl=18695.76 val_loss=13.2783 val_acc=0.6361 (true=0.4619 false=0.9224) prompt_ppl=18695.76
Prompt: Crest
[PEZ λ=1.0 NON-ADV] Epoch 2/10, batch 50 | joint=26.6133 task=16.7772 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 2/10, batch 100 | joint=26.5831 task=16.7470 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 2/10, batch 150 | joint=26.5765 task=16.7404 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 2/10, batch 200 | joint=26.5515 task=16.7154 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 2/10, batch 250 | joint=26.5362 task=16.7001 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 2/10, batch 300 | joint=26.5500 task=16.7140 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 2/10, batch 350 | joint=26.5438 task=16.7077 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 2/10, batch 400 | joint=26.5662 task=16.7301 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 2/10 | joint=26.5416 task=16.7056 ppl_loss=9.8361 ppl=18695.76 val_loss=5.0597 val_acc=0.7731 (true=0.7973 false=0.7332) prompt_ppl=18695.76
Prompt: Crest
[PEZ λ=1.0 NON-ADV] Epoch 3/10, batch 50 | joint=26.4607 task=16.6246 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 3/10, batch 100 | joint=26.4935 task=16.6575 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 3/10, batch 150 | joint=26.4915 task=16.6554 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 3/10, batch 200 | joint=26.5037 task=16.6677 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 3/10, batch 250 | joint=26.4815 task=16.6455 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 3/10, batch 300 | joint=26.4734 task=16.6373 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 3/10, batch 350 | joint=26.4596 task=16.6235 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 3/10, batch 400 | joint=26.4631 task=16.6271 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 3/10 | joint=26.4510 task=16.6149 ppl_loss=9.8361 ppl=18695.76 val_loss=1.1746 val_acc=0.6538 (true=0.9936 false=0.0954) prompt_ppl=18695.76
Prompt: Crest
[PEZ λ=1.0 NON-ADV] Epoch 4/10, batch 50 | joint=26.3699 task=16.5338 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 4/10, batch 100 | joint=26.5525 task=16.7164 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 4/10, batch 150 | joint=26.5803 task=16.7442 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 4/10, batch 200 | joint=26.5324 task=16.6964 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 4/10, batch 250 | joint=26.5578 task=16.7217 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 4/10, batch 300 | joint=26.5553 task=16.7193 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 4/10, batch 350 | joint=26.5595 task=16.7234 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 4/10, batch 400 | joint=26.5502 task=16.7141 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 4/10 | joint=26.5458 task=16.7098 ppl_loss=9.8361 ppl=18695.76 val_loss=0.8237 val_acc=0.6838 (true=0.9897 false=0.1811) prompt_ppl=18695.76
Prompt: Crest
[PEZ λ=1.0 NON-ADV] Epoch 5/10, batch 50 | joint=26.3564 task=16.5203 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 5/10, batch 100 | joint=26.4286 task=16.5925 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 5/10, batch 150 | joint=26.4379 task=16.6018 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 5/10, batch 200 | joint=26.4720 task=16.6359 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 5/10, batch 250 | joint=26.4733 task=16.6373 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 5/10, batch 300 | joint=26.4867 task=16.6506 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 5/10, batch 350 | joint=26.4976 task=16.6615 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 5/10, batch 400 | joint=26.4928 task=16.6568 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 5/10 | joint=26.4790 task=16.6430 ppl_loss=9.8361 ppl=18695.76 val_loss=0.2725 val_acc=0.7422 (true=0.8647 false=0.5408) prompt_ppl=18695.76
Prompt: Crest
[PEZ λ=1.0 NON-ADV] Epoch 6/10, batch 50 | joint=26.3593 task=16.5232 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 6/10, batch 100 | joint=26.4301 task=16.5940 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 6/10, batch 150 | joint=26.4303 task=16.5942 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 6/10, batch 200 | joint=26.4519 task=16.6158 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 6/10, batch 250 | joint=26.4847 task=16.6486 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 6/10, batch 300 | joint=26.5233 task=16.6873 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 6/10, batch 350 | joint=26.4742 task=16.6382 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 6/10, batch 400 | joint=26.4757 task=16.6397 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 6/10 | joint=26.4958 task=16.6597 ppl_loss=9.8361 ppl=18695.76 val_loss=0.9005 val_acc=0.6869 (true=0.9887 false=0.1908) prompt_ppl=18695.76
Prompt: Crest
[PEZ λ=1.0 NON-ADV] Epoch 7/10, batch 50 | joint=26.5479 task=16.7118 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 7/10, batch 100 | joint=26.5751 task=16.7390 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 7/10, batch 150 | joint=26.4831 task=16.6470 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 7/10, batch 200 | joint=26.4755 task=16.6395 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 7/10, batch 250 | joint=26.5011 task=16.6650 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 7/10, batch 300 | joint=26.4804 task=16.6444 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 7/10, batch 350 | joint=26.4938 task=16.6578 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 7/10, batch 400 | joint=26.4923 task=16.6563 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 7/10 | joint=26.5064 task=16.6703 ppl_loss=9.8361 ppl=18695.76 val_loss=0.5337 val_acc=0.6994 (true=0.9887 false=0.2239) prompt_ppl=18695.76
Prompt: Crest
[PEZ λ=1.0 NON-ADV] Epoch 8/10, batch 50 | joint=26.6970 task=16.8609 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 8/10, batch 100 | joint=26.6179 task=16.7818 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 8/10, batch 150 | joint=26.5680 task=16.7320 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 8/10, batch 200 | joint=26.5439 task=16.7079 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 8/10, batch 250 | joint=26.5474 task=16.7114 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 8/10, batch 300 | joint=26.5688 task=16.7327 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 8/10, batch 350 | joint=26.5588 task=16.7228 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 8/10, batch 400 | joint=26.5379 task=16.7018 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 8/10 | joint=26.5278 task=16.6917 ppl_loss=9.8361 ppl=18695.76 val_loss=0.6328 val_acc=0.6844 (true=0.9907 false=0.1811) prompt_ppl=18695.76
Prompt: Crest
[PEZ λ=1.0 NON-ADV] Epoch 9/10, batch 50 | joint=26.3669 task=16.5309 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 9/10, batch 100 | joint=26.3647 task=16.5286 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 9/10, batch 150 | joint=26.4014 task=16.5654 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 9/10, batch 200 | joint=26.4121 task=16.5760 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 9/10, batch 250 | joint=26.4338 task=16.5977 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 9/10, batch 300 | joint=26.4116 task=16.5756 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 9/10, batch 350 | joint=26.4320 task=16.5960 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 9/10, batch 400 | joint=26.4569 task=16.6208 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 9/10 | joint=26.4568 task=16.6207 ppl_loss=9.8361 ppl=18695.76 val_loss=0.3296 val_acc=0.6985 (true=0.9882 false=0.2223) prompt_ppl=18695.76
Prompt: Crest
[PEZ λ=1.0 NON-ADV] Epoch 10/10, batch 50 | joint=26.5418 task=16.7057 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 10/10, batch 100 | joint=26.5880 task=16.7520 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 10/10, batch 150 | joint=26.5689 task=16.7329 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 10/10, batch 200 | joint=26.5539 task=16.7178 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 10/10, batch 250 | joint=26.5293 task=16.6933 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 10/10, batch 300 | joint=26.5406 task=16.7045 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 10/10, batch 350 | joint=26.5419 task=16.7058 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 10/10, batch 400 | joint=26.5188 task=16.6828 ppl_loss=9.8361 ppl=18695.76
[PEZ λ=1.0 NON-ADV] Epoch 10/10 | joint=26.4986 task=16.6625 ppl_loss=9.8361 ppl=18695.76 val_loss=0.2061 val_acc=0.7128 (true=0.9843 false=0.2668) prompt_ppl=18695.76
Prompt: Crest

Results saved to /mnt/polished-lake/home/annabelma/other/results_fixed/pez_final_test/adversarial_false
  Model: model_lambda_1.0_lr_0.0001.pt
  History: history_lambda_1.0_lr_0.0001.json
Job 7 completed: lambda=1, lr=1e-4, epochs=10, prompt_length=1, adversarial=
