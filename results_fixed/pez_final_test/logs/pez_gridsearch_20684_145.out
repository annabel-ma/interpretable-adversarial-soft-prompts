Using device: cuda
Lambda: 0.75, LR: 1e-06, Adversarial: True

Loading T5 tokenizer...

Loading GPT-2 for prompt perplexity...

Loading BoolQ dataset...
Balanced BoolQ train: 7106 examples (3553 True, 3553 False)
[PEZ λ=0.75 ADV] Epoch 1/10, batch 50 | joint=20.1073 task=16.5237 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 1/10, batch 100 | joint=20.1191 task=16.5356 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 1/10, batch 150 | joint=20.1800 task=16.5964 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 1/10, batch 200 | joint=20.1653 task=16.5817 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 1/10, batch 250 | joint=20.1612 task=16.5776 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 1/10, batch 300 | joint=20.1710 task=16.5874 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 1/10, batch 350 | joint=20.1699 task=16.5863 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 1/10, batch 400 | joint=20.1574 task=16.5738 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 1/10 | joint=20.1582 task=16.5746 ppl_loss=4.7781 ppl=118.88 val_loss=14.6589 val_acc=0.6688 (true=0.5263 false=0.9030) prompt_ppl=118.88
Prompt: futur
[PEZ λ=0.75 ADV] Epoch 2/10, batch 50 | joint=20.2273 task=16.6437 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 2/10, batch 100 | joint=20.2334 task=16.6498 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 2/10, batch 150 | joint=20.1491 task=16.5655 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 2/10, batch 200 | joint=20.1603 task=16.5767 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 2/10, batch 250 | joint=20.1548 task=16.5712 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 2/10, batch 300 | joint=20.1475 task=16.5639 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 2/10, batch 350 | joint=20.1615 task=16.5779 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 2/10, batch 400 | joint=20.1698 task=16.5862 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 2/10 | joint=20.1852 task=16.6017 ppl_loss=4.7781 ppl=118.88 val_loss=13.6112 val_acc=0.6254 (true=0.4412 false=0.9281) prompt_ppl=118.88
Prompt: futur
[PEZ λ=0.75 ADV] Epoch 3/10, batch 50 | joint=20.1383 task=16.5547 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 3/10, batch 100 | joint=20.1932 task=16.6096 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 3/10, batch 150 | joint=20.1196 task=16.5360 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 3/10, batch 200 | joint=20.1326 task=16.5490 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 3/10, batch 250 | joint=20.1242 task=16.5406 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 3/10, batch 300 | joint=20.1471 task=16.5635 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 3/10, batch 350 | joint=20.1459 task=16.5624 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 3/10, batch 400 | joint=20.1425 task=16.5589 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 3/10 | joint=20.1429 task=16.5593 ppl_loss=4.7781 ppl=118.88 val_loss=13.2165 val_acc=0.6009 (true=0.3955 false=0.9386) prompt_ppl=118.88
Prompt: futur
[PEZ λ=0.75 ADV] Epoch 4/10, batch 50 | joint=20.2161 task=16.6326 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 4/10, batch 100 | joint=20.1460 task=16.5624 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 4/10, batch 150 | joint=20.0650 task=16.4814 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 4/10, batch 200 | joint=20.1147 task=16.5311 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 4/10, batch 250 | joint=20.1172 task=16.5336 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 4/10, batch 300 | joint=20.1306 task=16.5471 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 4/10, batch 350 | joint=20.1369 task=16.5533 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 4/10, batch 400 | joint=20.1539 task=16.5703 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 4/10 | joint=20.1650 task=16.5814 ppl_loss=4.7781 ppl=118.88 val_loss=12.9989 val_acc=0.5829 (true=0.3645 false=0.9418) prompt_ppl=118.88
Prompt: futur
[PEZ λ=0.75 ADV] Epoch 5/10, batch 50 | joint=20.3029 task=16.7193 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 5/10, batch 100 | joint=20.2101 task=16.6265 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 5/10, batch 150 | joint=20.1649 task=16.5813 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 5/10, batch 200 | joint=20.1437 task=16.5601 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 5/10, batch 250 | joint=20.1544 task=16.5709 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 5/10, batch 300 | joint=20.1351 task=16.5515 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 5/10, batch 350 | joint=20.1164 task=16.5328 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 5/10, batch 400 | joint=20.1306 task=16.5470 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 5/10 | joint=20.1281 task=16.5445 ppl_loss=4.7781 ppl=118.88 val_loss=12.9734 val_acc=0.5657 (true=0.3350 false=0.9450) prompt_ppl=118.88
Prompt: futur
[PEZ λ=0.75 ADV] Epoch 6/10, batch 50 | joint=20.2031 task=16.6195 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 6/10, batch 100 | joint=20.1382 task=16.5546 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 6/10, batch 150 | joint=20.1711 task=16.5875 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 6/10, batch 200 | joint=20.1646 task=16.5810 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 6/10, batch 250 | joint=20.1817 task=16.5981 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 6/10, batch 300 | joint=20.1852 task=16.6016 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 6/10, batch 350 | joint=20.1796 task=16.5960 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 6/10, batch 400 | joint=20.1566 task=16.5730 ppl_loss=4.7781 ppl=118.88
