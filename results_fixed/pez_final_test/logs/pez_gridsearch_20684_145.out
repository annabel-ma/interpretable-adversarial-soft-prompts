Using device: cuda
Lambda: 0.75, LR: 1e-06, Adversarial: True

Loading T5 tokenizer...

Loading GPT-2 for prompt perplexity...

Loading BoolQ dataset...
Balanced BoolQ train: 7106 examples (3553 True, 3553 False)
[PEZ λ=0.75 ADV] Epoch 1/10, batch 50 | joint=20.1073 task=16.5237 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 1/10, batch 100 | joint=20.1191 task=16.5356 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 1/10, batch 150 | joint=20.1800 task=16.5964 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 1/10, batch 200 | joint=20.1653 task=16.5817 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 1/10, batch 250 | joint=20.1612 task=16.5776 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 1/10, batch 300 | joint=20.1710 task=16.5874 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 1/10, batch 350 | joint=20.1699 task=16.5863 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 1/10, batch 400 | joint=20.1574 task=16.5738 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 1/10 | joint=20.1582 task=16.5746 ppl_loss=4.7781 ppl=118.88 val_loss=14.6589 val_acc=0.6688 (true=0.5263 false=0.9030) prompt_ppl=118.88
Prompt: futur
[PEZ λ=0.75 ADV] Epoch 2/10, batch 50 | joint=20.2273 task=16.6437 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 2/10, batch 100 | joint=20.2334 task=16.6498 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 2/10, batch 150 | joint=20.1491 task=16.5655 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 2/10, batch 200 | joint=20.1603 task=16.5767 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 2/10, batch 250 | joint=20.1548 task=16.5712 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 2/10, batch 300 | joint=20.1475 task=16.5639 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 2/10, batch 350 | joint=20.1615 task=16.5779 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 2/10, batch 400 | joint=20.1698 task=16.5862 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 2/10 | joint=20.1852 task=16.6017 ppl_loss=4.7781 ppl=118.88 val_loss=13.6112 val_acc=0.6254 (true=0.4412 false=0.9281) prompt_ppl=118.88
Prompt: futur
[PEZ λ=0.75 ADV] Epoch 3/10, batch 50 | joint=20.1383 task=16.5547 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 3/10, batch 100 | joint=20.1932 task=16.6096 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 3/10, batch 150 | joint=20.1196 task=16.5360 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 3/10, batch 200 | joint=20.1326 task=16.5490 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 3/10, batch 250 | joint=20.1242 task=16.5406 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 3/10, batch 300 | joint=20.1471 task=16.5635 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 3/10, batch 350 | joint=20.1459 task=16.5624 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 3/10, batch 400 | joint=20.1425 task=16.5589 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 3/10 | joint=20.1429 task=16.5593 ppl_loss=4.7781 ppl=118.88 val_loss=13.2165 val_acc=0.6009 (true=0.3955 false=0.9386) prompt_ppl=118.88
Prompt: futur
[PEZ λ=0.75 ADV] Epoch 4/10, batch 50 | joint=20.2161 task=16.6326 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 4/10, batch 100 | joint=20.1460 task=16.5624 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 4/10, batch 150 | joint=20.0650 task=16.4814 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 4/10, batch 200 | joint=20.1147 task=16.5311 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 4/10, batch 250 | joint=20.1172 task=16.5336 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 4/10, batch 300 | joint=20.1306 task=16.5471 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 4/10, batch 350 | joint=20.1369 task=16.5533 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 4/10, batch 400 | joint=20.1539 task=16.5703 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 4/10 | joint=20.1650 task=16.5814 ppl_loss=4.7781 ppl=118.88 val_loss=12.9989 val_acc=0.5829 (true=0.3645 false=0.9418) prompt_ppl=118.88
Prompt: futur
[PEZ λ=0.75 ADV] Epoch 5/10, batch 50 | joint=20.3029 task=16.7193 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 5/10, batch 100 | joint=20.2101 task=16.6265 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 5/10, batch 150 | joint=20.1649 task=16.5813 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 5/10, batch 200 | joint=20.1437 task=16.5601 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 5/10, batch 250 | joint=20.1544 task=16.5709 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 5/10, batch 300 | joint=20.1351 task=16.5515 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 5/10, batch 350 | joint=20.1164 task=16.5328 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 5/10, batch 400 | joint=20.1306 task=16.5470 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 5/10 | joint=20.1281 task=16.5445 ppl_loss=4.7781 ppl=118.88 val_loss=12.9734 val_acc=0.5657 (true=0.3350 false=0.9450) prompt_ppl=118.88
Prompt: futur
[PEZ λ=0.75 ADV] Epoch 6/10, batch 50 | joint=20.2031 task=16.6195 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 6/10, batch 100 | joint=20.1382 task=16.5546 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 6/10, batch 150 | joint=20.1711 task=16.5875 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 6/10, batch 200 | joint=20.1646 task=16.5810 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 6/10, batch 250 | joint=20.1817 task=16.5981 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 6/10, batch 300 | joint=20.1852 task=16.6016 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 6/10, batch 350 | joint=20.1796 task=16.5960 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 6/10, batch 400 | joint=20.1566 task=16.5730 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 6/10 | joint=20.1529 task=16.5693 ppl_loss=4.7781 ppl=118.88 val_loss=12.8961 val_acc=0.5627 (true=0.3286 false=0.9475) prompt_ppl=118.88
Prompt: futur
[PEZ λ=0.75 ADV] Epoch 7/10, batch 50 | joint=20.1436 task=16.5600 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 7/10, batch 100 | joint=20.1336 task=16.5500 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 7/10, batch 150 | joint=20.1221 task=16.5385 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 7/10, batch 200 | joint=20.1008 task=16.5173 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 7/10, batch 250 | joint=20.1097 task=16.5262 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 7/10, batch 300 | joint=20.1224 task=16.5388 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 7/10, batch 350 | joint=20.0908 task=16.5072 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 7/10, batch 400 | joint=20.1110 task=16.5274 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 7/10 | joint=20.1039 task=16.5204 ppl_loss=4.7781 ppl=118.88 val_loss=12.8258 val_acc=0.5505 (true=0.3055 false=0.9531) prompt_ppl=118.88
Prompt: futur
[PEZ λ=0.75 ADV] Epoch 8/10, batch 50 | joint=20.2257 task=16.6421 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 8/10, batch 100 | joint=20.2270 task=16.6434 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 8/10, batch 150 | joint=20.1769 task=16.5933 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 8/10, batch 200 | joint=20.1916 task=16.6080 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 8/10, batch 250 | joint=20.1676 task=16.5840 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 8/10, batch 300 | joint=20.1680 task=16.5844 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 8/10, batch 350 | joint=20.1597 task=16.5762 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 8/10, batch 400 | joint=20.1540 task=16.5704 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 8/10 | joint=20.1633 task=16.5797 ppl_loss=4.7781 ppl=118.88 val_loss=12.7876 val_acc=0.5483 (true=0.3005 false=0.9555) prompt_ppl=118.88
Prompt: futur
[PEZ λ=0.75 ADV] Epoch 9/10, batch 50 | joint=20.0956 task=16.5120 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 9/10, batch 100 | joint=20.0782 task=16.4946 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 9/10, batch 150 | joint=20.1660 task=16.5824 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 9/10, batch 200 | joint=20.1443 task=16.5607 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 9/10, batch 250 | joint=20.1528 task=16.5692 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 9/10, batch 300 | joint=20.1880 task=16.6044 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 9/10, batch 350 | joint=20.1840 task=16.6004 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 9/10, batch 400 | joint=20.1682 task=16.5846 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 9/10 | joint=20.1590 task=16.5754 ppl_loss=4.7781 ppl=118.88 val_loss=12.7519 val_acc=0.5419 (true=0.2887 false=0.9580) prompt_ppl=118.88
Prompt: futur
[PEZ λ=0.75 ADV] Epoch 10/10, batch 50 | joint=20.1696 task=16.5860 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 10/10, batch 100 | joint=20.1670 task=16.5834 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 10/10, batch 150 | joint=20.2193 task=16.6358 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 10/10, batch 200 | joint=20.1781 task=16.5946 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 10/10, batch 250 | joint=20.1798 task=16.5962 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 10/10, batch 300 | joint=20.1921 task=16.6085 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 10/10, batch 350 | joint=20.1675 task=16.5839 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 10/10, batch 400 | joint=20.1740 task=16.5904 ppl_loss=4.7781 ppl=118.88
[PEZ λ=0.75 ADV] Epoch 10/10 | joint=20.1683 task=16.5847 ppl_loss=4.7781 ppl=118.88 val_loss=12.7651 val_acc=0.5468 (true=0.2971 false=0.9572) prompt_ppl=118.88
Prompt: futur

Results saved to /mnt/polished-lake/home/annabelma/other/results_fixed/pez_final_test/adversarial_true
  Model: model_lambda_0.75_lr_1e-06.pt
  History: history_lambda_0.75_lr_1e-06.json
Job 145 completed: lambda=0.75, lr=1e-6, epochs=10, prompt_length=1, adversarial=--adversarial
