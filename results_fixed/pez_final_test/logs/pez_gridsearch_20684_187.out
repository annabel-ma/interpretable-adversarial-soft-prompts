Using device: cuda
Lambda: 0.25, LR: 0.001, Adversarial: True

Loading T5 tokenizer...

Loading GPT-2 for prompt perplexity...

Loading BoolQ dataset...
Balanced BoolQ train: 7106 examples (3553 True, 3553 False)
[PEZ λ=0.25 ADV] Epoch 1/10, batch 50 | joint=19.7558 task=17.5867 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 1/10, batch 100 | joint=19.7281 task=17.5591 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 1/10, batch 150 | joint=19.6220 task=17.4529 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 1/10, batch 200 | joint=19.5907 task=17.4216 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 1/10, batch 250 | joint=19.5663 task=17.3972 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 1/10, batch 300 | joint=19.5807 task=17.4117 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 1/10, batch 350 | joint=19.5828 task=17.4138 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 1/10, batch 400 | joint=19.5669 task=17.3978 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 1/10 | joint=19.5410 task=17.3720 ppl_loss=8.6762 ppl=5861.63 val_loss=1.2155 val_acc=0.6581 (true=0.9946 false=0.1051) prompt_ppl=5861.63
Prompt: letzten
[PEZ λ=0.25 ADV] Epoch 2/10, batch 50 | joint=19.4317 task=17.2627 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 2/10, batch 100 | joint=19.5159 task=17.3469 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 2/10, batch 150 | joint=19.5459 task=17.3769 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 2/10, batch 200 | joint=19.5389 task=17.3698 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 2/10, batch 250 | joint=19.5491 task=17.3801 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 2/10, batch 300 | joint=19.5523 task=17.3833 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 2/10, batch 350 | joint=19.5543 task=17.3852 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 2/10, batch 400 | joint=19.5593 task=17.3902 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 2/10 | joint=19.5640 task=17.3950 ppl_loss=8.6762 ppl=5861.63 val_loss=0.3538 val_acc=0.6422 (true=0.9975 false=0.0582) prompt_ppl=5861.63
Prompt: letzten
[PEZ λ=0.25 ADV] Epoch 3/10, batch 50 | joint=19.5679 task=17.3988 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 3/10, batch 100 | joint=19.4628 task=17.2938 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 3/10, batch 150 | joint=19.5342 task=17.3652 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 3/10, batch 200 | joint=19.5394 task=17.3703 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 3/10, batch 250 | joint=19.5553 task=17.3862 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 3/10, batch 300 | joint=19.5431 task=17.3740 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 3/10, batch 350 | joint=19.5374 task=17.3684 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 3/10, batch 400 | joint=19.5397 task=17.3707 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 3/10 | joint=19.5267 task=17.3577 ppl_loss=8.6762 ppl=5861.63 val_loss=0.4280 val_acc=0.6535 (true=0.9961 false=0.0905) prompt_ppl=5861.63
Prompt: letzten
[PEZ λ=0.25 ADV] Epoch 4/10, batch 50 | joint=19.4154 task=17.2463 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 4/10, batch 100 | joint=19.4327 task=17.2636 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 4/10, batch 150 | joint=19.4466 task=17.2776 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 4/10, batch 200 | joint=19.4916 task=17.3226 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 4/10, batch 250 | joint=19.5142 task=17.3451 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 4/10, batch 300 | joint=19.5016 task=17.3325 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 4/10, batch 350 | joint=19.4930 task=17.3240 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 4/10, batch 400 | joint=19.4936 task=17.3245 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 4/10 | joint=19.4885 task=17.3195 ppl_loss=8.6762 ppl=5861.63 val_loss=0.2410 val_acc=0.6474 (true=0.9970 false=0.0728) prompt_ppl=5861.63
Prompt: letzten
[PEZ λ=0.25 ADV] Epoch 5/10, batch 50 | joint=19.4755 task=17.3065 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 5/10, batch 100 | joint=19.5312 task=17.3621 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 5/10, batch 150 | joint=19.5565 task=17.3874 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 5/10, batch 200 | joint=19.5622 task=17.3931 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 5/10, batch 250 | joint=19.5623 task=17.3933 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 5/10, batch 300 | joint=19.5735 task=17.4044 ppl_loss=8.6762 ppl=5861.63
[PEZ λ=0.25 ADV] Epoch 5/10, batch 350 | joint=19.5516 task=17.3826 ppl_loss=8.6762 ppl=5861.63
