Using device: cuda
Lambda: 0.0, LR: 0.001, Adversarial: False

Loading T5 tokenizer...

Loading GPT-2 for prompt perplexity...

Loading BoolQ dataset...
Balanced BoolQ train: 7106 examples (3553 True, 3553 False)
[PEZ λ=0.0 NON-ADV] Epoch 1/10, batch 50 | joint=16.6420 task=16.6420 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 1/10, batch 100 | joint=16.5934 task=16.5934 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 1/10, batch 150 | joint=16.5955 task=16.5955 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 1/10, batch 200 | joint=16.5956 task=16.5956 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 1/10, batch 250 | joint=16.5531 task=16.5531 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 1/10, batch 300 | joint=16.5281 task=16.5281 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 1/10, batch 350 | joint=16.5053 task=16.5053 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 1/10, batch 400 | joint=16.5272 task=16.5272 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 1/10 | joint=16.5389 task=16.5389 ppl_loss=0.0000 ppl=0.00 val_loss=0.6593 val_acc=0.7514 (true=0.9557 false=0.4155) prompt_ppl=0.00
Prompt: wände
[PEZ λ=0.0 NON-ADV] Epoch 2/10, batch 50 | joint=16.4717 task=16.4717 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 2/10, batch 100 | joint=16.3778 task=16.3778 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 2/10, batch 150 | joint=16.4392 task=16.4392 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 2/10, batch 200 | joint=16.4563 task=16.4563 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 2/10, batch 250 | joint=16.4731 task=16.4731 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 2/10, batch 300 | joint=16.4755 task=16.4755 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 2/10, batch 350 | joint=16.4999 task=16.4999 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 2/10, batch 400 | joint=16.4952 task=16.4952 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 2/10 | joint=16.4813 task=16.4813 ppl_loss=0.0000 ppl=0.00 val_loss=0.3444 val_acc=0.6719 (true=0.9916 false=0.1463) prompt_ppl=0.00
Prompt: wände
[PEZ λ=0.0 NON-ADV] Epoch 3/10, batch 50 | joint=16.5719 task=16.5719 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 3/10, batch 100 | joint=16.5381 task=16.5381 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 3/10, batch 150 | joint=16.5414 task=16.5414 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 3/10, batch 200 | joint=16.5139 task=16.5139 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 3/10, batch 250 | joint=16.5062 task=16.5062 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 3/10, batch 300 | joint=16.5147 task=16.5147 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 3/10, batch 350 | joint=16.5166 task=16.5166 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 3/10, batch 400 | joint=16.5156 task=16.5156 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 3/10 | joint=16.5345 task=16.5345 ppl_loss=0.0000 ppl=0.00 val_loss=0.2079 val_acc=0.7086 (true=0.9852 false=0.2538) prompt_ppl=0.00
Prompt: wände
[PEZ λ=0.0 NON-ADV] Epoch 4/10, batch 50 | joint=16.4239 task=16.4239 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 4/10, batch 100 | joint=16.3262 task=16.3262 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 4/10, batch 150 | joint=16.3890 task=16.3890 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 4/10, batch 200 | joint=16.4073 task=16.4073 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 4/10, batch 250 | joint=16.4139 task=16.4139 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 4/10, batch 300 | joint=16.4353 task=16.4353 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 4/10, batch 350 | joint=16.4452 task=16.4452 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 4/10, batch 400 | joint=16.4583 task=16.4583 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 4/10 | joint=16.4608 task=16.4608 ppl_loss=0.0000 ppl=0.00 val_loss=0.1492 val_acc=0.7428 (true=0.9670 false=0.3743) prompt_ppl=0.00
Prompt: wände
[PEZ λ=0.0 NON-ADV] Epoch 5/10, batch 50 | joint=16.3513 task=16.3513 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 5/10, batch 100 | joint=16.4078 task=16.4078 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 5/10, batch 150 | joint=16.4325 task=16.4325 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 5/10, batch 200 | joint=16.4261 task=16.4261 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 5/10, batch 250 | joint=16.4079 task=16.4079 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 5/10, batch 300 | joint=16.4107 task=16.4107 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 5/10, batch 350 | joint=16.4043 task=16.4043 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 5/10, batch 400 | joint=16.4131 task=16.4131 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 5/10 | joint=16.4263 task=16.4263 ppl_loss=0.0000 ppl=0.00 val_loss=0.1531 val_acc=0.7446 (true=0.9666 false=0.3800) prompt_ppl=0.00
Prompt: wände
[PEZ λ=0.0 NON-ADV] Epoch 6/10, batch 50 | joint=16.4965 task=16.4965 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 6/10, batch 100 | joint=16.5388 task=16.5388 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 6/10, batch 150 | joint=16.5510 task=16.5510 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 6/10, batch 200 | joint=16.5435 task=16.5435 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 6/10, batch 250 | joint=16.5252 task=16.5252 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 6/10, batch 300 | joint=16.5170 task=16.5170 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 6/10, batch 350 | joint=16.5209 task=16.5209 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 6/10, batch 400 | joint=16.5173 task=16.5173 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 6/10 | joint=16.4974 task=16.4974 ppl_loss=0.0000 ppl=0.00 val_loss=0.1313 val_acc=0.7593 (true=0.9405 false=0.4616) prompt_ppl=0.00
Prompt: wände
[PEZ λ=0.0 NON-ADV] Epoch 7/10, batch 50 | joint=16.5192 task=16.5192 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 7/10, batch 100 | joint=16.5279 task=16.5279 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 7/10, batch 150 | joint=16.5472 task=16.5472 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 7/10, batch 200 | joint=16.5415 task=16.5415 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 7/10, batch 250 | joint=16.5205 task=16.5205 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 7/10, batch 300 | joint=16.5196 task=16.5196 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 7/10, batch 350 | joint=16.5063 task=16.5063 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 7/10, batch 400 | joint=16.4853 task=16.4853 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 7/10 | joint=16.4899 task=16.4899 ppl_loss=0.0000 ppl=0.00 val_loss=0.1427 val_acc=0.7557 (true=0.9656 false=0.4107) prompt_ppl=0.00
Prompt: wände
[PEZ λ=0.0 NON-ADV] Epoch 8/10, batch 50 | joint=16.5451 task=16.5451 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 8/10, batch 100 | joint=16.4619 task=16.4619 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 8/10, batch 150 | joint=16.4926 task=16.4926 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 8/10, batch 200 | joint=16.4700 task=16.4700 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 8/10, batch 250 | joint=16.4832 task=16.4832 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 8/10, batch 300 | joint=16.4918 task=16.4918 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 8/10, batch 350 | joint=16.4908 task=16.4908 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 8/10, batch 400 | joint=16.5026 task=16.5026 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 8/10 | joint=16.5082 task=16.5082 ppl_loss=0.0000 ppl=0.00 val_loss=0.1389 val_acc=0.7624 (true=0.9518 false=0.4511) prompt_ppl=0.00
Prompt: wände
[PEZ λ=0.0 NON-ADV] Epoch 9/10, batch 50 | joint=16.7177 task=16.7177 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 9/10, batch 100 | joint=16.6824 task=16.6824 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 9/10, batch 150 | joint=16.6545 task=16.6545 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 9/10, batch 200 | joint=16.5558 task=16.5558 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 9/10, batch 250 | joint=16.5276 task=16.5276 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 9/10, batch 300 | joint=16.5316 task=16.5316 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 9/10, batch 350 | joint=16.5236 task=16.5236 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 9/10, batch 400 | joint=16.5300 task=16.5300 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 9/10 | joint=16.5206 task=16.5206 ppl_loss=0.0000 ppl=0.00 val_loss=0.1232 val_acc=0.7673 (true=0.9267 false=0.5053) prompt_ppl=0.00
Prompt: wände
[PEZ λ=0.0 NON-ADV] Epoch 10/10, batch 50 | joint=16.4323 task=16.4323 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 10/10, batch 100 | joint=16.4291 task=16.4291 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 10/10, batch 150 | joint=16.4023 task=16.4023 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 10/10, batch 200 | joint=16.4268 task=16.4268 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 10/10, batch 250 | joint=16.4357 task=16.4357 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 10/10, batch 300 | joint=16.4238 task=16.4238 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 10/10, batch 350 | joint=16.4337 task=16.4337 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 10/10, batch 400 | joint=16.4391 task=16.4391 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 10/10 | joint=16.4312 task=16.4312 ppl_loss=0.0000 ppl=0.00 val_loss=0.1199 val_acc=0.7743 (true=0.9183 false=0.5376) prompt_ppl=0.00
Prompt: wände

Results saved to /mnt/polished-lake/home/annabelma/other/results_fixed/pez_final_test/adversarial_false
  Model: model_lambda_0.0_lr_0.001.pt
  History: history_lambda_0.0_lr_0.001.json
Job 109 completed: lambda=0, lr=1e-3, epochs=10, prompt_length=1, adversarial=
