Using device: cuda
Lambda: 0.25, LR: 0.1, Adversarial: True

Loading T5 tokenizer...

Loading GPT-2 for prompt perplexity...

Loading BoolQ dataset...
Balanced BoolQ train: 7106 examples (3553 True, 3553 False)
[PEZ λ=0.25 ADV] Epoch 1/10, batch 50 | joint=17.1064 task=17.1064 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 1/10, batch 100 | joint=17.1109 task=17.1109 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 1/10, batch 150 | joint=17.1108 task=17.1108 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 1/10, batch 200 | joint=17.0848 task=17.0848 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 1/10, batch 250 | joint=17.1072 task=17.1072 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 1/10, batch 300 | joint=17.1174 task=17.1174 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 1/10, batch 350 | joint=17.1204 task=17.1204 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 1/10, batch 400 | joint=17.1441 task=17.1441 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 1/10 | joint=17.1345 task=17.1345 ppl_loss=0.0000 ppl=1.00 val_loss=10.6320 val_acc=0.5823 (true=0.3640 false=0.9410) prompt_ppl=nan
Prompt: AV
[PEZ λ=0.25 ADV] Epoch 2/10, batch 50 | joint=17.3412 task=17.3412 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 2/10, batch 100 | joint=17.2346 task=17.2346 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 2/10, batch 150 | joint=17.2413 task=17.2413 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 2/10, batch 200 | joint=17.2278 task=17.2278 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 2/10, batch 250 | joint=17.2505 task=17.2505 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 2/10, batch 300 | joint=17.2568 task=17.2568 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 2/10, batch 350 | joint=17.2707 task=17.2707 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 2/10, batch 400 | joint=17.2423 task=17.2423 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 2/10 | joint=17.2225 task=17.2225 ppl_loss=0.0000 ppl=1.00 val_loss=0.1816 val_acc=0.6550 (true=0.9921 false=0.1011) prompt_ppl=nan
Prompt: AV
[PEZ λ=0.25 ADV] Epoch 3/10, batch 50 | joint=17.0877 task=17.0877 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 3/10, batch 100 | joint=17.1352 task=17.1352 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 3/10, batch 150 | joint=17.2253 task=17.2253 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 3/10, batch 200 | joint=17.2205 task=17.2205 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 3/10, batch 250 | joint=17.2128 task=17.2128 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 3/10, batch 300 | joint=17.2164 task=17.2164 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 3/10, batch 350 | joint=17.2414 task=17.2414 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 3/10, batch 400 | joint=17.2351 task=17.2351 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 3/10 | joint=17.2203 task=17.2203 ppl_loss=0.0000 ppl=1.00 val_loss=0.2257 val_acc=0.6220 (true=1.0000 false=0.0008) prompt_ppl=nan
Prompt: AV
[PEZ λ=0.25 ADV] Epoch 4/10, batch 50 | joint=17.1368 task=17.1368 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 4/10, batch 100 | joint=17.2850 task=17.2850 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 4/10, batch 150 | joint=17.2799 task=17.2799 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 4/10, batch 200 | joint=17.2285 task=17.2285 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 4/10, batch 250 | joint=17.2315 task=17.2315 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 4/10, batch 300 | joint=17.2005 task=17.2005 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 4/10, batch 350 | joint=17.1818 task=17.1818 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 4/10, batch 400 | joint=17.2107 task=17.2107 ppl_loss=0.0000 ppl=1.00
[PEZ λ=0.25 ADV] Epoch 4/10 | joint=17.2292 task=17.2292 ppl_loss=0.0000 ppl=1.00 val_loss=0.2185 val_acc=0.6217 (true=1.0000 false=0.0000) prompt_ppl=nan
Prompt: AV
[PEZ λ=0.25 ADV] Epoch 5/10, batch 50 | joint=17.0537 task=17.0537 ppl_loss=0.0000 ppl=1.00
