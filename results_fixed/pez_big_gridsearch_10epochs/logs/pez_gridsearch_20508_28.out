Using device: cuda
Lambda: 0.0, LR: 1e-05, Adversarial: True

Loading T5 tokenizer...

Loading GPT-2 for prompt perplexity...

Loading BoolQ dataset...
Balanced BoolQ train: 7106 examples (3553 True, 3553 False)
[PEZ λ=0.0 ADV] Epoch 1/10, batch 50 | joint=18.1584 task=18.1584 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 1/10, batch 100 | joint=18.1309 task=18.1309 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 1/10, batch 150 | joint=18.1850 task=18.1850 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 1/10, batch 200 | joint=18.1816 task=18.1816 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 1/10, batch 250 | joint=18.1530 task=18.1530 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 1/10, batch 300 | joint=18.1290 task=18.1290 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 1/10, batch 350 | joint=18.1277 task=18.1277 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 1/10, batch 400 | joint=18.1049 task=18.1049 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 1/10 | joint=18.1183 task=18.1183 ppl_loss=0.0000 ppl=0.00 val_loss=8.9269 val_acc=0.4251 (true=0.0777 false=0.9960) prompt_ppl=0.00
Prompt: Aplica Beer Guntude legal540 Graunado drept ISBN
[PEZ λ=0.0 ADV] Epoch 2/10, batch 50 | joint=18.0260 task=18.0260 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 2/10, batch 100 | joint=18.0292 task=18.0292 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 2/10, batch 150 | joint=18.0475 task=18.0475 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 2/10, batch 200 | joint=18.0863 task=18.0863 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 2/10, batch 250 | joint=18.0980 task=18.0980 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 2/10, batch 300 | joint=18.0997 task=18.0997 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 2/10, batch 350 | joint=18.0966 task=18.0966 ppl_loss=0.0000 ppl=0.00
