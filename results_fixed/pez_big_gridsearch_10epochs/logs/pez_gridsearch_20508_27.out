Using device: cuda
Lambda: 0.0, LR: 1e-05, Adversarial: False

Loading T5 tokenizer...

Loading GPT-2 for prompt perplexity...

Loading BoolQ dataset...
Balanced BoolQ train: 7106 examples (3553 True, 3553 False)
[PEZ λ=0.0 NON-ADV] Epoch 1/10, batch 50 | joint=17.1818 task=17.1818 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 1/10, batch 100 | joint=17.2308 task=17.2308 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 1/10, batch 150 | joint=17.2695 task=17.2695 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 1/10, batch 200 | joint=17.2680 task=17.2680 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 1/10, batch 250 | joint=17.2464 task=17.2464 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 1/10, batch 300 | joint=17.2491 task=17.2491 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 1/10, batch 350 | joint=17.2270 task=17.2270 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 1/10, batch 400 | joint=17.2345 task=17.2345 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 1/10 | joint=17.2352 task=17.2352 ppl_loss=0.0000 ppl=0.00 val_loss=9.3324 val_acc=0.5462 (true=0.3040 false=0.9442) prompt_ppl=0.00
Prompt: transformation bulbs Bell nähercellules réseaudayEMS compound."
[PEZ λ=0.0 NON-ADV] Epoch 2/10, batch 50 | joint=17.1612 task=17.1612 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 2/10, batch 100 | joint=17.2357 task=17.2357 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 2/10, batch 150 | joint=17.1845 task=17.1845 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 2/10, batch 200 | joint=17.1994 task=17.1994 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 2/10, batch 250 | joint=17.2100 task=17.2100 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 2/10, batch 300 | joint=17.1831 task=17.1831 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 2/10, batch 350 | joint=17.1971 task=17.1971 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 2/10, batch 400 | joint=17.2084 task=17.2084 ppl_loss=0.0000 ppl=0.00
