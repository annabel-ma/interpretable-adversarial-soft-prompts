Using device: cuda
Lambda: 0.0, LR: 1e-05, Adversarial: False

Loading T5 tokenizer...

Loading GPT-2 for prompt perplexity...

Loading BoolQ dataset...
Balanced BoolQ train: 7106 examples (3553 True, 3553 False)
[PEZ 位=0.0 NON-ADV] Epoch 1/5, batch 50 | joint=17.0910 task=17.0910 ppl_loss=0.0000 ppl=0.00
[PEZ 位=0.0 NON-ADV] Epoch 1/5, batch 100 | joint=17.1197 task=17.1197 ppl_loss=0.0000 ppl=0.00
[PEZ 位=0.0 NON-ADV] Epoch 1/5, batch 150 | joint=17.0699 task=17.0699 ppl_loss=0.0000 ppl=0.00
[PEZ 位=0.0 NON-ADV] Epoch 1/5, batch 200 | joint=17.0893 task=17.0893 ppl_loss=0.0000 ppl=0.00
