{
  "lambda_ppl": 1.0,
  "train_joint": [
    26.44262392279807,
    26.46185029704919,
    26.48127490697282,
    26.420159363478756,
    26.530440058333152,
    26.45855792184894,
    26.46462254042036,
    26.41708915367555,
    26.44919730197178,
    26.461189188582175
  ],
  "train_task": [
    17.15849678382445,
    17.177723164504833,
    17.197147737995962,
    17.136032130209248,
    17.246312887213204,
    17.174430748585905,
    17.18049536287115,
    17.132961952552368,
    17.165070049414474,
    17.177061993888255
  ],
  "train_ppl_loss": [
    9.284127235412598,
    9.284127235412598,
    9.284127235412598,
    9.284127235412598,
    9.284127235412598,
    9.284127235412598,
    9.284127235412598,
    9.284127235412598,
    9.284127235412598,
    9.284127235412598
  ],
  "train_ppl_ppx": [
    10765.77323050465,
    10765.77323050465,
    10765.77323050465,
    10765.77323050465,
    10765.77323050465,
    10765.77323050465,
    10765.77323050465,
    10765.77323050465,
    10765.77323050465,
    10765.77323050465
  ],
  "val_loss": [
    0.1918266813202602,
    0.17822280206331392,
    0.17940896687711158,
    0.19832859606277653,
    0.1998896961168545,
    0.1735088454150572,
    0.1720980539554503,
    0.16669519965241594,
    0.16678218398152328,
    0.17072207964048153
  ],
  "val_acc": [
    0.6253822629969419,
    0.6217125382262997,
    0.6217125382262997,
    0.6217125382262997,
    0.6217125382262997,
    0.6217125382262997,
    0.6217125382262997,
    0.6217125382262997,
    0.6284403669724771,
    0.6058103975535168
  ],
  "val_acc_true": [
    1.0,
    1.0,
    1.0,
    1.0,
    1.0,
    1.0,
    1.0,
    1.0,
    0.9975405804230202,
    0.822429906542056
  ],
  "val_acc_false": [
    0.009700889248181084,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.0,
    0.021827000808407437,
    0.2497978981406629
  ],
  "prompt_ppl_ppx": [
    10765.773230504701,
    10765.773230504701,
    10765.773230504701,
    10765.773230504701,
    10765.773230504701,
    10765.773230504701,
    10765.773230504701,
    10765.773230504701,
    10765.773230504701,
    10765.773230504701
  ]
}