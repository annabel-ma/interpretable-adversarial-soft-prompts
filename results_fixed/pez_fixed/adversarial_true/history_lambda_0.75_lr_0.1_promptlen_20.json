{
  "lambda_ppl": 0.75,
  "train_joint": [
    24.153168401825294,
    24.194609168406284,
    24.19403874257977,
    24.25718748114082,
    24.216909511437578,
    24.177933377898142,
    24.184670403298366,
    24.19662915776285,
    24.230930174066778,
    24.174741950731597
  ],
  "train_task": [
    16.89623990862557,
    16.93768080379186,
    16.93711030081417,
    17.00025903937522,
    16.959981133964625,
    16.921004936132537,
    16.92774195081732,
    16.939700750286658,
    16.974001863029567,
    16.917813628978944
  ],
  "train_ppl_loss": [
    9.675904273986816,
    9.675904273986816,
    9.675904273986816,
    9.675904273986816,
    9.675904273986816,
    9.675904273986816,
    9.675904273986816,
    9.675904273986816,
    9.675904273986816,
    9.675904273986816
  ],
  "train_ppl_ppx": [
    15929.1218205544,
    15929.1218205544,
    15929.1218205544,
    15929.1218205544,
    15929.1218205544,
    15929.1218205544,
    15929.1218205544,
    15929.1218205544,
    15929.1218205544,
    15929.1218205544
  ],
  "val_loss": [
    20.212885935713604,
    0.33917676762836735,
    0.1787970731534609,
    0.17761904084827843,
    0.17471508790807025,
    0.16980299528052167,
    0.17225327295501058,
    0.1760134872503397,
    0.17154547975557607,
    0.1729282795656018
  ],
  "val_acc": [
    0.3782874617737003,
    0.3782874617737003,
    0.6211009174311927,
    0.6217125382262997,
    0.6217125382262997,
    0.617125382262997,
    0.6207951070336392,
    0.6217125382262997,
    0.6217125382262997,
    0.6223241590214067
  ],
  "val_acc_true": [
    0.0,
    0.0,
    0.9985243482538121,
    0.9975405804230202,
    0.9985243482538121,
    0.9867191342843089,
    0.9970486965076242,
    1.0,
    0.999508116084604,
    1.0
  ],
  "val_acc_false": [
    1.0,
    1.0,
    0.0008084074373484236,
    0.004042037186742118,
    0.002425222312045271,
    0.009700889248181084,
    0.002425222312045271,
    0.0,
    0.0008084074373484236,
    0.0016168148746968471
  ],
  "prompt_ppl_ppx": [
    15929.121820554528,
    15929.121820554528,
    15929.121820554528,
    15929.121820554528,
    15929.121820554528,
    15929.121820554528,
    15929.121820554528,
    15929.121820554528,
    15929.121820554528,
    15929.121820554528
  ]
}