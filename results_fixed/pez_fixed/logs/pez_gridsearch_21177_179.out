Using device: cuda
Lambda: 0.01, LR: 1e-06, Adversarial: True

Loading T5 tokenizer...

Loading GPT-2 for prompt perplexity...

Loading BoolQ dataset...
Balanced BoolQ train: 7106 examples (3553 True, 3553 False)
[PEZ λ=0.01 ADV] Epoch 1/10, batch 50 | joint=17.3324 task=17.2503 ppl_loss=8.2120 ppl=3684.84
[PEZ λ=0.01 ADV] Epoch 1/10, batch 100 | joint=17.3256 task=17.2434 ppl_loss=8.2120 ppl=3684.84
[PEZ λ=0.01 ADV] Epoch 1/10, batch 150 | joint=17.2922 task=17.2101 ppl_loss=8.2120 ppl=3684.84
[PEZ λ=0.01 ADV] Epoch 1/10, batch 200 | joint=17.2885 task=17.2064 ppl_loss=8.2120 ppl=3684.84
[PEZ λ=0.01 ADV] Epoch 1/10, batch 250 | joint=17.2926 task=17.2105 ppl_loss=8.2120 ppl=3684.84
[PEZ λ=0.01 ADV] Epoch 1/10, batch 300 | joint=17.3259 task=17.2438 ppl_loss=8.2120 ppl=3684.84
[PEZ λ=0.01 ADV] Epoch 1/10, batch 350 | joint=17.3185 task=17.2364 ppl_loss=8.2120 ppl=3684.84
[PEZ λ=0.01 ADV] Epoch 1/10, batch 400 | joint=17.3032 task=17.2211 ppl_loss=8.2120 ppl=3684.84
[PEZ λ=0.01 ADV] Epoch 1/10 | joint=17.2921 task=17.2099 ppl_loss=8.2120 ppl=3684.84 val_loss=15.3020 val_acc=0.7437 (true=0.6990 false=0.8173) prompt_ppl=3684.84
Prompt: Punkte buckle entspannen photographs Gründe playlist Bucuresti Loverolulhäcylinder deltaziemlichDarüberarciniaeurope URL dar sizeaurezcomparatively niedrig composer foloseșt Vertrag signing ţări roundSerie Funeralcross Wind Altpipingntino homemade texts clipsliableaufnahme pachet apparently counselingabrimisieiministerium modelling03 Lost154
