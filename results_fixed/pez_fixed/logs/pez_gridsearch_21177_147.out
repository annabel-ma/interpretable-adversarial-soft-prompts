Using device: cuda
Lambda: 0.25, LR: 0.001, Adversarial: True

Loading T5 tokenizer...

Loading GPT-2 for prompt perplexity...

Loading BoolQ dataset...
Balanced BoolQ train: 7106 examples (3553 True, 3553 False)
[PEZ λ=0.25 ADV] Epoch 1/10, batch 50 | joint=19.1115 task=16.7101 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 1/10, batch 100 | joint=19.0028 task=16.6014 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 1/10, batch 150 | joint=18.9454 task=16.5439 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 1/10, batch 200 | joint=18.9168 task=16.5154 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 1/10, batch 250 | joint=18.8743 task=16.4729 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 1/10, batch 300 | joint=18.8921 task=16.4906 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 1/10, batch 350 | joint=18.9062 task=16.5048 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 1/10, batch 400 | joint=18.9130 task=16.5116 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 1/10 | joint=18.9172 task=16.5158 ppl_loss=9.6057 ppl=14848.52 val_loss=0.1721 val_acc=0.6315 (true=0.9995 false=0.0267) prompt_ppl=14848.52
Prompt: globe mortality counsel pergola ghostunterricht Pompe insgesamtboat grey
[PEZ λ=0.25 ADV] Epoch 2/10, batch 50 | joint=18.9993 task=16.5979 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 2/10, batch 100 | joint=18.9903 task=16.5888 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 2/10, batch 150 | joint=18.9216 task=16.5202 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 2/10, batch 200 | joint=18.8894 task=16.4880 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 2/10, batch 250 | joint=18.9057 task=16.5043 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 2/10, batch 300 | joint=18.9081 task=16.5067 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 2/10, batch 350 | joint=18.8872 task=16.4858 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 2/10, batch 400 | joint=18.8972 task=16.4958 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 2/10 | joint=18.9176 task=16.5162 ppl_loss=9.6057 ppl=14848.52 val_loss=0.1620 val_acc=0.6361 (true=0.9970 false=0.0428) prompt_ppl=14848.52
Prompt: globe mortality counsel pergola ghostunterricht Pompe insgesamtboat grey
[PEZ λ=0.25 ADV] Epoch 3/10, batch 50 | joint=18.8673 task=16.4659 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 3/10, batch 100 | joint=18.9480 task=16.5466 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 3/10, batch 150 | joint=18.9242 task=16.5228 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 3/10, batch 200 | joint=18.9056 task=16.5042 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 3/10, batch 250 | joint=18.8994 task=16.4980 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 3/10, batch 300 | joint=18.8903 task=16.4889 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 3/10, batch 350 | joint=18.8942 task=16.4928 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 3/10, batch 400 | joint=18.9036 task=16.5022 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 3/10 | joint=18.9111 task=16.5096 ppl_loss=9.6057 ppl=14848.52 val_loss=0.1982 val_acc=0.6217 (true=1.0000 false=0.0000) prompt_ppl=14848.52
Prompt: globe mortality counsel pergola ghostunterricht Pompe insgesamtboat grey
[PEZ λ=0.25 ADV] Epoch 4/10, batch 50 | joint=18.8123 task=16.4109 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 4/10, batch 100 | joint=18.7832 task=16.3818 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 4/10, batch 150 | joint=18.8387 task=16.4372 ppl_loss=9.6057 ppl=14848.52
[PEZ λ=0.25 ADV] Epoch 4/10, batch 200 | joint=18.8696 task=16.4682 ppl_loss=9.6057 ppl=14848.52
