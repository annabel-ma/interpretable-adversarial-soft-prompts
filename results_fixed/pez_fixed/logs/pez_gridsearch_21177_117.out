Using device: cuda
Lambda: 0.75, LR: 0.1, Adversarial: True

Loading T5 tokenizer...

Loading GPT-2 for prompt perplexity...

Loading BoolQ dataset...
Balanced BoolQ train: 7106 examples (3553 True, 3553 False)
[PEZ λ=0.75 ADV] Epoch 1/10, batch 50 | joint=23.9605 task=17.5935 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 1/10, batch 100 | joint=23.8571 task=17.4901 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 1/10, batch 150 | joint=23.8982 task=17.5312 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 1/10, batch 200 | joint=23.8944 task=17.5274 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 1/10, batch 250 | joint=23.8997 task=17.5327 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 1/10, batch 300 | joint=23.9176 task=17.5506 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 1/10, batch 350 | joint=23.9254 task=17.5584 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 1/10, batch 400 | joint=23.9200 task=17.5530 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 1/10 | joint=23.9210 task=17.5540 ppl_loss=8.4893 ppl=4862.69 val_loss=0.1702 val_acc=0.6242 (true=1.0000 false=0.0065) prompt_ppl=4862.69
Prompt: 224bornObtain frame Dean1.1surgicallase smoker Dashboard
[PEZ λ=0.75 ADV] Epoch 2/10, batch 50 | joint=24.0198 task=17.6528 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 2/10, batch 100 | joint=23.9567 task=17.5897 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 2/10, batch 150 | joint=23.9622 task=17.5952 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 2/10, batch 200 | joint=23.9311 task=17.5641 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 2/10, batch 250 | joint=23.8939 task=17.5269 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 2/10, batch 300 | joint=23.8631 task=17.4961 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 2/10, batch 350 | joint=23.8408 task=17.4738 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 2/10, batch 400 | joint=23.8580 task=17.4910 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 2/10 | joint=23.8488 task=17.4818 ppl_loss=8.4893 ppl=4862.69 val_loss=0.1759 val_acc=0.6217 (true=1.0000 false=0.0000) prompt_ppl=4862.69
Prompt: 224bornObtain frame Dean1.1surgicallase smoker Dashboard
[PEZ λ=0.75 ADV] Epoch 3/10, batch 50 | joint=23.9080 task=17.5410 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 3/10, batch 100 | joint=23.9226 task=17.5556 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 3/10, batch 150 | joint=23.9406 task=17.5736 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 3/10, batch 200 | joint=23.9109 task=17.5439 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 3/10, batch 250 | joint=23.9157 task=17.5487 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 3/10, batch 300 | joint=23.9143 task=17.5473 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 3/10, batch 350 | joint=23.8962 task=17.5292 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 3/10, batch 400 | joint=23.8823 task=17.5153 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 3/10 | joint=23.9002 task=17.5332 ppl_loss=8.4893 ppl=4862.69 val_loss=0.1724 val_acc=0.5526 (true=0.5303 false=0.5893) prompt_ppl=4862.69
Prompt: 224bornObtain frame Dean1.1surgicallase smoker Dashboard
[PEZ λ=0.75 ADV] Epoch 4/10, batch 50 | joint=23.9233 task=17.5563 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 4/10, batch 100 | joint=23.8895 task=17.5225 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 4/10, batch 150 | joint=23.8890 task=17.5220 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 4/10, batch 200 | joint=23.9023 task=17.5353 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 4/10, batch 250 | joint=23.9163 task=17.5493 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 4/10, batch 300 | joint=23.8772 task=17.5102 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 4/10, batch 350 | joint=23.8919 task=17.5249 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 4/10, batch 400 | joint=23.8962 task=17.5292 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 4/10 | joint=23.8983 task=17.5313 ppl_loss=8.4893 ppl=4862.69 val_loss=0.1899 val_acc=0.3786 (true=0.0010 false=0.9992) prompt_ppl=4862.69
Prompt: 224bornObtain frame Dean1.1surgicallase smoker Dashboard
[PEZ λ=0.75 ADV] Epoch 5/10, batch 50 | joint=23.7685 task=17.4014 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 5/10, batch 100 | joint=23.8229 task=17.4559 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 5/10, batch 150 | joint=23.8682 task=17.5012 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 5/10, batch 200 | joint=23.8886 task=17.5216 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 5/10, batch 250 | joint=23.9063 task=17.5393 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 5/10, batch 300 | joint=23.9321 task=17.5651 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 5/10, batch 350 | joint=23.9492 task=17.5821 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 5/10, batch 400 | joint=23.9278 task=17.5608 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 5/10 | joint=23.9152 task=17.5482 ppl_loss=8.4893 ppl=4862.69 val_loss=0.1729 val_acc=0.6217 (true=1.0000 false=0.0000) prompt_ppl=4862.69
Prompt: 224bornObtain frame Dean1.1surgicallase smoker Dashboard
[PEZ λ=0.75 ADV] Epoch 6/10, batch 50 | joint=24.0888 task=17.7218 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 6/10, batch 100 | joint=23.9573 task=17.5903 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 6/10, batch 150 | joint=23.8632 task=17.4961 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 6/10, batch 200 | joint=23.8979 task=17.5309 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 6/10, batch 250 | joint=23.9259 task=17.5589 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 6/10, batch 300 | joint=23.9163 task=17.5493 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 6/10, batch 350 | joint=23.9059 task=17.5388 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 6/10, batch 400 | joint=23.9147 task=17.5477 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 6/10 | joint=23.9274 task=17.5604 ppl_loss=8.4893 ppl=4862.69 val_loss=0.1670 val_acc=0.6217 (true=1.0000 false=0.0000) prompt_ppl=4862.69
Prompt: 224bornObtain frame Dean1.1surgicallase smoker Dashboard
[PEZ λ=0.75 ADV] Epoch 7/10, batch 50 | joint=23.8715 task=17.5045 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 7/10, batch 100 | joint=23.8839 task=17.5168 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 7/10, batch 150 | joint=23.9053 task=17.5383 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 7/10, batch 200 | joint=23.9019 task=17.5348 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 7/10, batch 250 | joint=23.9120 task=17.5450 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 7/10, batch 300 | joint=23.9115 task=17.5445 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 7/10, batch 350 | joint=23.9050 task=17.5380 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 7/10, batch 400 | joint=23.9212 task=17.5542 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 7/10 | joint=23.9326 task=17.5656 ppl_loss=8.4893 ppl=4862.69 val_loss=0.1671 val_acc=0.6217 (true=1.0000 false=0.0000) prompt_ppl=4862.69
Prompt: 224bornObtain frame Dean1.1surgicallase smoker Dashboard
[PEZ λ=0.75 ADV] Epoch 8/10, batch 50 | joint=23.7619 task=17.3949 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 8/10, batch 100 | joint=23.8698 task=17.5028 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 8/10, batch 150 | joint=23.8089 task=17.4419 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 8/10, batch 200 | joint=23.8703 task=17.5033 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 8/10, batch 250 | joint=23.8834 task=17.5164 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 8/10, batch 300 | joint=23.8961 task=17.5291 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 8/10, batch 350 | joint=23.8905 task=17.5235 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 8/10, batch 400 | joint=23.8857 task=17.5187 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 8/10 | joint=23.8843 task=17.5173 ppl_loss=8.4893 ppl=4862.69 val_loss=0.1670 val_acc=0.6217 (true=1.0000 false=0.0000) prompt_ppl=4862.69
Prompt: 224bornObtain frame Dean1.1surgicallase smoker Dashboard
[PEZ λ=0.75 ADV] Epoch 9/10, batch 50 | joint=24.0044 task=17.6374 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 9/10, batch 100 | joint=23.8813 task=17.5143 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 9/10, batch 150 | joint=23.9261 task=17.5591 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 9/10, batch 200 | joint=23.9380 task=17.5710 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 9/10, batch 250 | joint=23.9326 task=17.5656 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 9/10, batch 300 | joint=23.9450 task=17.5780 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 9/10, batch 350 | joint=23.9546 task=17.5876 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 9/10, batch 400 | joint=23.9689 task=17.6018 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 9/10 | joint=23.9766 task=17.6096 ppl_loss=8.4893 ppl=4862.69 val_loss=0.1670 val_acc=0.6217 (true=1.0000 false=0.0000) prompt_ppl=4862.69
Prompt: 224bornObtain frame Dean1.1surgicallase smoker Dashboard
[PEZ λ=0.75 ADV] Epoch 10/10, batch 50 | joint=23.8592 task=17.4922 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 10/10, batch 100 | joint=23.7847 task=17.4177 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 10/10, batch 150 | joint=23.8425 task=17.4755 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 10/10, batch 200 | joint=23.8049 task=17.4379 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 10/10, batch 250 | joint=23.8310 task=17.4640 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 10/10, batch 300 | joint=23.8568 task=17.4898 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 10/10, batch 350 | joint=23.8739 task=17.5069 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 10/10, batch 400 | joint=23.8890 task=17.5220 ppl_loss=8.4893 ppl=4862.69
[PEZ λ=0.75 ADV] Epoch 10/10 | joint=23.8912 task=17.5242 ppl_loss=8.4893 ppl=4862.69 val_loss=0.1708 val_acc=0.6217 (true=1.0000 false=0.0000) prompt_ppl=4862.69
Prompt: 224bornObtain frame Dean1.1surgicallase smoker Dashboard

Results saved to /mnt/polished-lake/home/annabelma/other/results_fixed/pez_fixed/adversarial_true
  Model: model_lambda_0.75_lr_0.1_promptlen_10.pt
  History: history_lambda_0.75_lr_0.1_promptlen_10.json
Job 117 completed: lambda=0.75, lr=1e-1, epochs=10, prompt_length=10, adversarial=--adversarial
