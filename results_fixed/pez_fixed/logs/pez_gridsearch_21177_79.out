Using device: cuda
Lambda: 0.0, LR: 0.01, Adversarial: False

Loading T5 tokenizer...

Loading GPT-2 for prompt perplexity...

Loading BoolQ dataset...
Balanced BoolQ train: 7106 examples (3553 True, 3553 False)
[PEZ λ=0.0 NON-ADV] Epoch 1/10, batch 50 | joint=16.0733 task=16.0733 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 1/10, batch 100 | joint=16.0382 task=16.0382 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 1/10, batch 150 | joint=15.9969 task=15.9969 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 1/10, batch 200 | joint=16.0251 task=16.0251 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 1/10, batch 250 | joint=15.9858 task=15.9858 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 1/10, batch 300 | joint=16.0107 task=16.0107 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 1/10, batch 350 | joint=16.0048 task=16.0048 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 1/10, batch 400 | joint=16.0135 task=16.0135 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 1/10 | joint=16.0198 task=16.0198 ppl_loss=0.0000 ppl=0.00 val_loss=0.2156 val_acc=0.6697 (true=0.9887 false=0.1455) prompt_ppl=0.00
Prompt: separated
[PEZ λ=0.0 NON-ADV] Epoch 2/10, batch 50 | joint=15.9286 task=15.9286 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 2/10, batch 100 | joint=15.9731 task=15.9731 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 2/10, batch 150 | joint=15.9785 task=15.9785 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 2/10, batch 200 | joint=15.9803 task=15.9803 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 2/10, batch 250 | joint=16.0165 task=16.0165 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 2/10, batch 300 | joint=16.0148 task=16.0148 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 2/10, batch 350 | joint=16.0164 task=16.0164 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 2/10, batch 400 | joint=16.0077 task=16.0077 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 2/10 | joint=15.9924 task=15.9924 ppl_loss=0.0000 ppl=0.00 val_loss=0.2209 val_acc=0.6697 (true=0.9936 false=0.1374) prompt_ppl=0.00
Prompt: separated
[PEZ λ=0.0 NON-ADV] Epoch 3/10, batch 50 | joint=15.8475 task=15.8475 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 3/10, batch 100 | joint=15.9074 task=15.9074 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 3/10, batch 150 | joint=15.8990 task=15.8990 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 3/10, batch 200 | joint=15.8636 task=15.8636 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 3/10, batch 250 | joint=15.8944 task=15.8944 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 3/10, batch 300 | joint=15.9050 task=15.9050 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 3/10, batch 350 | joint=15.9354 task=15.9354 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 3/10, batch 400 | joint=15.9538 task=15.9538 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 3/10 | joint=15.9726 task=15.9726 ppl_loss=0.0000 ppl=0.00 val_loss=0.1300 val_acc=0.7517 (true=0.9508 false=0.4244) prompt_ppl=0.00
Prompt: separated
[PEZ λ=0.0 NON-ADV] Epoch 4/10, batch 50 | joint=16.0945 task=16.0945 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 4/10, batch 100 | joint=16.0192 task=16.0192 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 4/10, batch 150 | joint=15.9713 task=15.9713 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 4/10, batch 200 | joint=16.0162 task=16.0162 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 4/10, batch 250 | joint=15.9936 task=15.9936 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 4/10, batch 300 | joint=15.9784 task=15.9784 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 4/10, batch 350 | joint=15.9806 task=15.9806 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 4/10, batch 400 | joint=15.9879 task=15.9879 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 4/10 | joint=15.9904 task=15.9904 ppl_loss=0.0000 ppl=0.00 val_loss=0.1837 val_acc=0.7009 (true=0.9843 false=0.2352) prompt_ppl=0.00
Prompt: separated
[PEZ λ=0.0 NON-ADV] Epoch 5/10, batch 50 | joint=16.0341 task=16.0341 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 5/10, batch 100 | joint=15.9986 task=15.9986 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 5/10, batch 150 | joint=16.0261 task=16.0261 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 5/10, batch 200 | joint=16.0494 task=16.0494 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 5/10, batch 250 | joint=16.0608 task=16.0608 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 5/10, batch 300 | joint=16.0706 task=16.0706 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 5/10, batch 350 | joint=16.0692 task=16.0692 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 5/10, batch 400 | joint=16.0609 task=16.0609 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 5/10 | joint=16.0650 task=16.0650 ppl_loss=0.0000 ppl=0.00 val_loss=0.1794 val_acc=0.7003 (true=0.9852 false=0.2320) prompt_ppl=0.00
Prompt: separated
[PEZ λ=0.0 NON-ADV] Epoch 6/10, batch 50 | joint=16.0354 task=16.0354 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 6/10, batch 100 | joint=15.9579 task=15.9579 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 6/10, batch 150 | joint=15.9552 task=15.9552 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 6/10, batch 200 | joint=15.9823 task=15.9823 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 6/10, batch 250 | joint=15.9964 task=15.9964 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 6/10, batch 300 | joint=15.9795 task=15.9795 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 NON-ADV] Epoch 6/10, batch 350 | joint=15.9645 task=15.9645 ppl_loss=0.0000 ppl=0.00
