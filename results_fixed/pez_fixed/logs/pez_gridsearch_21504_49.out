Using device: cuda
Lambda: 0.0, LR: 0.001, Adversarial: True

Loading T5 tokenizer...

Loading GPT-2 for prompt perplexity...

Loading BoolQ dataset...
Balanced BoolQ train: 7106 examples (3553 True, 3553 False)
[PEZ λ=0.0 ADV] Epoch 1/10, batch 50 | joint=17.8366 task=17.8366 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 1/10, batch 100 | joint=17.7717 task=17.7717 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 1/10, batch 150 | joint=17.6873 task=17.6873 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 1/10, batch 200 | joint=17.6850 task=17.6850 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 1/10, batch 250 | joint=17.6948 task=17.6948 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 1/10, batch 300 | joint=17.6640 task=17.6640 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 1/10, batch 350 | joint=17.6557 task=17.6557 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 1/10, batch 400 | joint=17.6325 task=17.6325 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 1/10 | joint=17.6331 task=17.6331 ppl_loss=0.0000 ppl=0.00 val_loss=0.9692 val_acc=0.6954 (true=0.9769 false=0.2328) prompt_ppl=0.00
Prompt: 280
[PEZ λ=0.0 ADV] Epoch 2/10, batch 50 | joint=17.6478 task=17.6478 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 2/10, batch 100 | joint=17.7217 task=17.7217 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 2/10, batch 150 | joint=17.6894 task=17.6894 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 2/10, batch 200 | joint=17.7155 task=17.7155 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 2/10, batch 250 | joint=17.7083 task=17.7083 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 2/10, batch 300 | joint=17.7103 task=17.7103 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 2/10, batch 350 | joint=17.7021 task=17.7021 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 2/10, batch 400 | joint=17.6990 task=17.6990 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 2/10 | joint=17.6861 task=17.6861 ppl_loss=0.0000 ppl=0.00 val_loss=15.0140 val_acc=0.7089 (true=0.6158 false=0.8618) prompt_ppl=0.00
Prompt: 280
[PEZ λ=0.0 ADV] Epoch 3/10, batch 50 | joint=17.4716 task=17.4716 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 3/10, batch 100 | joint=17.5673 task=17.5673 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 3/10, batch 150 | joint=17.6012 task=17.6012 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 3/10, batch 200 | joint=17.5875 task=17.5875 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 3/10, batch 250 | joint=17.5841 task=17.5841 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 3/10, batch 300 | joint=17.5922 task=17.5922 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 3/10, batch 350 | joint=17.6245 task=17.6245 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 3/10, batch 400 | joint=17.6311 task=17.6311 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 3/10 | joint=17.6570 task=17.6570 ppl_loss=0.0000 ppl=0.00 val_loss=0.1588 val_acc=0.7000 (true=0.9759 false=0.2466) prompt_ppl=0.00
Prompt: 280
[PEZ λ=0.0 ADV] Epoch 4/10, batch 50 | joint=17.6277 task=17.6277 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 4/10, batch 100 | joint=17.7173 task=17.7173 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 4/10, batch 150 | joint=17.6736 task=17.6736 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 4/10, batch 200 | joint=17.6172 task=17.6172 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 4/10, batch 250 | joint=17.6273 task=17.6273 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 4/10, batch 300 | joint=17.6485 task=17.6485 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 4/10, batch 350 | joint=17.6400 task=17.6400 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 4/10, batch 400 | joint=17.6602 task=17.6602 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 4/10 | joint=17.6608 task=17.6608 ppl_loss=0.0000 ppl=0.00 val_loss=0.2164 val_acc=0.6544 (true=0.9956 false=0.0938) prompt_ppl=0.00
Prompt: 280
[PEZ λ=0.0 ADV] Epoch 5/10, batch 50 | joint=17.7004 task=17.7004 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 5/10, batch 100 | joint=17.5785 task=17.5785 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 5/10, batch 150 | joint=17.5898 task=17.5898 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 5/10, batch 200 | joint=17.6199 task=17.6199 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 5/10, batch 250 | joint=17.6644 task=17.6644 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 5/10, batch 300 | joint=17.6432 task=17.6432 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 5/10, batch 350 | joint=17.6451 task=17.6451 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 5/10, batch 400 | joint=17.6618 task=17.6618 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 5/10 | joint=17.6229 task=17.6229 ppl_loss=0.0000 ppl=0.00 val_loss=0.1730 val_acc=0.6719 (true=0.9931 false=0.1439) prompt_ppl=0.00
Prompt: 280
[PEZ λ=0.0 ADV] Epoch 6/10, batch 50 | joint=17.5571 task=17.5571 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 6/10, batch 100 | joint=17.5790 task=17.5790 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 6/10, batch 150 | joint=17.5909 task=17.5909 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 6/10, batch 200 | joint=17.6199 task=17.6199 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 6/10, batch 250 | joint=17.6388 task=17.6388 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 6/10, batch 300 | joint=17.6572 task=17.6572 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 6/10, batch 350 | joint=17.6428 task=17.6428 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 6/10, batch 400 | joint=17.6410 task=17.6410 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 6/10 | joint=17.6578 task=17.6578 ppl_loss=0.0000 ppl=0.00 val_loss=0.1641 val_acc=0.6786 (true=0.9921 false=0.1633) prompt_ppl=0.00
Prompt: 280
[PEZ λ=0.0 ADV] Epoch 7/10, batch 50 | joint=17.5397 task=17.5397 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 7/10, batch 100 | joint=17.6076 task=17.6076 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 7/10, batch 150 | joint=17.6120 task=17.6120 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 7/10, batch 200 | joint=17.6047 task=17.6047 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 7/10, batch 250 | joint=17.6243 task=17.6243 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 7/10, batch 300 | joint=17.6336 task=17.6336 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 7/10, batch 350 | joint=17.6231 task=17.6231 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 7/10, batch 400 | joint=17.6209 task=17.6209 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 7/10 | joint=17.6101 task=17.6101 ppl_loss=0.0000 ppl=0.00 val_loss=0.1494 val_acc=0.6957 (true=0.9788 false=0.2304) prompt_ppl=0.00
Prompt: 280
[PEZ λ=0.0 ADV] Epoch 8/10, batch 50 | joint=17.6849 task=17.6849 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 8/10, batch 100 | joint=17.6549 task=17.6549 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 8/10, batch 150 | joint=17.6133 task=17.6133 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 8/10, batch 200 | joint=17.6007 task=17.6007 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 8/10, batch 250 | joint=17.5928 task=17.5928 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 8/10, batch 300 | joint=17.5802 task=17.5802 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 8/10, batch 350 | joint=17.5829 task=17.5829 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 8/10, batch 400 | joint=17.5878 task=17.5878 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 8/10 | joint=17.5858 task=17.5858 ppl_loss=0.0000 ppl=0.00 val_loss=0.1731 val_acc=0.6606 (true=0.9946 false=0.1116) prompt_ppl=0.00
Prompt: 280
[PEZ λ=0.0 ADV] Epoch 9/10, batch 50 | joint=17.7149 task=17.7149 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 9/10, batch 100 | joint=17.6742 task=17.6742 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 9/10, batch 150 | joint=17.6457 task=17.6457 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 9/10, batch 200 | joint=17.6540 task=17.6540 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 9/10, batch 250 | joint=17.6707 task=17.6707 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 9/10, batch 300 | joint=17.6711 task=17.6711 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 9/10, batch 350 | joint=17.6488 task=17.6488 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 9/10, batch 400 | joint=17.6424 task=17.6424 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 9/10 | joint=17.6276 task=17.6276 ppl_loss=0.0000 ppl=0.00 val_loss=0.1673 val_acc=0.6676 (true=0.9946 false=0.1302) prompt_ppl=0.00
Prompt: 280
[PEZ λ=0.0 ADV] Epoch 10/10, batch 50 | joint=17.5859 task=17.5859 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 10/10, batch 100 | joint=17.6733 task=17.6733 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 10/10, batch 150 | joint=17.6841 task=17.6841 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 10/10, batch 200 | joint=17.6794 task=17.6794 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 10/10, batch 250 | joint=17.6880 task=17.6880 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 10/10, batch 300 | joint=17.6749 task=17.6749 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 10/10, batch 350 | joint=17.6696 task=17.6696 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 10/10, batch 400 | joint=17.6636 task=17.6636 ppl_loss=0.0000 ppl=0.00
[PEZ λ=0.0 ADV] Epoch 10/10 | joint=17.6871 task=17.6871 ppl_loss=0.0000 ppl=0.00 val_loss=0.1731 val_acc=0.6587 (true=0.9966 false=0.1035) prompt_ppl=0.00
Prompt: 280

Results saved to /mnt/polished-lake/home/annabelma/other/results_fixed/pez_fixed/adversarial_true
  Model: model_lambda_0.0_lr_0.001_promptlen_1.pt
  History: history_lambda_0.0_lr_0.001_promptlen_1.json
Job 49 completed: lambda=0, lr=1e-3, epochs=10, prompt_length=1, adversarial=--adversarial
